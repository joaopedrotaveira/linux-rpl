From 8727014a881b69c65515ba93e38cb970148fceab Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Jo=C3=A3o=20Pedro=20Taveira?= <joao.p.taveira@gmail.com>
Date: Sun, 5 Jan 2014 16:14:55 +0000
Subject: [PATCH 3/4] Initial RPL support

---
 include/linux/ipv6.h            |    8 +-
 include/linux/rpl_nl.h          |  107 ++
 include/net/if_inet6.h          |    4 +
 include/net/netns/ipv6.h        |    4 +
 include/net/netns/rpl.h         |   38 +
 include/net/rpl/rpl.h           |   46 +
 include/net/rpl/rpl_constants.h |  157 +++
 include/net/rpl/rpl_dag.h       |  164 +++
 include/net/rpl/rpl_debug.h     |   51 +
 include/net/rpl/rpl_internals.h |  352 +++++
 include/net/rpl/rpl_of.h        |   40 +
 include/net/rpl/rpl_trickle.h   |   66 +
 include/net/rpl/rpl_types.h     |  242 ++++
 include/uapi/linux/ipv6.h       |    7 +
 net/ipv6/Kconfig                |   45 +
 net/ipv6/Makefile               |    6 +
 net/ipv6/addrconf.c             |   49 +
 net/ipv6/af_inet6.c             |   12 +
 net/ipv6/icmp.c                 |   23 +
 net/ipv6/rpl/netlink.c          |  137 ++
 net/ipv6/rpl/nl-dag-conf.c      |  615 +++++++++
 net/ipv6/rpl/nl-dag-info.c      |  376 +++++
 net/ipv6/rpl/nl-dag-mng.c       |  214 +++
 net/ipv6/rpl/nl_policy.c        |   64 +
 net/ipv6/rpl/nlrpl.h            |   51 +
 net/ipv6/rpl/rpl.c              |  866 ++++++++++++
 net/ipv6/rpl/rpl_dag.c          | 2863 +++++++++++++++++++++++++++++++++++++++
 net/ipv6/rpl/rpl_debug.c        |  472 +++++++
 net/ipv6/rpl/rpl_icmp6.c        | 1883 +++++++++++++++++++++++++
 net/ipv6/rpl/rpl_trickle.c      |  264 ++++
 net/ipv6/rpl_of_of0.c           |  181 +++
 31 files changed, 9406 insertions(+), 1 deletion(-)
 create mode 100644 include/linux/rpl_nl.h
 create mode 100644 include/net/netns/rpl.h
 create mode 100644 include/net/rpl/rpl.h
 create mode 100644 include/net/rpl/rpl_constants.h
 create mode 100644 include/net/rpl/rpl_dag.h
 create mode 100644 include/net/rpl/rpl_debug.h
 create mode 100644 include/net/rpl/rpl_internals.h
 create mode 100644 include/net/rpl/rpl_of.h
 create mode 100644 include/net/rpl/rpl_trickle.h
 create mode 100644 include/net/rpl/rpl_types.h
 create mode 100644 net/ipv6/rpl/netlink.c
 create mode 100644 net/ipv6/rpl/nl-dag-conf.c
 create mode 100644 net/ipv6/rpl/nl-dag-info.c
 create mode 100644 net/ipv6/rpl/nl-dag-mng.c
 create mode 100644 net/ipv6/rpl/nl_policy.c
 create mode 100644 net/ipv6/rpl/nlrpl.h
 create mode 100644 net/ipv6/rpl/rpl.c
 create mode 100644 net/ipv6/rpl/rpl_dag.c
 create mode 100644 net/ipv6/rpl/rpl_debug.c
 create mode 100644 net/ipv6/rpl/rpl_icmp6.c
 create mode 100644 net/ipv6/rpl/rpl_trickle.c
 create mode 100644 net/ipv6/rpl_of_of0.c

diff --git a/include/linux/ipv6.h b/include/linux/ipv6.h
index b8b7dc7..0dc53a9 100644
--- a/include/linux/ipv6.h
+++ b/include/linux/ipv6.h
@@ -47,7 +47,13 @@ struct ipv6_devconf {
 	__s32		disable_ipv6;
 	__s32		accept_dad;
 	__s32		force_tllao;
-	__s32           ndisc_notify;
+	__s32       ndisc_notify;
+#ifdef CONFIG_IPV6_RPL
+	__s32		rpl_enabled;
+	__s32		rpl_joined;
+	__s32		rpl_dodag_root;
+	__s32		rpl_icmp_dump;
+#endif /* CONFIG_IPV6_RPL */
 	void		*sysctl;
 };
 
diff --git a/include/linux/rpl_nl.h b/include/linux/rpl_nl.h
new file mode 100644
index 0000000..6ba1e9e
--- /dev/null
+++ b/include/linux/rpl_nl.h
@@ -0,0 +1,107 @@
+/*
+ *  rpl_nl.h
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *  Sergey Lapin <slapin@ossfans.org>
+ *  Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>
+ *  Maxim Osipov <maxim.osipov@siemens.com>
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License.
+ */
+
+#ifndef RPL_NL_H
+#define RPL_NL_H
+
+#define RPL_NL_NAME "RPL"
+#define RPL_MCAST_DAG_NAME "dag"
+
+enum {
+	__RPL_ATTR_INVALID,
+
+	RPL_ATTR_DEV_NAME,
+	RPL_ATTR_DEV_INDEX,
+	RPL_ATTR_DEV_ENABLED,
+	RPL_ATTR_DEV_AUTOGEN,
+
+	RPL_ATTR_OCP,
+	RPL_ATTR_INSTANCE_ID,
+
+	RPL_ATTR_DODAG_ID,
+	RPL_ATTR_RANK,
+	RPL_ATTR_VERSION,
+	RPL_ATTR_MOP,
+	RPL_ATTR_DTSN,
+	RPL_ATTR_DAO_SEQUENCE,
+	RPL_ATTR_GROUNDED,
+	RPL_ATTR_PCS,
+
+	RPL_ATTR_IS_ROOT,
+
+	RPL_ATTR_DIO_INT_DOUBL,
+	RPL_ATTR_DIO_INT_MIN,
+	RPL_ATTR_DIO_REDUN,
+	RPL_ATTR_MAX_RANK_INCR,
+	RPL_ATTR_MIN_HOP_RANK_INCR,
+
+	RPL_ATTR_DEF_LIFETIME,
+	RPL_ATTR_LIFETIME_UNIT,
+
+	RPL_ATTR_NODE_ADDR,
+	RPL_ATTR_IS_DODAG_PARENT,
+	RPL_ATTR_IS_DAO_PARENT,
+	RPL_ATTR_IS_PREFERRED,
+
+	RPL_ATTR_PREFIX,
+	RPL_ATTR_PREFIX_LEN,
+	RPL_ATTR_NEXT_HOP,
+	RPL_ATTR_ONE_HOP,
+
+	__RPL_ATTR_MAX,
+};
+
+#define RPL_ATTR_MAX (__RPL_ATTR_MAX - 1)
+
+extern const struct nla_policy rpl_policy[];
+
+/* commands */
+/* REQ should be responded with CONF
+ * and INDIC with RESP
+ */
+enum {
+	__RPL_COMMAND_INVALID,
+
+	RPL_LIST_INSTANCE,
+
+	RPL_LIST_OF,
+
+	/* Management */
+	RPL_GLOBAL_REPAIR,
+	RPL_LOCAL_REPAIR,
+	RPL_DAO_UPDATE,
+
+	/* Information */
+	RPL_LIST_PARENTS,
+	RPL_LIST_NEIGHBORS,
+	RPL_LIST_DOWNWARD_ROUTES,
+
+	/* Configuration */
+	RPL_LIST_DAG,
+	RPL_ADD_DAG,
+	RPL_DEL_DAG,
+
+	RPL_LIST_IFACE,
+	RPL_ENABLE_IFACE,
+	RPL_DISABLE_IFACE,
+
+	__RPL_CMD_MAX,
+};
+
+#define RPL_CMD_MAX (__RPL_CMD_MAX - 1)
+
+#endif /* RPL_NL_H */
diff --git a/include/net/if_inet6.h b/include/net/if_inet6.h
index 736b5fb..5f34348 100644
--- a/include/net/if_inet6.h
+++ b/include/net/if_inet6.h
@@ -17,6 +17,9 @@
 
 #include <net/snmp.h>
 #include <linux/ipv6.h>
+#ifdef CONFIG_IPV6_RPL
+#include <net/rpl/rpl.h>
+#endif /* CONFIG_IPV6_RPL */
 
 /* inet6_dev.if_flags */
 
@@ -204,6 +207,7 @@ struct inet6_dev {
 
 	unsigned long		tstamp; /* ipv6InterfaceTable update timestamp */
 	struct rcu_head		rcu;
+
 };
 
 static inline void ipv6_eth_mc_map(const struct in6_addr *addr, char *buf)
diff --git a/include/net/netns/ipv6.h b/include/net/netns/ipv6.h
index 005e2c2..17a442c 100644
--- a/include/net/netns/ipv6.h
+++ b/include/net/netns/ipv6.h
@@ -3,6 +3,7 @@
  */
 
 #include <net/inet_frag.h>
+#include <net/netns/rpl.h>
 
 #ifndef __NETNS_IPV6_H__
 #define __NETNS_IPV6_H__
@@ -61,6 +62,9 @@ struct netns_ipv6 {
 #endif
 	struct sock		**icmp_sk;
 	struct sock             *ndisc_sk;
+#ifdef CONFIG_IPV6_RPL
+	struct netns_rpl		rpl;
+#endif
 	struct sock             *tcp_sk;
 	struct sock             *igmp_sk;
 #ifdef CONFIG_IPV6_MROUTE
diff --git a/include/net/netns/rpl.h b/include/net/netns/rpl.h
new file mode 100644
index 0000000..4709683
--- /dev/null
+++ b/include/net/netns/rpl.h
@@ -0,0 +1,38 @@
+/**
+ * @file rpl.h
+ *
+ * @date Nov 30, 2013
+ * @author Joao Pedro Taveira <joao.silva@inov.pt>
+ */
+
+#ifndef __NETNS_RPL_H_
+#define __NETNS_RPL_H_
+
+struct netns_rpl {
+	/*
+	 * List of enabled devices (struct rpl_enabled_device)
+	 */
+	struct list_head 	rpl_enabled_devices_list_head;
+	struct mutex 		rpl_enabled_devices_list_mutex;
+
+	/*
+	 * RPL Input processing queue
+	 */
+	struct workqueue_struct		*rpl_rx_wq;
+
+	/*
+	 * List of RPL instances (struct rpl_instance)
+	 */
+	struct mutex 		rpl_instances_list_mutex;
+	struct list_head 	rpl_instances_list_head;
+
+	/*
+	 * List of RPL dags (struct rpl_dag)
+	 */
+	struct mutex 		rpl_dags_list_mutex;
+	struct list_head 	rpl_dags_list_head;
+
+	struct sock			*rpl_sk;
+};
+
+#endif /* __NETNS_RPL_H_ */
diff --git a/include/net/rpl/rpl.h b/include/net/rpl/rpl.h
new file mode 100644
index 0000000..186100e
--- /dev/null
+++ b/include/net/rpl/rpl.h
@@ -0,0 +1,46 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl.h
+ *
+ * @date Aug 20, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#ifndef RPL_H_
+#define RPL_H_
+
+/*
+ *  ICMPv6 message type
+ */
+#define ICMPV6_RPL 155
+
+extern int rpl_rcv(struct sk_buff *skb);
+
+extern int	rpl_init(void);
+extern void	rpl_cleanup(void);
+
+extern int rpl_sysctl_rpl_enabled(ctl_table *ctl, int write,
+			    void __user *buffer, size_t *lenp, loff_t *ppos);
+
+extern int rpl_sysctl_rpl_joined(ctl_table *ctl, int write,
+			    void __user *buffer, size_t *lenp, loff_t *ppos);
+
+extern int rpl_sysctl_rpl_dodag_root(ctl_table *ctl, int write,
+			    void __user *buffer, size_t *lenp, loff_t *ppos);
+
+extern int rpl_sysctl_rpl_icmp_dump(ctl_table *ctl, int write,
+			    void __user *buffer, size_t *lenp, loff_t *ppos);
+
+#endif /* RPL_H_ */
diff --git a/include/net/rpl/rpl_constants.h b/include/net/rpl/rpl_constants.h
new file mode 100644
index 0000000..6239077
--- /dev/null
+++ b/include/net/rpl/rpl_constants.h
@@ -0,0 +1,157 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_constants.h
+ *
+ * @date Aug 20, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#ifndef RPL_CONSTANTS_H_
+#define RPL_CONSTANTS_H_
+
+#include <linux/in6.h>
+
+/*
+ * RPL Defaults
+ */
+
+/*
+ * Rank for a virtual root that might be used to coordinate multiple roots
+ */
+#define RPL_BASE_RANK 0
+
+/*
+ * constant maximum for the Rank
+ */
+#define RPL_INFINITE_RANK 0xffff
+
+/*
+ * RPLInstanceID that is used by this protocol by a node without any overriding policy.
+ */
+#define RPL_DEFAULT_INSTANCE 0
+
+/*
+ * default value used to configure PCS in the DODAG Configuration option
+ * (dictates the number of significant bits in the Path Control field of the Transit Information option)
+ * value 0 means that a router sends a DAO to only one of its parents
+ */
+#define RPL_DEFAULT_PATH_CONTROL_SIZE 0
+
+/*
+ * default value used to configure Imin for the DIO Trickle timer
+ */
+#define RPL_DEFAULT_DIO_INTERVAL_MIN 3  // 8 ms
+
+/*
+ * default value used to configure Imax for the DIO Trickle timer
+ */
+#define RPL_DEFAULT_DIO_INTERVAL_DOUBLINGS 20  // 2.3 hours
+
+/*
+ * default value used to configure k for the DIO Trickle timer
+ */
+#define RPL_DEFAULT_DIO_REDUNDANCY_CONSTANT 10
+
+/*
+ * default value of MinHopRankIncrease
+ */
+#define RPL_DEFAULT_MIN_HOP_RANK_INCREASE 256
+
+/*
+ * default value for the DelayDAO Timer
+ */
+#define RPL_DEFAULT_DAO_DELAY 1
+
+/*
+ * default duration to wait in order to receive a DAO-ACK message
+ * (this value is not defined in the RFC)
+ */
+#define RPL_DEFAULT_DAO_ACK_DELAY 2
+
+/*
+ * number of times the node should try to send a DAO message before giving up
+ * (this value is not defined in the RFC)
+ */
+#define RPL_DEFAULT_DAO_MAX_TRANS_RETRY 3
+
+/*
+ * number of time a DAO will transmit No-Path that contains information on
+ * routes that recently have been deleted
+ */
+#define RPL_DEFAULT_DAO_NO_PATH_TRANS 3
+
+/*
+ * default maximum rank increased (0 means the mechanism is disabled)
+ */
+#define RPL_DEFAULT_MAX_RANK_INCREASE 3 * RPL_DEFAULT_MIN_HOP_RANK_INCREASE
+
+/*
+ * Rank for a DODAG root See Section 17: ROOT_RANK has a value of MinHopRankIncrease
+ */
+#define RPL_ROOT_RANK RPL_DEFAULT_MIN_HOP_RANK_INCREASE
+
+#define RPL_DIS_INTERVAL 		60 // seconds
+#define RPL_DIS_INIT_INTERVAL	5	// seconds
+
+#define RPL_OF_OF0				0
+#define RPL_OF_MRHOF			1
+
+#define MODULE_ALIAS_RPL_OF(OCP) \
+	MODULE_ALIAS("rpl-of-" __stringify(OCP))
+
+#define RPL_MOP_NO_DOWNWARD_ROUTES		0
+#define RPL_MOP_NON_STORING_MODE		1
+#define RPL_MOP_STORING_MODE_WITHOUT_MC	2
+#define RPL_MOP_STORING_MODE_WITH_MC	3
+
+/*
+ * ICMPv6 message codes for RPL messages
+ */
+#define ICMPV6_RPL_DIS			0x00
+#define ICMPV6_RPL_SEC_DIS		0x80
+
+#define ICMPV6_RPL_DIO			0x01
+#define ICMPV6_RPL_SEC_DIO		0x81
+
+#define ICMPV6_RPL_DAO			0x02
+#define ICMPV6_RPL_SEC_DAO		0x82
+
+#define ICMPV6_RPL_DAO_ACK		0x03
+#define ICMPV6_RPL_SEC_DAO_ACK	0x83
+
+#define ICMPV6_RPL_CC			0x8A
+
+/*
+ * RPL control message option type
+ */
+#define ICMPV6_RPL_OPT_Pad1						0x00
+#define ICMPV6_RPL_OPT_PadN						0x01
+#define ICMPV6_RPL_OPT_DAG_Metric_Container		0x02
+#define ICMPV6_RPL_OPT_Route_Information		0x03
+#define ICMPV6_RPL_OPT_DODAG_Configuration		0x04
+#define ICMPV6_RPL_OPT_RPL_Target				0x05
+#define ICMPV6_RPL_OPT_Transit_Information		0x06
+#define ICMPV6_RPL_OPT_Solicited_Information	0x07
+#define ICMPV6_RPL_OPT_Prefix_Information		0x08
+#define ICMPV6_RPL_OPT_RPL_Target_Descriptor	0x09
+
+
+#ifdef CONFIG_IPV6_RPL
+#define IN6ADDR_ALL_RPL_NODES_INIT \
+		{ { { 0xff,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0x1a } } }
+extern const struct in6_addr in6addr_all_rpl_nodes;
+#endif /* CONFIG_IPV6_RPL */
+
+#endif /* RPL_CONSTANTS_H_ */
diff --git a/include/net/rpl/rpl_dag.h b/include/net/rpl/rpl_dag.h
new file mode 100644
index 0000000..944b5ed
--- /dev/null
+++ b/include/net/rpl/rpl_dag.h
@@ -0,0 +1,164 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_dag.h
+ *
+ * @date Jul 31, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#ifndef RPL_DAG_H_
+#define RPL_DAG_H_
+
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/in6.h>
+#include <linux/mutex.h>
+#include <linux/skbuff.h>
+#include <net/rpl/rpl_types.h>
+
+/*
+ * RPL Instances List Interface
+ */
+extern int rpl_instances_list_init(struct netns_rpl *rplns);
+extern int rpl_instances_list_cleanup(struct netns_rpl *rplns);
+
+/*
+ * RPL Enabled Network Devices
+ */
+extern int rpl_enabled_devices_list_init(struct netns_rpl *rplns);
+extern int rpl_enabled_devices_list_cleanup(struct netns_rpl *rplns);
+extern struct rpl_enabled_device *rpl_enabled_devices_list_add(struct net_device *dev, int *err);
+extern int rpl_enabled_devices_list_del(struct net_device *dev);
+extern struct rpl_enabled_device *rpl_enabled_device_get(struct net_device *dev);
+extern struct rpl_enabled_device *rpl_enabled_device_find_by_name(struct net *net, const char name[IFNAMSIZ + 1]);
+extern struct net_device *rpl_enabled_device_find_idev_by_name(struct net *net, const char name[IFNAMSIZ + 1]);
+extern int rpl_enabled_device_add_dis_timer(struct rpl_enabled_device *enabled);
+
+/*
+ * RPL Instance Functions
+ */
+
+extern void rpl_instance_free(struct rpl_instance *instance);
+static inline void rpl_instance_put(struct rpl_instance *instance)
+{
+	if (atomic_dec_and_test(&instance->refcnt))
+		rpl_instance_free(instance);
+}
+
+static inline void __rpl_instance_put(struct rpl_instance *instance)
+{
+	atomic_dec(&instance->refcnt);
+}
+
+static inline void rpl_instance_hold(struct rpl_instance *instance)
+{
+	atomic_inc(&instance->refcnt);
+}
+
+/*
+ * RPL Dags Functions
+ */
+extern int rpl_dags_list_init(struct netns_rpl *rplns);
+extern int rpl_dags_list_cleanup(struct netns_rpl *rplns);
+
+extern struct rpl_node *rpl_node_alloc(const struct in6_addr *addr, struct net_device *dev, rpl_rank_t rank, __u8 dtsn, int *err);
+extern int rpl_node_free(struct rpl_node *node);
+
+extern int rpl_dags_list_dump(struct net *net);
+
+extern int rpl_dags_list_add(struct net *net, struct rpl_dag *dag);
+extern int rpl_dags_list_del(struct net *net, struct rpl_dag *dag);
+
+extern struct rpl_dag *rpl_dag_find(struct net *net, __u8 instanceID, const struct in6_addr *dodagid);
+
+extern int rpl_dag_set_rank(struct rpl_dag *dag, rpl_rank_t rank);
+
+extern void rpl_dag_free(struct rpl_dag *dag);
+static inline void rpl_dag_put(struct rpl_dag *dag)
+{
+	if (atomic_dec_and_test(&dag->refcnt))
+		rpl_dag_free(dag);
+}
+
+static inline void __rpl_dag_put(struct rpl_dag *dag)
+{
+	atomic_dec(&dag->refcnt);
+}
+
+static inline void rpl_dag_hold(struct rpl_dag *dag)
+{
+	atomic_inc(&dag->refcnt);
+}
+
+extern bool rpl_dag_is_allowed(struct rpl_dag *dag, struct net_device *dev);
+extern int rpl_dag_set_allowed(struct rpl_dag *dag, struct net_device *dev,bool enabled, bool auto_gen, bool *should_trigger_dio);
+extern int rpl_dag_set_enabled(struct rpl_dag *dag, struct net_device *dev,bool enabled);
+
+extern struct rpl_node *rpl_dag_get_node(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *addr);
+extern int rpl_dag_add_node(struct rpl_dag *dag, struct rpl_node *node);
+extern int rpl_dag_del_node(struct rpl_node *parent);
+extern int rpl_dag_purge_nodes(struct rpl_dag *dag);
+extern int rpl_dag_unlink_nodes_by_dev(struct rpl_dag *dag, struct net_device *dev);
+extern int rpl_dag_unlink_node(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *addr);
+extern int rpl_dag_target_unreachable(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *addr);
+
+extern int rpl_dag_add_target(struct rpl_dag *dag, struct rpl_target *target, bool *updated);
+
+extern struct rpl_target *rpl_dag_get_target(struct rpl_dag *dag, const struct in6_addr *prefix, __u8 prefix_len);
+
+extern void rpl_dag_dbg_dump(struct rpl_dag *dag);
+
+extern struct rpl_dag *rpl_dag_setup_using_conf(struct net *net, struct rpl_dag_conf *cfg, int *perr);
+extern void rpl_dag_conf_default_init(struct rpl_dag_conf *cfg);
+
+extern int rpl_dag_start_root(struct net *net, struct rpl_dag_conf *cfg, struct net_device *dev);
+
+extern struct rpl_dag *rpl_dag_new_from_dio(struct net *net, struct net_device *dev, struct sk_buff *skb);
+
+extern int rpl_dag_disjoin(struct rpl_dag *dag, struct net_device *dev);
+extern int rpl_dag_inconsistent(struct rpl_dag *dag);
+extern int rpl_dag_consistent(struct rpl_dag *dag);
+
+extern int rpl_dag_cleanup_no_path(struct rpl_dag *dag);
+
+extern int rpl_dag_trigger_dao_timer(struct rpl_dag *dag);
+
+extern struct rpl_target *rpl_target_alloc(const struct in6_addr *prefix, __u8 prefix_len, int *err);
+extern void rpl_target_free(struct rpl_target *target);
+extern struct rpl_target_transit_info *rpl_target_get_installed(struct rpl_target *target);
+extern int rpl_target_add_transit_info(struct rpl_target *target, struct rpl_target_transit_info *transit_info,bool *updated);
+extern struct rpl_target_transit_info *rpl_target_find_transit_info(struct rpl_target *target, struct net_device *dev, const struct in6_addr *next_hop);
+extern int rpl_target_set_no_path(struct net *net, __u8 instanceID, const struct in6_addr *dodagid,
+		struct net_device *dev, const struct in6_addr *target_addr,
+		__u8 target_addr_len, const struct in6_addr *next_hop);
+extern int rpl_target_check_routes(struct rpl_target *target, bool *routes_updated);
+extern int rpl_target_merge_transit_info(struct rpl_target *old_target,struct rpl_target *new_target, bool *updated);
+
+extern struct rpl_target_transit_info *rpl_transit_info_alloc(const struct in6_addr *next_hop, struct net_device *dev, bool is_one_hop, int *err);
+extern void rpl_transit_info_free(struct rpl_target_transit_info *transit_info);
+extern int rpl_transit_info_update(struct rpl_target *target,
+		struct rpl_target_transit_info *transit_info, __u8 DAOSequence, __u8 path_sequence,
+		__u8 path_lifetime, __u8 path_control, bool *updated);
+
+extern int rpl_dag_update_upward_routes(struct rpl_dag *dag, bool *updated);
+extern int rpl_add_route_nexthop(struct net_device *dev, const struct in6_addr *prefix,
+		__u8 prefix_len, const struct in6_addr *next_hop);
+extern int rpl_dag_purge_targets_by_nexthop(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *addr);
+extern int rpl_dag_purge_targets_by_dev(struct rpl_dag *dag, struct net_device *dev);
+
+extern int lollipop_greater_than(int a, int b);
+extern int ipv6_get_global_addr(struct net_device *dev, struct in6_addr *addr,
+		    unsigned char banned_flags);
+#endif /* RPL_DAG_H_ */
diff --git a/include/net/rpl/rpl_debug.h b/include/net/rpl/rpl_debug.h
new file mode 100644
index 0000000..ac04238
--- /dev/null
+++ b/include/net/rpl/rpl_debug.h
@@ -0,0 +1,51 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file icmpv6_rpl_debug.h
+ *
+ * @date Jul 23, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#ifndef ICMPV6_RPL_DEBUG_H_
+#define ICMPV6_RPL_DEBUG_H_
+
+#ifdef CONFIG_IPV6_RPL
+
+#include <net/rpl/rpl_internals.h>
+
+//#define RPL_CONFIG_DEBUG_NETDEV
+
+#ifdef RPL_CONFIG_DEBUG_NETDEV
+extern int netdev_debug;
+extern void __dev_hold(struct net_device *, const char *);
+extern void __dev_put(struct net_device *, const char *);
+
+#define dev_hold(dev)	__dev_hold(dev, __FUNCTION__)
+#define dev_put(dev)	__dev_put(dev, __FUNCTION__)
+#else
+#define dev_hold(dev)	dev_hold(dev)
+#define dev_put(dev)	dev_put(dev)
+#endif
+
+
+extern void icmpv6_rpl_print_msg(struct rpl_msg *msg, size_t len);
+
+extern ssize_t icmpv6_rpl_print_option(__u8 *offset);
+
+//void rpl_msg_buf_print(struct rpl_msg_buf *rpl_msg_buf);
+
+#endif /* CONFIG_IPV6_RPL */
+
+#endif /* ICMPV6_RPL_DEBUG_H_ */
diff --git a/include/net/rpl/rpl_internals.h b/include/net/rpl/rpl_internals.h
new file mode 100644
index 0000000..b38ab72
--- /dev/null
+++ b/include/net/rpl/rpl_internals.h
@@ -0,0 +1,352 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_internals.h
+ *
+ * @date Jul 22, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#ifndef RPL_INTERNALS_H_
+#define RPL_INTERNALS_H_
+
+#ifdef CONFIG_IPV6_RPL
+
+#define RPL_DIO_IS_GROUNDED(x) ((x & 0x80) >> 7)
+#define RPL_DIO_MOP(x) ((x & 0x38) >> 3)
+#define RPL_DIO_Prf(x) ((x & 0x07) >> 0)
+
+#define RPL_DAO_FLAGS(x) ((x & 0x3F) >> 0)
+#define RPL_DAO_K(x) ((x & 0x80) >> 7)
+#define RPL_DAO_D(x) ((x & 0x40) >> 6)
+
+#define RPL_DAO_ACK_Reserved(x) ((x & 0x3F) >> 0)
+#define RPL_DAO_ACK_D(x) ((x & 0x80) >> 7)
+
+#define RPL_CC_Flags(x) ((x & 0x3F) >> 0)
+#define RPL_CC_IS_RESPONSE(x) ((x & 0x80) >> 7)
+
+#define RPL_RIO_Prf(x) ((x & 0x18) >> 3)
+
+#define RPL_TIO_E(x) ((x & 0x80) >> 7)
+
+#define RPL_SIO_V(x) ((x & 0x80) >> 7)
+#define RPL_SIO_I(x) ((x & 0x40) >> 6)
+#define RPL_SIO_D(x) ((x & 0x20) >> 5)
+
+#define RPL_PIO_L(x) ((x & 0x80) >> 7)
+#define RPL_PIO_A(x) ((x & 0x40) >> 6)
+#define RPL_PIO_R(x) ((x & 0x20) >> 5)
+
+#define RPL_DCO_Flags(x) ((x & 0xF0) >> 4)
+#define RPL_DCO_A(x) ((x & 0x08) >> 3)
+#define RPL_DCO_PCS(x) ((x & 0x07) >> 0)
+
+#include <linux/skbuff.h>
+#include <linux/timer.h>
+#include <linux/list.h>
+#include <linux/leds.h>
+#include <net/rpl/rpl_dag.h>
+
+//extern struct workqueue_struct	*rpl_rx_wq;
+
+//DEFINE_LED_TRIGGER_GLOBAL(ledtrig_rpl_joined);
+extern struct led_trigger *ledtrig_rpl_joined;
+
+//extern struct mutex rpl_enabled_devices_list_mutex;
+//extern struct list_head rpl_enabled_devices_list_head;
+//
+//extern struct mutex rpl_dags_list_mutex;
+//extern struct list_head rpl_dags_list_head;
+
+#include <net/if_inet6.h>
+
+struct rpl_base_option {
+	__u8	type;
+	__u8	length;
+};
+
+struct rpl_option_pad1 {
+	__u8	type;
+};
+
+struct rpl_option_padn {
+	struct	rpl_base_option	base;
+	__u8	zeros[0];
+};
+
+struct rpl_option_dag_metric_container {
+	struct	rpl_base_option	base;
+	__u8	data[0];
+};
+
+struct rpl_option_route_information {
+	struct	rpl_base_option	base;
+	__u8	prefix_length;
+	__u8	Resvd_Prf_Resvd;	// prefix flags
+	__be32	route_lifetime;
+	__u8	prefix[0];
+};
+
+struct rpl_option_dodag_configuration {
+	struct	rpl_base_option base;
+	__u8	flags_A_PCS;
+	__u8	DIOIntDoubl;
+	__u8	DIOIntMin;
+	__u8	DIORedun;
+	__be16	MaxRankIncrease;
+	__be16	MinHopRankIncrease;
+	__be16	OCP;
+	__u8	reserved;
+	__u8	def_lifetime;
+	__be16	lifetime_unit;
+};
+
+struct rpl_option_rpl_target {
+	struct	rpl_base_option base;
+	__u8	reserved;
+	__u8	prefix_length;
+	__u8	prefix[0];
+};
+
+struct rpl_option_transit_information {
+	struct	rpl_base_option base;
+	__u8	E_flags;
+	__u8	path_control;
+	__u8	path_sequence;
+	__u8	path_lifetime;
+	struct	in6_addr	parent;
+};
+
+struct rpl_option_solicited_information {
+	struct	rpl_base_option base;
+	__u8	instanceID;
+	__u8	VID_flags;
+	struct	in6_addr	dodagid;
+	__u8	version;
+};
+
+struct rpl_option_prefix_information {
+	struct	rpl_base_option base;
+	__u8	prefix_length;
+	__u8	LAR_reserved1;	// prefix flags
+	__be32	valid_lifetime;
+	__be32	preferred_lifetime;
+	__be32	reserved2;
+	union {
+		struct	in6_addr address;
+		__u8	prefix[0];
+	};
+};
+
+struct rpl_option_rpl_target_descriptor {
+	struct	rpl_base_option base;
+	__be32	descriptor;
+};
+
+typedef union rpl_option {
+	struct rpl_option_pad1 pad1;
+	struct rpl_option_padn padn;
+	struct rpl_option_dag_metric_container dag_metric_container;
+	struct rpl_option_route_information route_information;
+	struct rpl_option_dodag_configuration dodag_configuration;
+	struct rpl_option_rpl_target rpl_target;
+	struct rpl_option_transit_information transit_information;
+	struct rpl_option_solicited_information solicited_information;
+	struct rpl_option_prefix_information prefix_information;
+	struct rpl_option_rpl_target_descriptor rpl_target_descriptor;
+} u_rpl_option;
+
+struct rpl_base_dis {
+	__u8 flags;
+	__u8 reserved;
+	u_rpl_option dis_options[0];
+};
+
+struct rpl_base_dio {
+	__u8	instanceID;
+	__u8	version;
+	__be16	rank;
+	__u8	g_mop_prf;
+	__u8	DTSN;
+	__u8	flags;
+	__u8	reserved;
+	struct in6_addr	dodagid;
+	u_rpl_option dio_options[0];
+};
+
+struct rpl_base_dao {
+	__u8	instanceID;
+	__u8	KD_flags;
+	__u8	reserved;
+	__u8	DAOSequence;
+	union {
+		struct dao_with_dodagid {
+			struct in6_addr	dodagid;
+			u_rpl_option dao_options[0];
+		} u_with_dodagid;
+		struct dao_no_dodagid {
+			u_rpl_option dao_options[0];
+		} u_no_dodagid;
+	};
+};
+
+struct rpl_base_dao_ack {
+	__u8	instanceID;
+	__u8	D_reserved;
+	__u8	DAOSequence;
+	__u8	status;
+	union {
+		struct doa_ack_with_dodagid {
+			struct in6_addr	dodagid;
+			u_rpl_option dao_ack_options[0];
+		} u_with_dodagid;
+		struct doa_ack_no_dodagid {
+			u_rpl_option dao_ack_options[0];
+		} u_no_dodagid;
+	};
+};
+
+struct rpl_base_cc {
+	__u8	instanceID;
+	__u8	R_flags;
+	__be16	CCNonce;
+	struct	in6_addr	dodagid;
+	__be32	dest_counter;
+	u_rpl_option cc_options[0];
+};
+
+typedef union rpl_base	{
+	struct rpl_base_dis 	dis;
+	struct rpl_base_dio 	dio;
+	struct rpl_base_dao 	dao;
+	struct rpl_base_dao_ack	dao_ack;
+	struct rpl_base_cc		cc;
+} u_icmpv6_rpl_base;
+
+struct rpl_msg {
+    __u8	icmp6_type;   /* type field */
+    __u8	icmp6_code;   /* code field */
+    __sum16	icmp6_cksum;  /* checksum field */
+
+	u_icmpv6_rpl_base	base;
+};
+
+struct rpl_enabled_device {
+	struct list_head	enabled_list;
+	//struct inet6_dev	*idev;
+	struct net_device	*dev;
+	struct timer_list	dis_timer;
+	bool				joined_mc;
+	//FIXME how many solicited information could we add to an enabled device??
+	struct rpl_option_solicited_information *solicited_information;
+};
+
+struct sk_buff *icmpv6_rpl_dis_new(struct net_device *dev);
+struct sk_buff *icmpv6_rpl_dio_new(
+		struct net_device *dev,
+		__u8 instanceID,
+		__u8 version,
+		rpl_rank_t rank,
+		bool g,
+		__u8 mop,
+		__u8 prf,
+		__u8 DTSN,
+		struct in6_addr *dodagid);
+struct sk_buff *icmpv6_rpl_dao_new(
+		struct net_device *dev,
+		__u8 instanceID,
+		__u8 expect_DAO_ACK,
+		__u8 DAOSequence,
+		struct in6_addr *dodagid);
+struct sk_buff *icmpv6_rpl_dao_ack_new(
+		struct net_device *dev,
+		__u8 instanceID,
+		__u8 DAOSequence,
+		__u8 status,
+		const struct in6_addr *dodagid);
+struct sk_buff *icmpv6_rpl_cc_new(
+		struct net_device *dev,
+		__u8 instanceID,
+		__u8 is_response,
+		__u16 CCNonce,
+		struct in6_addr *dodagid,
+		__u32 dest_counter);
+
+struct sk_buff *icmpv6_rpl_add_option_pad1(struct sk_buff *rpl_msg_buf);
+struct sk_buff *icmpv6_rpl_add_option_padn(struct sk_buff *rpl_msg_buf, __u8 n);
+struct sk_buff *icmpv6_rpl_add_option_dag_metric_container(struct sk_buff *rpl_msg_buf, __u8 *metric_data, __u8 metric_data_len);
+struct sk_buff *icmpv6_rpl_add_option_route_information(struct sk_buff *rpl_msg_buf, __u8 prefix_length, __u8 prf, __u32 route_lifetime, __u8 prefix[16]);
+struct sk_buff *icmpv6_rpl_add_option_dodag_configuration(
+		struct sk_buff *rpl_msg_buf,
+		bool auth,
+		__u8 PCS,
+		__u8 DIOIntDoubl,
+		__u8 DIOIntMin,
+		__u8 DIORedun,
+		rpl_rank_t MaxRankIncrease,
+		rpl_rank_t MinHopRankIncrease,
+		rpl_ocp_t OCP,
+		__u8 def_lifetime,
+		__u16 lifetime_unit);
+struct sk_buff *icmpv6_rpl_add_option_rpl_target(struct sk_buff *rpl_msg_buf,__u8 prefix_length,__u8 target_prefix[16]);
+struct sk_buff *icmpv6_rpl_add_option_transit_information(struct sk_buff *rpl_msg_buf,__u8 external, __u8 path_control, __u8 path_sequence, __u8 path_lifetime, struct in6_addr *parent_address);
+struct sk_buff *icmpv6_rpl_add_option_solicited_information(
+		struct sk_buff *rpl_msg_buf,
+		__u8 instanceID,
+		__u8 version_predicate,
+		__u8 instanceID_predicate,
+		__u8 DODAGID_predicate,
+		struct in6_addr *dodagid,
+		__u8 version);
+struct sk_buff *icmpv6_rpl_add_option_prefix_information(
+		struct sk_buff *rpl_msg_buf,
+		__u8 prefix_length,
+		__u8 on_link,
+		__u8 autonomous,
+		__u8 router_address,
+		__u32	valid_lifetime,
+		__u32	preferred_lifetime,
+		__u8 prefix[16]);
+struct sk_buff *icmpv6_rpl_add_option_rpl_target_descriptor(struct sk_buff *rpl_msg_buf,__u32 descriptor);
+
+int icmpv6_rpl_is_option_allowed(__u8 message_type, __u8 option_type);
+
+extern u_rpl_option *icmpv6_rpl_option_get_next(u_rpl_option *first, u_rpl_option *current_option, size_t len);
+
+extern __u8 icmpv6_rpl_option_get_code(u_rpl_option *option);
+
+extern __u8 icmpv6_rpl_option_get_length(u_rpl_option *option);
+
+extern u_rpl_option *icmpv6_rpl_find_option(struct sk_buff *skb, __u8 req_type);
+
+extern int rpl_start(struct rpl_dag_conf *cfg, struct net_device *dev);
+
+extern int rpl_stop(struct net_device *dev);
+
+extern int rpl_send_dis(struct rpl_enabled_device *enabled_device);
+
+extern int rpl_send_dio(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *daddr, bool add_dodag_conf_option, bool poison);
+
+extern int rpl_send_dao(struct rpl_dag *dag, struct net_device *dev, bool allnodes, bool no_path);
+
+extern int rpl_recv_dis(struct net_device *dev,struct sk_buff *skb);
+
+extern int rpl_recv_dio(struct net_device *dev,struct sk_buff *skb);
+
+extern int rpl_recv_dao(struct net_device *dev,struct sk_buff *skb);
+
+#endif /* CONFIG_IPV6_RPL */
+
+#endif /* RPL_INTERNALS_H_ */
diff --git a/include/net/rpl/rpl_of.h b/include/net/rpl/rpl_of.h
new file mode 100644
index 0000000..d86fd83
--- /dev/null
+++ b/include/net/rpl/rpl_of.h
@@ -0,0 +1,40 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_of.h
+ *
+ * @date Aug 20, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#ifndef RPL_OF_H_
+#define RPL_OF_H_
+
+#include <net/rpl/rpl_constants.h>
+#include <net/rpl/rpl_types.h>
+
+/*
+ * Objective Function Interface
+ */
+extern struct rpl_of *rpl_of_alloc(rpl_ocp_t ocp, struct rpl_of_ops *ops);
+extern void rpl_of_free(struct rpl_of *of);
+extern int rpl_of_register(struct rpl_of *of);
+extern void rpl_of_unregister(struct rpl_of *of);
+extern struct rpl_of *rpl_of_get(rpl_ocp_t ocp);
+extern rpl_rank_t rpl_of_calculate_rank(struct rpl_of *of, struct rpl_node *parent,
+		rpl_rank_t base, int *err);
+extern int rpl_of_compare_nodes(struct rpl_of *of, struct rpl_node *p1,
+		struct rpl_node *p2, int *err);
+
+#endif /* RPL_OF_H_ */
diff --git a/include/net/rpl/rpl_trickle.h b/include/net/rpl/rpl_trickle.h
new file mode 100644
index 0000000..27c3ca4
--- /dev/null
+++ b/include/net/rpl/rpl_trickle.h
@@ -0,0 +1,66 @@
+/*
+ *	Trickle Timer: The Trickle Algorithm (RFC6206)
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_trickle.h
+ *
+ * @date Jul 30, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#ifndef RPL_TRICKLE_H_
+#define RPL_TRICKLE_H_
+
+#ifdef CONFIG_IPV6_RPL
+
+#include <linux/sched.h>	// for task_struct
+
+struct trickle_timer {
+	struct mutex		lock;
+
+	// Imin, Imax, I and t fields are MILISECONDS
+
+	unsigned long 		Imin;	// Imin: minimum interval size (default 100 ms)
+	unsigned long 		Imax;	// Imax: maximum interval size, expressed in the number of doubling of the minimum interval size (default 16, that is 6553.6 seconds)
+	int 				k;		// k: redundancy constant
+
+	unsigned long		I;
+	int					c;
+	unsigned long		t;
+
+	struct task_struct	*task;
+	void				(*trickle_fn)(unsigned long arg);
+	unsigned long		trickle_fn_arg;
+};
+
+extern struct trickle_timer *
+trickle_new(
+		unsigned long Imin,
+		unsigned long Imax,
+		int k,
+		void (*trickle_fn)(unsigned long arg),
+		unsigned long trickle_fn_arg);
+
+extern void trickle_free(struct trickle_timer *trickle);
+
+extern int trickle_start(struct trickle_timer *trickle);
+
+extern int trickle_stop(struct trickle_timer *trickle);
+
+extern int trickle_hear_consistent(struct trickle_timer *trickle);
+
+extern int trickle_hear_inconsistent(struct trickle_timer *trickle);
+
+#endif /* CONFIG_IPV6_RPL */
+
+#endif /* RPL_TRICKLE_H_ */
diff --git a/include/net/rpl/rpl_types.h b/include/net/rpl/rpl_types.h
new file mode 100644
index 0000000..7a3ff51
--- /dev/null
+++ b/include/net/rpl/rpl_types.h
@@ -0,0 +1,242 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_types.h
+ *
+ * @date Aug 20, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#ifndef RPL_TYPES_H_
+#define RPL_TYPES_H_
+
+#include <linux/types.h>
+#include <linux/in6.h>
+#include <linux/list.h>
+#include <linux/mutex.h>
+#include <linux/timer.h>
+#include <net/if_inet6.h>
+#include <net/addrconf.h>
+#include <net/rpl/rpl_trickle.h>
+
+typedef __u16 rpl_ocp_t;
+typedef __u16 rpl_rank_t;
+
+/*
+ * Rank Comparison (DAGRank())
+ */
+#define DAGRank(rank, dag) \
+  ((rank) / (dag)->MinHopRankIncrease)
+
+#define RPL_LOLLIPOP_MAX_VALUE				255
+#define RPL_LOLLIPOP_CIRCULAR_REGION		127
+#define RPL_LOLLIPOP_SEQUENCE_WINDOW		16
+#define RPL_LOLLIPOP_INIT                (RPL_LOLLIPOP_MAX_VALUE - RPL_LOLLIPOP_SEQUENCE_WINDOW + 1)
+#define RPL_LOLLIPOP_INCREMENT(counter)                                 \
+  do {                                                                  \
+    if((counter) > RPL_LOLLIPOP_CIRCULAR_REGION) {                      \
+      (counter) = ((counter) + 1) & RPL_LOLLIPOP_MAX_VALUE;             \
+    } else {                                                            \
+      (counter) = ((counter) + 1) & RPL_LOLLIPOP_CIRCULAR_REGION;       \
+    }                                                                   \
+  } while(0)
+
+#define RPL_LOLLIPOP_IS_INIT(counter)		\
+  ((counter) > RPL_LOLLIPOP_CIRCULAR_REGION)
+
+struct rpl_instance {
+	/* Instances list_head link */
+	struct list_head	instances_list;
+	struct net 			*net;
+
+	__u8				instanceID;
+
+	/* Objective Function */
+	struct rpl_of		*of;
+
+	/* Automatic generated on operation
+	 * otherwise, it means that was created by user configuration
+	 * */
+	bool				auto_gen;
+
+	atomic_t			refcnt;
+};
+
+struct rpl_dag_conf {
+	bool use_defaults;
+	bool root;
+	bool grounded;
+
+	/*
+	 * DODAG Root router config
+	 */
+	__u8 DIOIntDoubl;
+	__u8 DIOIntMin;
+	__u8 DIORedun;
+	__u8 PCS;
+	rpl_rank_t MinHopRankIncrease;
+	__u8 preference;
+	struct in6_addr dodagid;
+	//FIXME @see http://tools.ietf.org/html/rfc6550#section-18.2.5
+
+	/*
+	 * Every Router config
+	 */
+	rpl_ocp_t ocp;
+	__u8 instanceID;
+	__u8 mop;
+	struct prefix_info 	prefix_info;
+
+	//FIXME @see http://tools.ietf.org/html/rfc6550#section-18.2.3
+
+	/*
+	 * Non-DODAG-Root router config
+	 */
+	//FIXME @see http://tools.ietf.org/html/rfc6550#section-18.2.4
+};
+
+struct rpl_dag {
+	/* Dodags list_head link (used by struct instance) */
+	struct list_head 	dag_list;
+
+	/* respective instance */
+	struct rpl_instance *instance;
+
+	/* DODAG Id */
+	struct in6_addr		dodagid;
+
+	__u8				version;
+	rpl_rank_t			rank;
+	__u8				DAOSequence;
+
+	bool				is_root;
+
+	bool				grounded;
+	__u8				mop;
+	__u8				preference;
+	__u8				DTSN;
+
+	int					unreachable_counter;
+
+	struct trickle_timer	*dio_timer;
+
+	struct timer_list	dao_timer;
+	struct workqueue_struct		*dao_tx_wq;
+
+	bool				authenticated;
+	__u8				PCS;
+	__u8 				DIOIntDoubl;
+	__u8				DIOIntMin;
+	__u8				DIORedun;
+	rpl_rank_t			MaxRankIncrease;
+	rpl_rank_t			MinHopRankIncrease;
+	__u8				def_lifetime;
+	__u16				lifetime_unit;
+	struct prefix_info	*prefix_info;
+
+	struct mutex		parents_lock;
+	struct list_head	dodag_parents;	// list of rpl_node's
+	struct list_head	neighbours;	// list of rpl_node's
+
+	struct list_head	targets_head;
+
+	/* Automatic generated on operation
+	 * otherwise, it means that was created by user configuration
+	 * */
+	bool				auto_gen;
+
+	/* Interfaces allowed to join this dag
+	 * */
+	struct list_head	allowed_interfaces;	/* list of struct rpl_allowed_if */
+
+	atomic_t			refcnt;
+};
+
+struct rpl_allowed_if {
+	struct list_head	allowed_if_list;
+	//struct inet6_dev	*idev;
+	struct net_device	*dev;
+
+	bool				enabled;
+
+	/* Automatic generated on operation
+	 * otherwise, it means that was created by user configuration
+	 * */
+	bool				auto_gen;
+
+	__u8				node_addr_path_sequence;
+	struct in6_addr		global_addr;
+};
+
+struct rpl_node {
+	/* nodes list_head link */
+	struct list_head	node_list;
+
+	struct rpl_dag		*dag;
+
+	__u8				metric_link;
+
+	/* storing mode elements */
+	struct in6_addr		addr;
+	//struct inet6_dev	*idev;
+	struct net_device	*dev;
+
+	bool				is_dao_parent;
+	bool				is_dodag_parent;
+	bool				is_preferred;
+
+	rpl_rank_t			rank;
+	__u8				dtsn;
+};
+
+struct rpl_target_transit_info {
+	struct list_head transit_info_list;
+	//struct inet6_dev *idev;
+	struct net_device *dev;
+	struct in6_addr next_hop;
+	bool			installed;
+	bool			one_hop;
+	__u8 DAOSequence;
+	__u8 path_sequence;
+	__u8 path_lifetime;
+	__u8 path_control;
+};
+
+struct rpl_target {
+	struct list_head	target_list;
+	__u8				prefix_len;
+	struct in6_addr		prefix;
+	struct list_head	transit_head;
+	__u32 target_descriptor;
+};
+
+struct rpl_of {
+	/* Objective Functions list_head link */
+	struct list_head 	of_list;
+	rpl_ocp_t 			ocp;
+	struct rpl_of_ops	*ops;
+};
+
+struct rpl_of_ops {
+	struct module	*owner;
+	void (*reset)(struct rpl_dag *dag);
+	void (*parent_state_callback)(struct rpl_node *parent, void *data);
+	struct rpl_node *(*best_parent)(struct rpl_node *parent1, struct rpl_node *parent2);
+	int (*compare_nodes)(struct rpl_node *n1, struct rpl_node *n2);
+	struct rpl_dag *(*best_dag)(struct rpl_dag *dag1, struct rpl_dag *dag2);
+	rpl_rank_t (*calculate_rank)(struct rpl_node *node, rpl_rank_t base);
+	void (*update_metric_container)(struct rpl_instance *instance);
+};
+
+#endif /* RPL_TYPES_H_ */
diff --git a/include/uapi/linux/ipv6.h b/include/uapi/linux/ipv6.h
index 4bda4cf..1867385 100644
--- a/include/uapi/linux/ipv6.h
+++ b/include/uapi/linux/ipv6.h
@@ -160,6 +160,13 @@ enum {
 	DEVCONF_ACCEPT_DAD,
 	DEVCONF_FORCE_TLLAO,
 	DEVCONF_NDISC_NOTIFY,
+#ifdef CONFIG_IPV6_RPL
+	DEVCONF_RPL_ENABLED,
+	DEVCONF_RPL_JOINED,
+	DEVCONF_RPL_DODAG_ROOT,
+	DEVCONF_RPL_DODAGID,
+	DEVCONF_RPL_ICMP_DUMP,
+#endif /* CONFIG_IPV6_RPL */
 	DEVCONF_MAX
 };
 
diff --git a/net/ipv6/Kconfig b/net/ipv6/Kconfig
index 11b13ea..aea9c68 100644
--- a/net/ipv6/Kconfig
+++ b/net/ipv6/Kconfig
@@ -66,6 +66,51 @@ config IPV6_OPTIMISTIC_DAD
 
 	  If unsure, say N.
 
+config IPV6_RPL
+	bool "RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks (RFC 6550) support"
+	select IPV6_RPL_OF_OF0
+	---help---
+	  This is experimental support of RPL protocol.
+
+	  Low-Power and Lossy Networks (LLNs) are a class of network in which
+	  both the routers and their interconnect are constrained.  LLN routers
+	  typically operate with constraints on processing power, memory, and
+	  energy (battery power).  Their interconnects are characterized by
+	  high loss rates, low data rates, and instability.  LLNs are comprised
+	  of anything from a few dozen to thousands of routers.  Supported
+	  traffic flows include point-to-point (between devices inside the
+	  LLN), point-to-multipoint (from a central control point to a subset
+	  of devices inside the LLN), and multipoint-to-point (from devices
+	  inside the LLN towards a central control point).  This document
+	  specifies the IPv6 Routing Protocol for Low-Power and Lossy Networks
+	  (RPL), which provides a mechanism whereby multipoint-to-point traffic
+	  from devices inside the LLN towards a central control point as well
+	  as point-to-multipoint traffic from the central control point to the
+	  devices inside the LLN are supported.  Support for point-to-point
+	  traffic is also available.
+
+	  http://tools.ietf.org/html/rfc6550
+
+	  If unsure, say N.
+
+config IPV6_RPL_OF_OF0
+	tristate "RPL: Objective Function Zero for the Routing Protocol for Low-Power and Lossy Networks (RFC 6552)"
+	depends on IPV6_RPL
+	---help---
+	  This is experimental support of RPL protocol.
+
+	  The Routing Protocol for Low-Power and Lossy Networks (RPL)
+	  specification defines a generic Distance Vector protocol that is
+	  adapted to a variety of network types by the application of specific
+	  Objective Functions (OFs).  An OF states the outcome of the process
+	  used by a RPL node to select and optimize routes within a RPL
+	  Instance based on the Information Objects available; an OF is not an
+	  algorithm.
+
+	  http://tools.ietf.org/html/rfc6552
+
+	  If unsure, say N.
+
 config INET6_AH
 	tristate "IPv6: AH transformation"
 	select XFRM_ALGO
diff --git a/net/ipv6/Makefile b/net/ipv6/Makefile
index 470a9c0..78c5ccc 100644
--- a/net/ipv6/Makefile
+++ b/net/ipv6/Makefile
@@ -9,6 +9,7 @@ ipv6-objs :=	af_inet6.o anycast.o ip6_output.o ip6_input.o addrconf.o \
 		route.o ip6_fib.o ipv6_sockglue.o ndisc.o udp.o udplite.o \
 		raw.o icmp.o mcast.o reassembly.o tcp_ipv6.o ping.o \
 		exthdrs.o datagram.o ip6_flowlabel.o inet6_connection_sock.o
+		
 
 ipv6-offload :=	ip6_offload.o tcpv6_offload.o udp_offload.o exthdrs_offload.o
 
@@ -22,6 +23,11 @@ ipv6-$(CONFIG_IPV6_MULTIPLE_TABLES) += fib6_rules.o
 ipv6-$(CONFIG_PROC_FS) += proc.o
 ipv6-$(CONFIG_SYN_COOKIES) += syncookies.o
 
+ipv6-$(CONFIG_IPV6_RPL) += rpl/rpl_trickle.o rpl/rpl_debug.o rpl/rpl_dag.o \
+	rpl/rpl_icmp6.o rpl/rpl.o rpl/netlink.o rpl/nl_policy.o rpl/nl-dag-conf.o \
+	rpl/nl-dag-info.o rpl/nl-dag-mng.o
+obj-$(CONFIG_IPV6_RPL_OF_OF0) += rpl_of_of0.o
+
 ipv6-objs += $(ipv6-y)
 
 obj-$(CONFIG_INET6_AH) += ah6.o
diff --git a/net/ipv6/addrconf.c b/net/ipv6/addrconf.c
index 498ea99..76e362b 100644
--- a/net/ipv6/addrconf.c
+++ b/net/ipv6/addrconf.c
@@ -36,6 +36,7 @@
  *	YOSHIFUJI Hideaki @USAGI	:	improved source address
  *						selection; consider scope,
  *						status etc.
+ *	João Pedro Taveira			:	added RPL support
  */
 
 #define pr_fmt(fmt) "IPv6: " fmt
@@ -88,6 +89,10 @@
 #include <linux/random.h>
 #endif
 
+#ifdef CONFIG_IPV6_RPL
+#include <net/rpl/rpl.h>
+#endif
+
 #include <linux/uaccess.h>
 #include <asm/unaligned.h>
 
@@ -202,6 +207,13 @@ static struct ipv6_devconf ipv6_devconf __read_mostly = {
 	.accept_source_route	= 0,	/* we do not accept RH0 by default. */
 	.disable_ipv6		= 0,
 	.accept_dad		= 1,
+
+#ifdef CONFIG_IPV6_RPL
+	.rpl_enabled = 0,
+	.rpl_joined = 0,
+	.rpl_dodag_root = 0,
+	.rpl_icmp_dump = 0,
+#endif
 };
 
 static struct ipv6_devconf ipv6_devconf_dflt __read_mostly = {
@@ -236,6 +248,12 @@ static struct ipv6_devconf ipv6_devconf_dflt __read_mostly = {
 	.accept_source_route	= 0,	/* we do not accept RH0 by default. */
 	.disable_ipv6		= 0,
 	.accept_dad		= 1,
+#ifdef CONFIG_IPV6_RPL
+	.rpl_enabled = 0,
+	.rpl_joined = 0,
+	.rpl_dodag_root = 0,
+	.rpl_icmp_dump = 0,
+#endif
 };
 
 /* IPv6 Wildcard Address and Loopback Address defined by RFC2553 */
@@ -438,6 +456,7 @@ static struct inet6_dev *ipv6_add_dev(struct net_device *dev)
 	if (ndev->cnf.forwarding && (dev->flags & IFF_MULTICAST))
 		ipv6_dev_mc_inc(dev, &in6addr_linklocal_allrouters);
 
+
 	return ndev;
 }
 
@@ -5003,6 +5022,36 @@ static struct addrconf_sysctl_table
 			.mode           = 0644,
 			.proc_handler   = proc_dointvec
 		},
+#ifdef CONFIG_IPV6_RPL
+		{
+			.procname       = "rpl_enabled",
+			.data           = &ipv6_devconf.rpl_enabled,
+			.maxlen         = sizeof(int),
+			.mode           = 0644,
+			.proc_handler   = rpl_sysctl_rpl_enabled
+		},
+		{
+			.procname       = "rpl_joined",
+			.data           = &ipv6_devconf.rpl_joined,
+			.maxlen         = sizeof(int),
+			.mode           = 0644,
+			.proc_handler   = rpl_sysctl_rpl_joined
+		},
+		{
+			.procname       = "rpl_dodag_root",
+			.data           = &ipv6_devconf.rpl_dodag_root,
+			.maxlen         = sizeof(int),
+			.mode           = 0644,
+			.proc_handler   = rpl_sysctl_rpl_dodag_root
+		},
+		{
+			.procname       = "rpl_icmp_dump",
+			.data           = &ipv6_devconf.rpl_icmp_dump,
+			.maxlen         = sizeof(int),
+			.mode           = 0644,
+			.proc_handler   = rpl_sysctl_rpl_icmp_dump
+		},
+#endif /* CONFIG_IPV6_RPL */
 		{
 			/* sentinel */
 		}
diff --git a/net/ipv6/af_inet6.c b/net/ipv6/af_inet6.c
index a5ac969..b79ba7d 100644
--- a/net/ipv6/af_inet6.c
+++ b/net/ipv6/af_inet6.c
@@ -943,9 +943,18 @@ static int __init inet6_init(void)
 	if (err)
 		goto sysctl_fail;
 #endif
+#ifdef CONFIG_IPV6_RPL
+	err = rpl_init();
+	if (err)
+		goto rpl_fail;
+#endif
 out:
 	return err;
 
+#ifdef CONFIG_IPV6_RPL
+rpl_fail:
+	rpl_cleanup();
+#endif
 #ifdef CONFIG_SYSCTL
 sysctl_fail:
 	ipv6_packet_cleanup();
@@ -1024,6 +1033,9 @@ static void __exit inet6_exit(void)
 	tcpv6_exit();
 
 	/* Cleanup code parts. */
+#ifdef CONFIG_IPV6_RPL
+	rpl_cleanup();
+#endif
 	ipv6_packet_cleanup();
 	ipv6_frag_exit();
 	ipv6_exthdrs_exit();
diff --git a/net/ipv6/icmp.c b/net/ipv6/icmp.c
index 7cfc8d2..0cf4521 100644
--- a/net/ipv6/icmp.c
+++ b/net/ipv6/icmp.c
@@ -27,6 +27,8 @@
  *	Randy Dunlap and
  *	YOSHIFUJI Hideaki @USAGI:	Per-interface statistics support
  *	Kazunori MIYAZAWA @USAGI:       change output process to use ip6_append_data
+ *	João Pedro Taveira		:	added RPL support
+ *
  */
 
 #define pr_fmt(fmt) "IPv6: " fmt
@@ -70,6 +72,10 @@
 
 #include <asm/uaccess.h>
 
+#ifdef CONFIG_IPV6_RPL
+#include <net/rpl/rpl.h>
+#endif /* CONFIG_IPV6_RPL */
+
 /*
  *	The ICMP socket(s). This is the most convenient way to flow control
  *	our ICMP output as well as maintain a clean interface throughout
@@ -712,13 +718,24 @@ static int icmpv6_rcv(struct sk_buff *skb)
 		}
 	}
 
+	/*
+	 * The smallest RPL message has 6 bytes, which fails next validation
+	 * because sizeof(*hdr) is 8 bytes
+	 * */
+#ifndef CONFIG_IPV6_RPL
 	if (!pskb_pull(skb, sizeof(*hdr)))
 		goto discard_it;
+#endif /* CONFIG_IPV6_RPL */
 
 	hdr = icmp6_hdr(skb);
 
 	type = hdr->icmp6_type;
 
+#ifdef CONFIG_IPV6_RPL
+	if (type != ICMPV6_RPL && !pskb_pull(skb, sizeof(*hdr)))
+		goto discard_it;
+#endif /* CONFIG_IPV6_RPL */
+
 	ICMP6MSGIN_INC_STATS_BH(dev_net(dev), idev, type);
 
 	switch (type) {
@@ -758,6 +775,12 @@ static int icmpv6_rcv(struct sk_buff *skb)
 		ndisc_rcv(skb);
 		break;
 
+#ifdef CONFIG_IPV6_RPL
+	case ICMPV6_RPL:
+		rpl_rcv(skb);
+		break;
+#endif /* CONFIG_IPV6_RPL */
+
 	case ICMPV6_MGM_QUERY:
 		igmp6_event_query(skb);
 		break;
diff --git a/net/ipv6/rpl/netlink.c b/net/ipv6/rpl/netlink.c
new file mode 100644
index 0000000..4fa4947
--- /dev/null
+++ b/net/ipv6/rpl/netlink.c
@@ -0,0 +1,137 @@
+/*
+ *  Netlink inteface
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *  Sergey Lapin <slapin@ossfans.org>
+ *  Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>
+ *  Maxim Osipov <maxim.osipov@siemens.com>
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License.
+ */
+
+#include <linux/kernel.h>
+#include <linux/gfp.h>
+#include <net/genetlink.h>
+#include <linux/rpl_nl.h>
+
+#include "nlrpl.h"
+
+#include <net/rpl/rpl_debug.h>
+
+static unsigned int rpl_seq_num;
+static DEFINE_SPINLOCK(rpl_seq_lock);
+
+struct genl_family nlrpl_family = {
+	.id		= GENL_ID_GENERATE,
+	.hdrsize	= 0,
+	.name		= RPL_NL_NAME,
+	.version	= 1,
+	.maxattr	= RPL_ATTR_MAX,
+	.netnsok	= true
+};
+
+/* Requests to userspace */
+struct sk_buff *rpl_nl_create(int flags, u8 req)
+{
+	void *hdr;
+	struct sk_buff *msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_ATOMIC);
+	unsigned long f;
+
+	if (!msg)
+		return NULL;
+
+	spin_lock_irqsave(&rpl_seq_lock, f);
+	hdr = genlmsg_put(msg, 0, rpl_seq_num++,
+			&nlrpl_family, flags, req);
+	spin_unlock_irqrestore(&rpl_seq_lock, f);
+	if (!hdr) {
+		nlmsg_free(msg);
+		return NULL;
+	}
+
+	return msg;
+}
+
+int rpl_nl_mcast(struct sk_buff *msg, unsigned int group)
+{
+	struct nlmsghdr *nlh = nlmsg_hdr(msg);
+	void *hdr = genlmsg_data(nlmsg_data(nlh));
+
+	if (genlmsg_end(msg, hdr) < 0)
+		goto out;
+
+	return genlmsg_multicast(msg, 0, group, GFP_ATOMIC);
+out:
+	nlmsg_free(msg);
+	return -ENOBUFS;
+}
+
+struct sk_buff *rpl_nl_new_reply(struct genl_info *info,
+		int flags, u8 req)
+{
+	void *hdr;
+	struct sk_buff *msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_ATOMIC);
+
+	if (!msg)
+		return NULL;
+
+	hdr = genlmsg_put_reply(msg, info,
+			&nlrpl_family, flags, req);
+	if (!hdr) {
+		nlmsg_free(msg);
+		return NULL;
+	}
+
+	return msg;
+}
+
+int rpl_nl_reply(struct sk_buff *msg, struct genl_info *info)
+{
+	struct nlmsghdr *nlh = nlmsg_hdr(msg);
+	void *hdr = genlmsg_data(nlmsg_data(nlh));
+
+	if (genlmsg_end(msg, hdr) < 0)
+		goto out;
+
+	return genlmsg_reply(msg, info);
+out:
+	nlmsg_free(msg);
+	return -ENOBUFS;
+}
+
+int __init rpl_nl_init(void)
+{
+	int rc;
+
+	rc = genl_register_family(&nlrpl_family);
+	if (rc)
+		goto fail;
+
+	rc = nlrpl_dag_conf_register();
+	if (rc)
+		goto fail;
+	rc = nlrpl_dag_info_register();
+	if (rc)
+		goto fail;
+	rc = nlrpl_dag_mng_register();
+	if (rc)
+		goto fail;
+
+	return 0;
+
+fail:
+	genl_unregister_family(&nlrpl_family);
+	return rc;
+}
+
+void __exit rpl_nl_exit(void)
+{
+	genl_unregister_family(&nlrpl_family);
+}
+
diff --git a/net/ipv6/rpl/nl-dag-conf.c b/net/ipv6/rpl/nl-dag-conf.c
new file mode 100644
index 0000000..ba7630d
--- /dev/null
+++ b/net/ipv6/rpl/nl-dag-conf.c
@@ -0,0 +1,615 @@
+/*
+ *  Netlink inteface
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License.
+ */
+
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <net/netlink.h>
+#include <net/genetlink.h>
+#include <linux/rpl_nl.h>
+
+#include <net/rpl/rpl_internals.h>
+#include <net/rpl/rpl_debug.h>
+#include <net/rpl/rpl_dag.h>
+
+#include "nlrpl.h"
+
+/*
+ * List DAGs Functions
+ */
+
+static int rpl_nl_fill_dag(struct sk_buff *msg, u32 portid,
+	u32 seq, int flags, struct rpl_dag *dag)
+{
+	void *hdr;
+
+	pr_debug("%s\n", __func__);
+
+	hdr = genlmsg_put(msg, 0, seq, &nlrpl_family, flags,
+		RPL_LIST_DAG);
+	if (!hdr)
+		goto out;
+
+	if(nla_put_u8(msg,RPL_ATTR_INSTANCE_ID,dag->instance->instanceID) ||
+			nla_put_u16(msg,RPL_ATTR_OCP,dag->instance->of->ocp) ||
+			nla_put(msg,RPL_ATTR_DODAG_ID,sizeof(struct in6_addr),&dag->dodagid) ||
+			nla_put_u8(msg,RPL_ATTR_VERSION,dag->version) ||
+			nla_put_u8(msg,RPL_ATTR_GROUNDED,dag->grounded) ||
+			nla_put_u8(msg,RPL_ATTR_MOP,dag->mop) ||
+			nla_put_u8(msg,RPL_ATTR_DTSN,dag->DTSN) ||
+			nla_put_u16(msg,RPL_ATTR_RANK,dag->rank) ||
+			nla_put_u8(msg,RPL_ATTR_DAO_SEQUENCE,dag->DAOSequence) ||
+			nla_put_u8(msg,RPL_ATTR_PCS,dag->PCS) ||
+			nla_put_u16(msg,RPL_ATTR_MIN_HOP_RANK_INCR,dag->MinHopRankIncrease) ||
+			nla_put_u8(msg,RPL_ATTR_IS_ROOT,dag->is_root))
+		goto nla_put_failure;
+
+	return genlmsg_end(msg, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(msg, hdr);
+out:
+	return -EMSGSIZE;
+}
+
+static int rpl_list_dag(struct sk_buff *skb,
+	struct genl_info *info)
+{
+	struct net *net;
+	struct sk_buff *msg;
+	struct in6_addr dodagid;
+	__u8 instanceID;
+	struct rpl_dag *dag;
+	int rc = -ENOBUFS;
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DODAG_ID])
+		return -EINVAL;
+	if (!info->attrs[RPL_ATTR_INSTANCE_ID])
+		return -EINVAL;
+
+	instanceID = nla_get_u8(info->attrs[RPL_ATTR_INSTANCE_ID]);
+
+	nla_memcpy(&dodagid,info->attrs[RPL_ATTR_DODAG_ID],nla_len(info->attrs[RPL_ATTR_DODAG_ID]));
+
+	net = genl_info_net(info);
+	dag = rpl_dag_find(net,instanceID,&dodagid);
+	if (!dag)
+		return -EADDRNOTAVAIL;
+
+	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+	if (!msg)
+		goto out_dag;
+
+	rc = rpl_nl_fill_dag(msg, info->snd_portid, info->snd_seq,
+			0, dag);
+	if (rc < 0)
+		goto out_free;
+
+	rpl_dag_put(dag);
+
+	return genlmsg_reply(msg, info);
+out_free:
+	nlmsg_free(msg);
+out_dag:
+	rpl_dag_put(dag);
+	return rc;
+
+}
+
+struct dump_dag_data {
+	struct sk_buff *skb;
+	struct netlink_callback *cb;
+	int idx, s_idx;
+};
+
+static int rpl_dump_dag_iter(struct rpl_dag *dag, void *_data)
+{
+	int rc;
+	struct dump_dag_data *data = _data;
+
+	pr_debug("%s\n", __func__);
+
+	if (data->idx++ < data->s_idx)
+		return 0;
+
+	rc = rpl_nl_fill_dag(data->skb,
+			NETLINK_CB(data->cb->skb).portid,
+			data->cb->nlh->nlmsg_seq,
+			NLM_F_MULTI,
+			dag);
+
+	if (rc < 0) {
+		data->idx--;
+		return rc;
+	}
+
+	return 0;
+}
+
+static int rpl_dump_dag(struct sk_buff *skb,
+	struct netlink_callback *cb)
+{
+	struct net *net = sock_net(skb->sk);
+	struct rpl_dag *dag;
+	struct dump_dag_data data = {
+		.cb = cb,
+		.skb = skb,
+		.s_idx = cb->args[0],
+		.idx = 0,
+	};
+
+	pr_debug("%s\n", __func__);
+
+	mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+		rpl_dump_dag_iter(dag,&data);
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+
+	cb->args[0] = data.idx;
+	return skb->len;
+}
+
+/*
+ * List Enabled Interfaces Functions
+ */
+
+static int rpl_nl_fill_enabled_device(struct sk_buff *msg, u32 portid,
+	u32 seq, int flags, struct rpl_enabled_device *enabled_device)
+{
+	void *hdr;
+
+	pr_debug("%s\n", __func__);
+
+	hdr = genlmsg_put(msg, 0, seq, &nlrpl_family, flags,
+		RPL_LIST_IFACE);
+	if (!hdr)
+		goto out;
+
+	//FIXME we should add RPL_ATTR_DEV_ENABLED and RPL_ATTR_DEV_AUTOGEN
+	if(nla_put_string(msg,RPL_ATTR_DEV_NAME,enabled_device->dev->name) ||
+		nla_put_u8(msg,RPL_ATTR_DEV_ENABLED,true))
+		goto nla_put_failure;
+
+	return genlmsg_end(msg, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(msg, hdr);
+out:
+	return -EMSGSIZE;
+}
+
+static int rpl_list_iface(struct sk_buff *skb,
+	struct genl_info *info)
+{
+	struct net *net;
+	struct sk_buff *msg;
+	int rc = -ENOBUFS;
+	const char *dev_name;
+	struct rpl_enabled_device *enabled_device;
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DEV_NAME])
+		return -EINVAL;
+
+	dev_name = nla_data(info->attrs[RPL_ATTR_DEV_NAME]);
+	if (dev_name[nla_len(info->attrs[RPL_ATTR_DEV_NAME]) - 1] != '\0')
+		return -EINVAL; /* dev name should be null-terminated */
+
+	if (strlen(dev_name) >= IFNAMSIZ)
+		return -ENAMETOOLONG;
+
+	net = genl_info_net(info);
+	enabled_device = rpl_enabled_device_find_by_name(net,dev_name);
+	if (!enabled_device)
+		return -ENXIO;
+
+	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+	if (!msg)
+		goto out_dev;
+
+	rc = rpl_nl_fill_enabled_device(msg, info->snd_portid, info->snd_seq,
+			0, enabled_device);
+	if (rc < 0)
+		goto out_free;
+
+	return genlmsg_reply(msg, info);
+out_free:
+	nlmsg_free(msg);
+out_dev:
+	return rc;
+
+}
+
+static int rpl_dump_iface_iter(struct rpl_enabled_device *enabled_device, void *_data)
+{
+	int rc;
+	struct dump_dag_data *data = _data;
+
+	pr_debug("%s\n", __func__);
+
+	if (data->idx++ < data->s_idx)
+		return 0;
+
+	rc = rpl_nl_fill_enabled_device(data->skb,
+			NETLINK_CB(data->cb->skb).portid,
+			data->cb->nlh->nlmsg_seq,
+			NLM_F_MULTI,
+			enabled_device);
+
+	if (rc < 0) {
+		data->idx--;
+		return rc;
+	}
+
+	return 0;
+}
+
+static int rpl_dump_iface(struct sk_buff *skb,
+	struct netlink_callback *cb)
+{
+	struct net *net = sock_net(skb->sk);
+	struct rpl_enabled_device *enabled_device;
+	struct dump_dag_data data = {
+		.cb = cb,
+		.skb = skb,
+		.s_idx = cb->args[0],
+		.idx = 0,
+	};
+
+	pr_debug("%s\n", __func__);
+
+	mutex_lock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+	list_for_each_entry(enabled_device,&net->ipv6.rpl.rpl_enabled_devices_list_head,enabled_list){
+		rpl_dump_iface_iter(enabled_device,&data);
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+
+	cb->args[0] = data.idx;
+
+	return skb->len;
+}
+
+/*
+ * Enable interface(s)
+ */
+
+static int rpl_enable_iface(struct sk_buff *skb,
+	struct genl_info *info)
+{
+	struct sk_buff *msg;
+	int rc = -ENOBUFS;
+	const char *dev_name;
+	struct net_device *dev;
+	struct net *net;
+	struct inet6_dev *idev;
+	struct rpl_enabled_device *enabled_device;
+	//struct rpl_dag_conf cfg; //FIXME we must populate cfg
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DEV_NAME])
+		return -EINVAL;
+
+	dev_name = nla_data(info->attrs[RPL_ATTR_DEV_NAME]);
+	if (dev_name[nla_len(info->attrs[RPL_ATTR_DEV_NAME]) - 1] != '\0')
+		return -EINVAL; /* dev name should be null-terminated */
+
+	if (strlen(dev_name) >= IFNAMSIZ)
+		return -ENAMETOOLONG;
+
+	net = genl_info_net(info);
+	dev = dev_get_by_name(net, dev_name);
+	if(!dev)
+		return -ENODEV;
+
+	if (dev->flags & IFF_LOOPBACK){
+		dev_put(dev);
+		return -EINVAL;
+	}
+
+	idev = in6_dev_get(dev);
+	if(!idev){
+		dev_put(dev);
+		return -ENODEV;
+	}
+
+	//rc = rpl_start(&cfg,idev);
+	rc = rpl_start(NULL,dev);
+	if(rc < 0){
+		in6_dev_put(idev);
+		dev_put(dev);
+		goto out_dev;
+	}
+
+	in6_dev_put(idev);
+	idev = NULL;
+	dev_put(dev);
+	dev = NULL;
+
+	enabled_device = rpl_enabled_device_find_by_name(net,dev_name);
+	if (!enabled_device)
+		return -ENXIO;
+
+	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+	if (!msg)
+		goto out_dev;
+
+	rc = rpl_nl_fill_enabled_device(msg, info->snd_portid, info->snd_seq,
+			0, enabled_device);
+	if (rc < 0)
+		goto out_free;
+
+	return genlmsg_reply(msg, info);
+out_free:
+	nlmsg_free(msg);
+out_dev:
+	return rc;
+
+}
+
+static int rpl_enable_ifaces(struct sk_buff *skb,
+	struct netlink_callback *cb)
+{
+	struct net *net = sock_net(skb->sk);
+	int h, s_h;
+	int idx;
+	int s_idx;
+	struct net_device *dev;
+	struct inet6_dev *idev;
+	struct hlist_head *head;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 9, 0))
+	struct hlist_node *node;
+#endif
+	int rc = -ENOBUFS;
+	struct rpl_enabled_device *enabled_device;
+	//struct rpl_dag_conf cfg; //FIXME we must populate cfg
+
+	pr_debug("%s\n", __func__);
+
+	s_h = cb->args[0];
+	s_idx = idx = cb->args[1];
+
+	rcu_read_lock();
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 9, 0))
+#else
+	cb->seq = atomic_read(&net->ipv6.dev_addr_genid) ^ net->dev_base_seq;
+#endif
+
+	for (h = s_h; h < NETDEV_HASHENTRIES; h++, s_idx = 0) {
+		idx = 0;
+		head = &net->dev_index_head[h];
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 9, 0))
+		hlist_for_each_entry_rcu(dev, node, head, index_hlist) {
+#else
+		hlist_for_each_entry_rcu(dev, head, index_hlist) {
+#endif
+			if (idx < s_idx)
+				goto cont;
+			idev = __in6_dev_get(dev);
+			if (!idev)
+				goto cont;
+
+			if (dev->flags & IFF_LOOPBACK)
+				goto cont;
+
+			//rc = rpl_start(&cfg,idev);
+			rc = rpl_start(NULL,dev);
+			if(rc < 0){
+				pr_debug("%s: error starting RPL on %s\n", __func__,idev->dev->name);
+				goto done;
+			}
+
+			enabled_device = rpl_enabled_device_get(dev);
+			if (!enabled_device){
+				pr_debug("%s: enabled device not found %s\n", __func__,idev->dev->name);
+				goto done;
+			}
+
+			rc = rpl_nl_fill_enabled_device(skb,
+					NETLINK_CB(skb).portid, cb->nlh->nlmsg_seq,
+					NLM_F_MULTI, enabled_device);
+			if (rc < 0){
+				pr_debug("%s: error filling enabled device %s\n", __func__,idev->dev->name);
+				goto done;
+			}
+cont:
+			idx++;
+		}
+	}
+done:
+	rcu_read_unlock();
+
+	cb->args[0] = h;
+	cb->args[1] = idx;
+
+	return skb->len;
+}
+
+/*
+ * Disable interface(s)
+ */
+
+static int rpl_disable_iface(struct sk_buff *skb,
+	struct genl_info *info)
+{
+	struct net *net;
+	struct sk_buff *msg;
+	int rc = -ENOBUFS;
+	const char *dev_name;
+	struct net_device *dev;
+	struct inet6_dev *idev;
+	//struct rpl_enabled_device *enabled_device;
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DEV_NAME])
+		return -EINVAL;
+
+	dev_name = nla_data(info->attrs[RPL_ATTR_DEV_NAME]);
+	if (dev_name[nla_len(info->attrs[RPL_ATTR_DEV_NAME]) - 1] != '\0')
+		return -EINVAL; /* dev name should be null-terminated */
+
+	if (strlen(dev_name) >= IFNAMSIZ)
+		return -ENAMETOOLONG;
+
+	net = genl_info_net(info);
+	dev = dev_get_by_name(net, dev_name);
+	if(!dev)
+		return -ENODEV;
+
+	if (dev->flags & IFF_LOOPBACK){
+		dev_put(dev);
+		return -EINVAL;
+	}
+
+	idev = in6_dev_get(dev);
+	if(!idev){
+		dev_put(dev);
+		return -ENODEV;
+	}
+
+	rc = rpl_stop(dev);
+	if(rc < 0){
+		in6_dev_put(idev);
+		dev_put(dev);
+		goto out_dev;
+	}
+
+	in6_dev_put(idev);
+	idev = NULL;
+	dev_put(dev);
+	dev = NULL;
+
+	msg = rpl_nl_new_reply(info, 0, RPL_LIST_IFACE);
+	if (!msg)
+		goto out_dev;
+
+	return genlmsg_reply(msg, info);
+	nlmsg_free(msg);
+out_dev:
+	return rc;
+
+}
+
+static int rpl_disable_ifaces(struct sk_buff *skb,
+	struct netlink_callback *cb)
+{
+	struct net *net = sock_net(skb->sk);
+	int h, s_h;
+	int idx;
+	int s_idx;
+	struct net_device *dev;
+	struct inet6_dev *idev;
+	struct hlist_head *head;
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 9, 0))
+	struct hlist_node *node;
+#endif
+	int rc = -ENOBUFS;
+	struct rpl_enabled_device *enabled_device;
+
+	pr_debug("%s\n", __func__);
+
+	//see inet6_dump_addr() on addrconf.c:4000
+
+	s_h = cb->args[0];
+	s_idx = idx = cb->args[1];
+
+	rcu_read_lock();
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 9, 0))
+#else
+	cb->seq = atomic_read(&net->ipv6.dev_addr_genid) ^ net->dev_base_seq;
+#endif
+
+	for (h = s_h; h < NETDEV_HASHENTRIES; h++, s_idx = 0) {
+		idx = 0;
+		head = &net->dev_index_head[h];
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 9, 0))
+		hlist_for_each_entry_rcu(dev, node, head, index_hlist) {
+#else
+		hlist_for_each_entry_rcu(dev, head, index_hlist) {
+#endif
+			if (idx < s_idx)
+				goto cont;
+
+			if (dev->flags & IFF_LOOPBACK)
+				goto cont;
+
+			idev = __in6_dev_get(dev);
+			if (!idev)
+				goto cont;
+
+			rc = rpl_stop(dev);
+			if(rc < 0){
+				pr_debug("%s: error starting RPL on %s\n", __func__,idev->dev->name);
+				goto done;
+			}
+
+			enabled_device = rpl_enabled_device_get(dev);
+			if (!enabled_device){
+				pr_debug("%s: enabled device not found %s\n", __func__,idev->dev->name);
+				goto done;
+			}
+
+			rc = rpl_nl_fill_enabled_device(skb,
+					NETLINK_CB(skb).portid, cb->nlh->nlmsg_seq,
+					NLM_F_MULTI, enabled_device);
+			if (rc < 0){
+				pr_debug("%s: error filling enabled device %s\n", __func__,idev->dev->name);
+				goto done;
+			}
+cont:
+			idx++;
+		}
+	}
+done:
+	rcu_read_unlock();
+
+	cb->args[0] = h;
+	cb->args[1] = idx;
+
+	return skb->len;
+}
+
+/*
+ * Operations
+ */
+
+static struct genl_ops nlrpl_dag_conf_ops[] = {
+	RPL_DUMP(RPL_LIST_DAG, rpl_list_dag,rpl_dump_dag),
+	RPL_DUMP(RPL_LIST_IFACE, rpl_list_iface,rpl_dump_iface),
+	RPL_DUMP(RPL_ENABLE_IFACE, rpl_enable_iface,rpl_enable_ifaces),
+	RPL_DUMP(RPL_DISABLE_IFACE, rpl_disable_iface,rpl_disable_ifaces),
+};
+
+/*
+ * No need to unregister as family unregistration will do it.
+ */
+int nlrpl_dag_conf_register(void)
+{
+	int i;
+	int rc;
+
+	for (i = 0; i < ARRAY_SIZE(nlrpl_dag_conf_ops); i++) {
+		rc = genl_register_ops(&nlrpl_family,
+				&nlrpl_dag_conf_ops[i]);
+		if (rc)
+			return rc;
+	}
+
+	return 0;
+}
diff --git a/net/ipv6/rpl/nl-dag-info.c b/net/ipv6/rpl/nl-dag-info.c
new file mode 100644
index 0000000..6d0ea0a
--- /dev/null
+++ b/net/ipv6/rpl/nl-dag-info.c
@@ -0,0 +1,376 @@
+/*
+ *  Netlink inteface
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License.
+ */
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <net/netlink.h>
+#include <net/genetlink.h>
+#include <linux/rpl_nl.h>
+
+#include <net/rpl/rpl_debug.h>
+#include <net/rpl/rpl_internals.h>
+#include <net/rpl/rpl_dag.h>
+
+#include "nlrpl.h"
+
+/*
+ * Nodes Dump Functions
+ */
+
+static int rpl_nl_dag_fill_node(u8 cmd, struct sk_buff *msg, u32 portid,
+	u32 seq, int flags, struct rpl_dag *dag, struct rpl_node *node)
+{
+	void *hdr;
+
+	pr_debug("%s\n", __func__);
+
+	hdr = genlmsg_put(msg, 0, seq, &nlrpl_family, flags,cmd);
+	if (!hdr)
+		goto out;
+
+	if(nla_put_u8(msg,RPL_ATTR_INSTANCE_ID,dag->instance->instanceID) ||
+			nla_put(msg,RPL_ATTR_DODAG_ID,sizeof(struct in6_addr),&dag->dodagid) ||
+			nla_put(msg,RPL_ATTR_NODE_ADDR,sizeof(struct in6_addr),&node->addr) ||
+			nla_put_string(msg,RPL_ATTR_DEV_NAME,node->dev->name) ||
+			nla_put_u8(msg,RPL_ATTR_IS_DODAG_PARENT,node->is_dodag_parent) ||
+			nla_put_u8(msg,RPL_ATTR_IS_PREFERRED,node->is_preferred) ||
+			nla_put_u8(msg,RPL_ATTR_IS_DAO_PARENT,node->is_dao_parent) ||
+			nla_put_u8(msg,RPL_ATTR_DTSN,node->dtsn) ||
+			nla_put_u16(msg,RPL_ATTR_RANK,node->rank))
+		goto nla_put_failure;
+
+	return genlmsg_end(msg, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(msg, hdr);
+out:
+	return -EMSGSIZE;
+}
+
+static int rpl_dag_list_nodes(u8 cmd, struct sk_buff *skb,
+	struct genl_info *info)
+{
+	struct net *net;
+	struct sk_buff *msg;
+	struct in6_addr dodagid;
+	__u8 instanceID;
+	struct rpl_dag *dag;
+	struct rpl_node *node;
+	struct list_head *node_list;
+	int rc = -ENOBUFS;
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DODAG_ID])
+		return -EINVAL;
+	if (!info->attrs[RPL_ATTR_INSTANCE_ID])
+		return -EINVAL;
+
+	instanceID = nla_get_u8(info->attrs[RPL_ATTR_INSTANCE_ID]);
+
+	nla_memcpy(&dodagid,info->attrs[RPL_ATTR_DODAG_ID],nla_len(info->attrs[RPL_ATTR_DODAG_ID]));
+
+	net = genl_info_net(info);
+	dag = rpl_dag_find(net,instanceID,&dodagid);
+	if (!dag)
+		return -EADDRNOTAVAIL;
+
+	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+	if (!msg)
+		goto out_dag;
+
+	if(cmd == RPL_LIST_PARENTS)
+		node_list = &dag->dodag_parents;
+	else if(cmd == RPL_LIST_NEIGHBORS)
+		node_list = &dag->neighbours;
+	else
+		goto out_free;
+
+	mutex_lock(&dag->parents_lock);
+	list_for_each_entry(node,node_list,node_list){
+		rc = rpl_nl_dag_fill_node(cmd,msg,info->snd_portid,info->snd_seq,
+				NLM_F_MULTI,dag,node);
+		if (rc < 0) {
+			mutex_unlock(&dag->parents_lock);
+			goto out_free;
+		}
+	}
+	mutex_unlock(&dag->parents_lock);
+
+	rpl_dag_put(dag);
+
+	return genlmsg_reply(msg, info);
+out_free:
+	nlmsg_free(msg);
+out_dag:
+	rpl_dag_put(dag);
+	return rc;
+
+}
+
+static int rpl_dag_list_parents(struct sk_buff *skb,
+	struct genl_info *info)
+{
+	return rpl_dag_list_nodes(RPL_LIST_PARENTS,skb,info);
+}
+
+static int rpl_dag_list_neighbors(struct sk_buff *skb,
+	struct genl_info *info)
+{
+	return rpl_dag_list_nodes(RPL_LIST_NEIGHBORS,skb,info);
+}
+
+struct dump_dag_data {
+	u8 cmd;
+	struct sk_buff *skb;
+	struct netlink_callback *cb;
+	int idx, s_idx;
+};
+
+static int rpl_dag_dump_node_iter(struct rpl_dag *dag, void *_data)
+{
+	int rc;
+	struct dump_dag_data *data = _data;
+	struct rpl_node *node;
+	struct list_head *node_list;
+
+	pr_debug("%s\n", __func__);
+
+	if (data->idx++ < data->s_idx)
+		return 0;
+
+	if(data->cmd == RPL_LIST_PARENTS)
+		node_list = &dag->dodag_parents;
+	else if(data->cmd == RPL_LIST_NEIGHBORS)
+		node_list = &dag->neighbours;
+	else
+		return -EINVAL;
+
+	mutex_lock(&dag->parents_lock);
+	list_for_each_entry(node,node_list,node_list){
+		rc = rpl_nl_dag_fill_node(data->cmd,data->skb,
+				NETLINK_CB(data->cb->skb).portid,
+				data->cb->nlh->nlmsg_seq,
+				NLM_F_MULTI,
+				dag,node);
+
+		if (rc < 0) {
+			data->idx--;
+			mutex_unlock(&dag->parents_lock);
+			return rc;
+		}
+	}
+	mutex_unlock(&dag->parents_lock);
+	return 0;
+}
+
+static int rpl_dag_dump_nodes(u8 cmd, struct sk_buff *skb,
+	struct netlink_callback *cb)
+{
+	struct net *net = sock_net(skb->sk);
+	struct rpl_dag *dag;
+	struct dump_dag_data data = {
+		.cmd = cmd,
+		.cb = cb,
+		.skb = skb,
+		.s_idx = cb->args[0],
+		.idx = 0,
+	};
+
+	pr_debug("%s\n", __func__);
+
+	mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+		rpl_dag_dump_node_iter(dag,&data);
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+
+	cb->args[0] = data.idx;
+
+	return skb->len;
+}
+
+static int rpl_dag_dump_parents(struct sk_buff *skb,
+	struct netlink_callback *cb)
+{
+	return rpl_dag_dump_nodes(RPL_LIST_PARENTS,skb,cb);
+}
+
+static int rpl_dag_dump_neighbors(struct sk_buff *skb,
+	struct netlink_callback *cb)
+{
+	return rpl_dag_dump_nodes(RPL_LIST_NEIGHBORS,skb,cb);
+}
+
+/*
+ * Targets/Downward Routes Dump Functions
+ */
+
+static int rpl_nl_dag_fill_downward_route(struct sk_buff *msg, u32 portid,
+	u32 seq, int flags, struct rpl_dag *dag, struct rpl_target *target)
+{
+	void *hdr;
+	struct rpl_target_transit_info *transit_info;
+
+	pr_debug("%s\n", __func__);
+
+	hdr = genlmsg_put(msg, 0, seq, &nlrpl_family, flags,RPL_LIST_DOWNWARD_ROUTES);
+	if (!hdr)
+		goto out;
+
+	transit_info = rpl_target_get_installed(target);
+	if(!transit_info)
+		goto nla_put_failure;
+
+	if(nla_put_u8(msg,RPL_ATTR_INSTANCE_ID,dag->instance->instanceID) ||
+			nla_put(msg,RPL_ATTR_DODAG_ID,sizeof(struct in6_addr),&dag->dodagid) ||
+			nla_put(msg,RPL_ATTR_PREFIX,sizeof(struct in6_addr),&target->prefix) ||
+			nla_put_u8(msg,RPL_ATTR_PREFIX_LEN,target->prefix_len) ||
+			nla_put(msg,RPL_ATTR_NEXT_HOP,sizeof(struct in6_addr),&transit_info->next_hop) ||
+			nla_put_string(msg,RPL_ATTR_DEV_NAME,transit_info->dev->name) ||
+			nla_put_u8(msg,RPL_ATTR_ONE_HOP,transit_info->one_hop))
+		goto nla_put_failure;
+
+	return genlmsg_end(msg, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(msg, hdr);
+out:
+	return -EMSGSIZE;
+}
+
+static int rpl_dag_dump_downward_routes_iter(struct rpl_dag *dag, void *_data)
+{
+	int rc;
+	struct dump_dag_data *data = _data;
+	struct rpl_target *target;
+
+	pr_debug("%s\n", __func__);
+
+	if (data->idx++ < data->s_idx)
+		return 0;
+
+	list_for_each_entry(target,&dag->targets_head,target_list){
+		rc = rpl_nl_dag_fill_downward_route(data->skb,
+				NETLINK_CB(data->cb->skb).portid,
+				data->cb->nlh->nlmsg_seq,
+				NLM_F_MULTI,
+				dag,target);
+
+		if (rc < 0) {
+			data->idx--;
+			return rc;
+		}
+	}
+	return 0;
+}
+
+static int rpl_dag_list_downward_routes(struct sk_buff *skb,
+	struct genl_info *info)
+{
+	struct net *net;
+	struct sk_buff *msg;
+	struct in6_addr dodagid;
+	__u8 instanceID;
+	struct rpl_dag *dag;
+	struct rpl_target *target;
+	int rc = -ENOBUFS;
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DODAG_ID])
+		return -EINVAL;
+	if (!info->attrs[RPL_ATTR_INSTANCE_ID])
+		return -EINVAL;
+
+	instanceID = nla_get_u8(info->attrs[RPL_ATTR_INSTANCE_ID]);
+
+	nla_memcpy(&dodagid,info->attrs[RPL_ATTR_DODAG_ID],nla_len(info->attrs[RPL_ATTR_DODAG_ID]));
+
+	net = genl_info_net(info);
+	dag = rpl_dag_find(net,instanceID,&dodagid);
+	if (!dag)
+		return -EADDRNOTAVAIL;
+
+	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+	if (!msg)
+		goto out_dag;
+
+	list_for_each_entry(target,&dag->targets_head,target_list){
+		rc = rpl_nl_dag_fill_downward_route(msg,info->snd_portid,info->snd_seq,
+				NLM_F_MULTI,dag,target);
+		if (rc < 0) {
+			goto out_free;
+		}
+	}
+
+	rpl_dag_put(dag);
+
+	return genlmsg_reply(msg, info);
+out_free:
+	nlmsg_free(msg);
+out_dag:
+	rpl_dag_put(dag);
+	return rc;
+
+}
+
+static int rpl_dag_dump_downward_routes(struct sk_buff *skb,
+	struct netlink_callback *cb)
+{
+	struct net *net = sock_net(skb->sk);
+	struct rpl_dag *dag;
+	struct dump_dag_data data = {
+		.cb = cb,
+		.skb = skb,
+		.s_idx = cb->args[0],
+		.idx = 0,
+	};
+
+	pr_debug("%s\n", __func__);
+
+	mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+		rpl_dag_dump_downward_routes_iter(dag,&data);
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+
+	cb->args[0] = data.idx;
+
+	return skb->len;
+}
+
+static struct genl_ops nlrpl_dag_info_ops[] = {
+	RPL_DUMP(RPL_LIST_PARENTS, rpl_dag_list_parents,rpl_dag_dump_parents),
+	RPL_DUMP(RPL_LIST_NEIGHBORS, rpl_dag_list_neighbors,rpl_dag_dump_neighbors),
+	RPL_DUMP(RPL_LIST_DOWNWARD_ROUTES, rpl_dag_list_downward_routes,rpl_dag_dump_downward_routes),
+};
+
+/*
+ * No need to unregister as family unregistration will do it.
+ */
+int nlrpl_dag_info_register(void)
+{
+	int i;
+	int rc;
+
+	for (i = 0; i < ARRAY_SIZE(nlrpl_dag_info_ops); i++) {
+		rc = genl_register_ops(&nlrpl_family,
+				&nlrpl_dag_info_ops[i]);
+		if (rc)
+			return rc;
+	}
+
+	return 0;
+}
diff --git a/net/ipv6/rpl/nl-dag-mng.c b/net/ipv6/rpl/nl-dag-mng.c
new file mode 100644
index 0000000..625d667
--- /dev/null
+++ b/net/ipv6/rpl/nl-dag-mng.c
@@ -0,0 +1,214 @@
+/*
+ *  Netlink inteface
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License.
+ */
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <net/netlink.h>
+#include <net/genetlink.h>
+#include <linux/rpl_nl.h>
+
+#include <net/rpl/rpl_debug.h>
+#include <net/rpl/rpl_internals.h>
+#include <net/rpl/rpl_dag.h>
+
+#include "nlrpl.h"
+
+/*
+ * Global Repair
+ */
+
+static int rpl_dag_global_repair(struct sk_buff *skb,
+		struct genl_info *info)
+{
+	struct net *net;
+	struct sk_buff *msg;
+	struct in6_addr dodagid;
+	__u8 instanceID;
+	struct rpl_dag *dag;
+	int rc = -ENOBUFS;
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DODAG_ID])
+		return -EINVAL;
+	if (!info->attrs[RPL_ATTR_INSTANCE_ID])
+		return -EINVAL;
+
+	instanceID = nla_get_u8(info->attrs[RPL_ATTR_INSTANCE_ID]);
+
+	nla_memcpy(&dodagid,info->attrs[RPL_ATTR_DODAG_ID],nla_len(info->attrs[RPL_ATTR_DODAG_ID]));
+
+	net = genl_info_net(info);
+	dag = rpl_dag_find(net,instanceID,&dodagid);
+	if (!dag)
+		return -EADDRNOTAVAIL;
+
+	msg = rpl_nl_new_reply(info, 0, RPL_GLOBAL_REPAIR);
+	if (!msg)
+		goto out_dag;
+
+	RPL_LOLLIPOP_INCREMENT(dag->version);
+	rc = rpl_dag_inconsistent(dag);
+	if(rc < 0)
+		goto out_free;
+
+	if (nla_put_u8(msg,RPL_ATTR_INSTANCE_ID,dag->instance->instanceID) ||
+		nla_put(msg,RPL_ATTR_DODAG_ID,sizeof(struct in6_addr),&dag->dodagid) ||
+		nla_put_u8(msg,RPL_ATTR_VERSION,dag->version))
+		goto out_free;
+
+	rpl_dag_put(dag);
+
+	return genlmsg_reply(msg, info);
+out_free:
+	nlmsg_free(msg);
+out_dag:
+	rpl_dag_put(dag);
+	return rc;
+}
+
+/*
+ * Local Repair
+ */
+
+static int rpl_dag_local_repair(struct sk_buff *skb,
+		struct genl_info *info)
+{
+	struct net *net;
+	struct sk_buff *msg;
+	struct in6_addr dodagid;
+	__u8 instanceID;
+	struct rpl_dag *dag;
+	int rc = -ENOBUFS;
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DODAG_ID])
+		return -EINVAL;
+	if (!info->attrs[RPL_ATTR_INSTANCE_ID])
+		return -EINVAL;
+
+	instanceID = nla_get_u8(info->attrs[RPL_ATTR_INSTANCE_ID]);
+
+	nla_memcpy(&dodagid,info->attrs[RPL_ATTR_DODAG_ID],nla_len(info->attrs[RPL_ATTR_DODAG_ID]));
+
+	net = genl_info_net(info);
+	dag = rpl_dag_find(net,instanceID,&dodagid);
+	if (!dag)
+		return -EADDRNOTAVAIL;
+
+	msg = rpl_nl_new_reply(info, 0, RPL_LOCAL_REPAIR);
+	if (!msg)
+		goto out_dag;
+
+	rc = rpl_dag_inconsistent(dag);
+	if(rc < 0)
+		goto out_free;
+
+	if (nla_put_u8(msg,RPL_ATTR_INSTANCE_ID,dag->instance->instanceID) ||
+		nla_put(msg,RPL_ATTR_DODAG_ID,sizeof(struct in6_addr),&dag->dodagid) ||
+		nla_put_u8(msg,RPL_ATTR_VERSION,dag->version))
+		goto out_free;
+
+	rpl_dag_put(dag);
+
+	return genlmsg_reply(msg, info);
+out_free:
+	nlmsg_free(msg);
+out_dag:
+	rpl_dag_put(dag);
+	return rc;
+}
+
+/*
+ * DAO Update
+ */
+
+static int rpl_dag_dao_update(struct sk_buff *skb,
+		struct genl_info *info)
+{
+	struct net *net;
+	struct sk_buff *msg;
+	struct in6_addr dodagid;
+	__u8 instanceID;
+	struct rpl_dag *dag;
+	int rc = -ENOBUFS;
+
+	pr_debug("%s\n", __func__);
+
+	if (!info->attrs[RPL_ATTR_DODAG_ID])
+		return -EINVAL;
+	if (!info->attrs[RPL_ATTR_INSTANCE_ID])
+		return -EINVAL;
+
+	instanceID = nla_get_u8(info->attrs[RPL_ATTR_INSTANCE_ID]);
+
+	nla_memcpy(&dodagid,info->attrs[RPL_ATTR_DODAG_ID],nla_len(info->attrs[RPL_ATTR_DODAG_ID]));
+
+	net = genl_info_net(info);
+	dag = rpl_dag_find(net,instanceID,&dodagid);
+	if (!dag)
+		return -EADDRNOTAVAIL;
+
+	msg = rpl_nl_new_reply(info, 0, RPL_DAO_UPDATE);
+	if (!msg)
+		goto out_dag;
+
+	RPL_LOLLIPOP_INCREMENT(dag->DTSN);
+	rc = rpl_dag_inconsistent(dag);
+	if(rc < 0)
+		goto out_free;
+
+	if (nla_put_u8(msg,RPL_ATTR_INSTANCE_ID,dag->instance->instanceID) ||
+		nla_put(msg,RPL_ATTR_DODAG_ID,sizeof(struct in6_addr),&dag->dodagid) ||
+		nla_put_u8(msg,RPL_ATTR_VERSION,dag->version))
+		goto out_free;
+
+	rpl_dag_put(dag);
+
+	return genlmsg_reply(msg, info);
+out_free:
+	nlmsg_free(msg);
+out_dag:
+	rpl_dag_put(dag);
+	return rc;
+}
+
+/*
+ * Operations
+ */
+
+static struct genl_ops nlrpl_dag_mng_ops[] = {
+		RPL_OP(RPL_GLOBAL_REPAIR,rpl_dag_global_repair),
+		RPL_OP(RPL_LOCAL_REPAIR,rpl_dag_local_repair),
+		RPL_OP(RPL_DAO_UPDATE,rpl_dag_dao_update),
+};
+
+/*
+ * No need to unregister as family unregistration will do it.
+ */
+int nlrpl_dag_mng_register(void)
+{
+	int i;
+	int rc;
+
+	for (i = 0; i < ARRAY_SIZE(nlrpl_dag_mng_ops); i++) {
+		rc = genl_register_ops(&nlrpl_family,
+				&nlrpl_dag_mng_ops[i]);
+		if (rc)
+			return rc;
+	}
+
+	return 0;
+}
diff --git a/net/ipv6/rpl/nl_policy.c b/net/ipv6/rpl/nl_policy.c
new file mode 100644
index 0000000..cebcfba
--- /dev/null
+++ b/net/ipv6/rpl/nl_policy.c
@@ -0,0 +1,64 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *  Sergey Lapin <slapin@ossfans.org>
+ *  Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>
+ *  Maxim Osipov <maxim.osipov@siemens.com>
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License.
+ */
+
+#include <linux/kernel.h>
+#include <net/netlink.h>
+#include <linux/rpl_nl.h>
+
+#define NLA_RPL_RANK NLA_U16
+
+const struct nla_policy rpl_policy[RPL_ATTR_MAX + 1] = {
+	[RPL_ATTR_DEV_NAME] = { .type = NLA_STRING, },
+	[RPL_ATTR_DEV_INDEX] = { .type = NLA_U32, },
+	[RPL_ATTR_DEV_ENABLED] = { .type = NLA_U8, },
+	[RPL_ATTR_DEV_AUTOGEN] = { .type = NLA_U8, },
+
+	[RPL_ATTR_OCP] = { .type = NLA_U16, },
+	[RPL_ATTR_INSTANCE_ID] = { .type = NLA_U8, },
+
+	[RPL_ATTR_DODAG_ID] = { .len = sizeof(struct in6_addr), },
+
+	[RPL_ATTR_RANK] = { .type = NLA_RPL_RANK, },
+	[RPL_ATTR_VERSION] = { .type = NLA_U8, },
+	[RPL_ATTR_MOP] = { .type = NLA_U8, },
+	[RPL_ATTR_DTSN] = { .type = NLA_U8, },
+	[RPL_ATTR_DAO_SEQUENCE] = { .type = NLA_U8, },
+
+	[RPL_ATTR_GROUNDED] = { .type = NLA_U8, },
+	[RPL_ATTR_IS_ROOT] = { .type = NLA_U8, },
+
+	[RPL_ATTR_PCS] = { .type = NLA_U8, },
+	[RPL_ATTR_DIO_INT_DOUBL] = { .type = NLA_U8, },
+	[RPL_ATTR_DIO_INT_MIN] = { .type = NLA_U8, },
+	[RPL_ATTR_DIO_REDUN] = { .type = NLA_U8, },
+	[RPL_ATTR_MAX_RANK_INCR] = { .type = NLA_RPL_RANK, },
+	[RPL_ATTR_MIN_HOP_RANK_INCR] = { .type = NLA_RPL_RANK, },
+
+	[RPL_ATTR_DEF_LIFETIME] = { .type = NLA_U8, },
+	[RPL_ATTR_LIFETIME_UNIT] = { .type = NLA_U16, },
+
+	[RPL_ATTR_NODE_ADDR] = { .len = sizeof(struct in6_addr), },
+	[RPL_ATTR_IS_DODAG_PARENT] = { .type = NLA_U8, },
+	[RPL_ATTR_IS_DAO_PARENT] = { .type = NLA_U8, },
+	[RPL_ATTR_IS_PREFERRED] = { .type = NLA_U8, },
+
+	[RPL_ATTR_PREFIX] = { .len = sizeof(struct in6_addr), },
+	[RPL_ATTR_PREFIX_LEN] = { .type = NLA_U8, },
+	[RPL_ATTR_NEXT_HOP] = { .len = sizeof(struct in6_addr), },
+	[RPL_ATTR_ONE_HOP] = { .type = NLA_U8, },
+
+};
+
diff --git a/net/ipv6/rpl/nlrpl.h b/net/ipv6/rpl/nlrpl.h
new file mode 100644
index 0000000..6b9ff01
--- /dev/null
+++ b/net/ipv6/rpl/nlrpl.h
@@ -0,0 +1,51 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Siemens AG (ieee802154)
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License.
+ */
+
+#ifndef NL_RPL_LOCAL_H
+#define NL_RPL_LOCAL_H
+
+int __init rpl_nl_init(void);
+void __exit rpl_nl_exit(void);
+
+#define RPL_OP(_cmd, _func)			\
+	{						\
+		.cmd	= _cmd,				\
+		.policy	= rpl_policy,		\
+		.doit	= _func,			\
+		.dumpit	= NULL,				\
+		.flags	= GENL_ADMIN_PERM,		\
+	}
+
+#define RPL_DUMP(_cmd, _func, _dump)		\
+	{						\
+		.cmd	= _cmd,				\
+		.policy	= rpl_policy,		\
+		.doit	= _func,			\
+		.dumpit	= _dump,			\
+	}
+
+struct genl_info;
+
+struct sk_buff *rpl_nl_create(int flags, u8 req);
+int rpl_nl_mcast(struct sk_buff *msg, unsigned int group);
+struct sk_buff *rpl_nl_new_reply(struct genl_info *info,
+		int flags, u8 req);
+int rpl_nl_reply(struct sk_buff *msg, struct genl_info *info);
+
+extern struct genl_family nlrpl_family;
+int nlrpl_dag_conf_register(void);
+int nlrpl_dag_info_register(void);
+int nlrpl_dag_mng_register(void);
+
+#endif /* NL_RPL_LOCAL_H */
diff --git a/net/ipv6/rpl/rpl.c b/net/ipv6/rpl/rpl.c
new file mode 100644
index 0000000..4c6e8e8
--- /dev/null
+++ b/net/ipv6/rpl/rpl.c
@@ -0,0 +1,866 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/*
+ * @file rpl.c
+ *
+ * @date Jul 25, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#define pr_fmt(fmt) "ICMPv6: " fmt
+
+#include <stddef.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/socket.h>
+#include <linux/netdevice.h>
+#include <linux/ipv6.h>
+#include <linux/timer.h>
+
+#ifdef CONFIG_SYSCTL
+#include <linux/sysctl.h>
+#endif
+
+#include <net/addrconf.h>
+#include <net/if_inet6.h>
+#include "nlrpl.h"
+#include <net/rpl/rpl_constants.h>
+#include <net/rpl/rpl_internals.h>
+#include <net/rpl/rpl_debug.h>
+#include <net/sock.h>
+#include <net/net_namespace.h>
+#include <net/inet_common.h>
+#include <net/netevent.h>
+
+#define RPL_DEBUG 3
+
+#define RPL_PRINTK(val, level, fmt, ...)				\
+do {								\
+	if (val <= RPL_DEBUG)					\
+		net_##level##_ratelimited(fmt, ##__VA_ARGS__);	\
+} while (0)
+
+DEFINE_LED_TRIGGER_GLOBAL(ledtrig_rpl_joined);
+
+/*
+ * Join inet6_dev to a DODAG as non-root
+ */
+int rpl_ipv6_join(struct net *net, struct rpl_dag_conf *cfg, struct rpl_enabled_device *enabled_device){
+	int err = -EINVAL;
+	struct rpl_dag *dag;
+	bool trigger_dio = false;
+
+	if(enabled_device){
+		if(cfg && !cfg->use_defaults){
+			dag = rpl_dag_setup_using_conf(net,cfg,&err);
+			if(!dag){
+				RPL_PRINTK(1, err,"%s(): Error configuring dag: %d\n",__func__,err);
+				goto out;
+			}
+			rpl_dag_set_allowed(dag,enabled_device->dev,true,false,&trigger_dio);
+			//FIXME add Solicited Information option to enabled device
+
+			if(dag)
+				rpl_dag_put(dag);
+		} else {
+			mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+			list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+				if(dag && dag->auto_gen){
+					rpl_dag_set_allowed(dag,enabled_device->dev,true,true,&trigger_dio);
+					if(trigger_dio){
+						rpl_dag_inconsistent(dag);
+					}
+					trigger_dio = false;
+				}
+			}
+			mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+		}
+		err = rpl_enabled_device_add_dis_timer(enabled_device);
+	}
+out:
+	return err;
+}
+
+/*
+ * Disjoin inet6_dev from all DODAG as non-root
+ */
+int rpl_ipv6_disjoin(struct net_device *dev)
+{
+	struct net *net = dev_net(dev);
+	int err = 0;
+	struct rpl_dag *dag;
+	struct list_head *dag_ptr,*dag_next;
+
+	mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	list_for_each_safe(dag_ptr,dag_next,&net->ipv6.rpl.rpl_dags_list_head){
+		dag = list_entry(dag_ptr,struct rpl_dag,dag_list);
+		//printk(KERN_DEBUG "%s(): REMOVEME checking dag %pI6 on device: %s\n",__func__,&dag->dodagid,idev->dev->name);
+		if(rpl_dag_is_allowed(dag,dev)){
+			//printk(KERN_DEBUG "%s(): REMOVEME before call dag_disjoin: %s\n",__func__,idev->dev->name);
+			err = rpl_dag_disjoin(dag,dev);
+			if(err) {
+				RPL_PRINTK(1, err,"%s(): Error poisoning dag: %d\n",__func__,err);
+			}
+		}
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	return err;
+}
+
+/*
+ * setup dodag root parameters in inet6_dev
+ */
+
+struct rpl_start_root_work {
+	struct net_device 	*dev;
+	struct work_struct 	work;
+	struct rpl_dag_conf cfg;
+};
+
+static void rpl_start_root_worker(struct work_struct *work)
+{
+	int err = 0;
+	struct rpl_start_root_work *rw = container_of(work, struct rpl_start_root_work, work);
+	if (rw->dev == NULL) {
+		RPL_PRINTK(2, warn, "%s(): dev is null\n",__func__);
+		goto out;
+	}
+	err = rpl_dag_start_root(dev_net(rw->dev),&rw->cfg,rw->dev);
+	if(err)
+	{
+		RPL_PRINTK(0,err,"%s: error starting root: %d",__func__,err);
+	}
+out:
+	dev_put(rw->dev);
+	kfree(rw);
+}
+
+int rpl_setup_dodag_root(struct net *net, struct rpl_dag_conf *cfg, struct rpl_enabled_device *enabled_device)
+{
+	int err = 0;
+	struct rpl_start_root_work *work;
+	struct in6_addr dodagid;
+
+	/*
+	 * This function must check user defined ipv6 address from dev
+	 * and start a RPL Root DODAG using such addr as DODAG ID
+	 */
+
+	err = ipv6_get_global_addr(enabled_device->dev,&dodagid,0);
+	if(err)
+	{
+		printk(KERN_DEBUG "rpl: %s: Global address not found\n",__func__);
+		goto out;
+	}
+
+	work = kzalloc(sizeof(struct rpl_start_root_work), GFP_ATOMIC);
+	if (!work)
+	{
+		err = -ENOMEM;
+		goto out;
+	}
+
+	INIT_WORK(&work->work, rpl_start_root_worker);
+	work->dev = enabled_device->dev;
+	dev_hold(enabled_device->dev);
+	if(cfg){
+		memcpy(&work->cfg,cfg,sizeof(*cfg));
+	} else {
+		rpl_dag_conf_default_init(&work->cfg);
+		work->cfg.root = true;
+		work->cfg.use_defaults = false;
+		memcpy(&work->cfg.dodagid,&dodagid,sizeof(struct in6_addr));
+
+		ipv6_addr_prefix(&work->cfg.prefix_info.prefix,&dodagid,64);
+		work->cfg.prefix_info.prefix_len = 64;
+		work->cfg.prefix_info.autoconf = true;
+		work->cfg.prefix_info.valid = 0xffffffff;
+		work->cfg.prefix_info.prefered = 0xffffffff;
+	}
+	queue_work(net->ipv6.rpl.rpl_rx_wq, &work->work);
+out:
+	return err;
+}
+
+/*
+ * Start RPL Protocol in INET6 Device
+ */
+int rpl_start(struct rpl_dag_conf *cfg, struct net_device *dev)
+{
+	struct rpl_enabled_device *enabled_device;
+	struct inet6_dev *idev;
+
+	int err = 0;
+	if(!dev)
+	{
+		RPL_PRINTK(0,err,"%s: device is NULL",__func__);
+		err = -EINVAL;
+		goto out;
+	}
+
+	idev = __in6_dev_get(dev);
+	if(!idev){
+		RPL_PRINTK(3,dbg,"%s: IPv6 is disabled",__func__);
+		err = -EINVAL;
+		goto out;
+	}
+
+	if(idev->cnf.disable_ipv6)
+	{
+		RPL_PRINTK(3,dbg,"%s: IPv6 is disabled",__func__);
+		err = -EINVAL;
+		goto out;
+	}
+
+	enabled_device = rpl_enabled_devices_list_add(dev,&err);
+	if(err || !enabled_device)
+	{
+		RPL_PRINTK(2,err,"%s: error adding dev to enabled devices list",__func__);
+		goto out;
+	}
+
+	if(!enabled_device->joined_mc){
+		RPL_PRINTK(1,dbg, "RPL: Join interface-local all-RPL-node multicast group\n");
+		err = ipv6_dev_mc_inc(dev, &in6addr_all_rpl_nodes);
+		if(err)
+		{
+			RPL_PRINTK(2,warn,"RPL: error joining interface-local all-RPL-node multicast group\n");
+			goto out;
+		}
+		enabled_device->joined_mc = true;
+	}
+
+	//TODO: should we add a "enabled" to enabled_device flag?
+	if(!idev->cnf.rpl_dodag_root){
+		err = rpl_ipv6_join(dev_net(dev),cfg,enabled_device);
+		if(err)
+		{
+			RPL_PRINTK(2,warn,"%s: error joining rpl",__func__);
+			goto out_mc_dec;
+		}
+	}
+	else if(idev->cnf.rpl_dodag_root){
+		err = rpl_setup_dodag_root(dev_net(dev),cfg,enabled_device);
+		if(err){
+			RPL_PRINTK(2,err,"%s: error setting up dodag root",__func__);
+			goto out_mc_dec;
+		}
+	}
+
+	idev->cnf.rpl_joined = 1;
+
+out:
+	return err;
+
+out_mc_dec:
+	if(enabled_device->joined_mc){
+		RPL_PRINTK(1,dbg, "RPL: Leaving interface-local all-RPL-node multicast group\n");
+		//if(__ipv6_dev_mc_dec(idev, &in6addr_all_rpl_nodes)){
+		if(ipv6_dev_mc_dec(dev, &in6addr_all_rpl_nodes)){
+			RPL_PRINTK(2,warn,"RPL: Error leaving interface-local all-RPL-node multicast group\n");
+		}
+		enabled_device->joined_mc = false;
+	}
+
+	rpl_enabled_devices_list_del(dev);
+
+	goto out;
+	return err;
+}
+
+/* FIXME when echo 0 > rpl_enabled on a interface and there's some other interface joined in same DAG
+ * dCPU: 0 PID: 2105 Comm: kworker/u2:2 Tainted: G           O 3.10.3+ #81
+dWorkqueue: eth0 rpl_rx_worker [ipv6]
+dtask: da9e8280 ti: da846000 task.ti: da846000
+PC is at __mutex_lock_slowpath+0x4c/0x144
+LR is at trickle_hear_inconsistent+0x10/0xd8 [ipv6]
+pc : [<c03e62b8>]    lr : [<bf087180>]    psr: a0000013
+sp : da847e90  ip : 00000000  fp : da814000
+r10: 0001e5dc  r9 : 00000000  r8 : d9a08a40
+r7 : da9e8280  r6 : d98f4a00  r5 : 0001e5d8  r4 : da846000
+r3 : e28ccaab  r2 : da847e94  r1 : 00000000  r0 : 0001e5d8
+Flags: NzCv  IRQs on  FIQs on  Mode SVC_32  ISA ARM  Segment kernel
+Control: 00c5387d  Table: 18944008  DAC: 00000017
+dCPU: 0 PID: 2105 Comm: kworker/u2:2 Tainted: G           O 3.10.3+ #81
+dWorkqueue: eth0 rpl_rx_worker [ipv6]
+[<c00136f0>] (unwind_backtrace+0x0/0xf0) from [<c0010b4c>] (show_stack+0x10/0x14)
+[<c0010b4c>] (show_stack+0x10/0x14) from [<c0075ce8>] (kdb_dumpregs+0x28/0x50)
+[<c0075ce8>] (kdb_dumpregs+0x28/0x50) from [<c0077f54>] (kdb_main_loop+0x3c0/0x6c0)
+[<c0077f54>] (kdb_main_loop+0x3c0/0x6c0) from [<c007a648>] (kdb_stub+0x154/0x380)
+[<c007a648>] (kdb_stub+0x154/0x380) from [<c0071818>] (kgdb_handle_exception+0x32c/0x6c0)
+[<c0071818>] (kgdb_handle_exception+0x32c/0x6c0) from [<c0012e70>] (kgdb_notify+0x24/0x40)
+[<c0012e70>] (kgdb_notify+0x24/0x40) from [<c03ea0e4>] (notifier_call_chain+0x44/0x84)
+[<c03ea0e4>] (notifier_call_chain+0x44/0x84) from [<c03ea15c>] (__atomic_notifier_call_chain+0x38/0x4c)
+[<c03ea15c>] (__atomic_notifier_call_chain+0x38/0x4c) from [<c03ea188>] (atomic_notifier_call_chain+0x18/0x20)
+[<c03ea188>] (atomic_notifier_call_chain+0x18/0x20) from [<c03ea1c8>] (notify_die+0x38/0x44)
+[<c03ea1c8>] (notify_die+0x38/0x44) from [<c0010c14>] (die+0xc4/0x3a8)
+[<c0010c14>] (die+0xc4/0x3a8) from [<c03e2ad8>] (__do_kernel_fault.part.9+0x54/0x74)
+[<c03e2ad8>] (__do_kernel_fault.part.9+0x54/0x74) from [<c0017344>] (do_bad_area+0x80/0x84)
+[<c0017344>] (do_bad_area+0x80/0x84) from [<c03ea058>] (do_translation_fault+0x60/0xa8)
+[<c03ea058>] (do_translation_fault+0x60/0xa8) from [<c000834c>] (do_DataAbort+0x34/0x98)
+[<c000834c>] (do_DataAbort+0x34/0x98) from [<c03e85f8>] (__dabt_svc+0x38/0x60)
+Exception stack(0xda847e48 to 0xda847e90)
+7e40:                   0001e5d8 00000000 da847e94 e28ccaab da846000 0001e5d8
+7e60: d98f4a00 da9e8280 d9a08a40 00000000 0001e5dc da814000 00000000 da847e90
+7e80: bf087180 c03e62b8 a0000013 ffffffff
+[<c03e85f8>] (__dabt_svc+0x38/0x60) from [<c03e62b8>] (__mutex_lock_slowpath+0x4c/0x144)
+[<c03e62b8>] (__mutex_lock_slowpath+0x4c/0x144) from [<bf087180>] (trickle_hear_inconsistent+0x10/0xd8 [ipv6])
+[<bf087180>] (trickle_hear_inconsistent+0x10/0xd8 [ipv6]) from [<bf08f128>] (rpl_ipv6_signal_inconsistency+0x1c/0x2c [ipv6])
+[<bf08f128>] (rpl_ipv6_signal_inconsistency+0x1c/0x2c [ipv6]) from [<bf08cdfc>] (rpl_recv_dis+0x88/0xac [ipv6])
+[<bf08cdfc>] (rpl_recv_dis+0x88/0xac [ipv6]) from [<bf08e408>] (rpl_rx_worker+0xcc/0x180 [ipv6])
+[<bf08e408>] (rpl_rx_worker+0xcc/0x180 [ipv6]) from [<c00364c0>] (process_one_work+0x10c/0x35c)
+[<c00364c0>] (process_one_work+0x10c/0x35c) from [<c0036b68>] (worker_thread+0x130/0x3b0)
+[<c0036b68>] (worker_thread+0x130/0x3b0) from [<c003c260>] (kthread+0xa4/0xb0)
+[<c003c260>] (kthread+0xa4/0xb0) from [<c000dad8>] (ret_from_fork+0x14/0x3c)
+ */
+
+/*
+ * Stop RPL Protocol in INET6 Device
+ */
+int rpl_stop(struct net_device *dev)
+{
+	int err = 0;
+	struct inet6_dev *idev;
+
+	printk(KERN_DEBUG "%s(): stoping...\n",__func__);
+
+	idev = __in6_dev_get(dev);
+	if(!idev){
+		RPL_PRINTK(3,dbg,"%s: IPv6 is disabled",__func__);
+		err = -EINVAL;
+		goto out;
+	}
+
+	err = rpl_ipv6_disjoin(dev);
+	if(err)
+	{
+		RPL_PRINTK(2,warn,"%s: error leaving rpl",__func__);
+		goto out;
+	}
+
+	err = rpl_enabled_devices_list_del(dev);
+
+	if(err)
+	{
+		RPL_PRINTK(2,err,"%s: error removing dev to enabled devices list",__func__);
+		goto out;
+	}
+
+	RPL_PRINTK(1,dbg, "RPL: Leaving interface-local all-RPL-node multicast group\n");
+	//if(__ipv6_dev_mc_dec(idev, &in6addr_all_rpl_nodes))
+	if(ipv6_dev_mc_dec(dev, &in6addr_all_rpl_nodes))
+	{
+		RPL_PRINTK(2,warn,"RPL: Error leaving interface-local all-RPL-node multicast group\n");
+	}
+
+	idev->cnf.rpl_joined = 0;
+out:
+	return err;
+}
+
+/**
+ * @see @file ndisc.c ndisc_rcv
+ * */
+static int _rpl_rcv(struct net_device *dev, struct sk_buff *skb)
+{
+	struct rpl_msg *msg;
+
+	struct inet6_dev *idev;
+
+	msg = (struct rpl_msg *)skb_transport_header(skb);
+
+	__skb_push(skb, skb->data - skb_transport_header(skb));
+
+	if (dev == NULL) {
+		RPL_PRINTK(2, warn, "%s(): idev is NULL\n",
+			  __func__);
+		return 0;
+	}
+
+	idev = __in6_dev_get(dev);
+	if(idev){
+		if(msg && idev->cnf.rpl_icmp_dump)
+			icmpv6_rpl_print_msg(msg,skb->len);
+	}
+
+	switch(msg->icmp6_code){
+	case ICMPV6_RPL_DIS:
+		rpl_recv_dis(dev,skb);
+		break;
+	case ICMPV6_RPL_DIO:
+		rpl_recv_dio(dev,skb);
+		break;
+	case ICMPV6_RPL_DAO:
+		rpl_recv_dao(dev,skb);
+		break;
+	case ICMPV6_RPL_DAO_ACK:
+		//rpl_recv_dao_ack();
+		break;
+	case ICMPV6_RPL_CC:
+		//rpl_recv_cc();
+		break;
+	case ICMPV6_RPL_SEC_DIS:
+	case ICMPV6_RPL_SEC_DIO:
+	case ICMPV6_RPL_SEC_DAO:
+	case ICMPV6_RPL_SEC_DAO_ACK:
+	default:
+		printk(KERN_DEBUG "icmpv6: msg of unknown type (0x%02X)\n",msg->icmp6_type);
+	}
+	return 0;
+}
+
+struct rpl_rx_work {
+	struct sk_buff *skb;
+	struct work_struct work;
+	struct net_device *dev;
+};
+
+struct rpl_neigh_check_work {
+	struct net_device	*dev;
+	struct work_struct 	work;
+	struct in6_addr 	neigh_addr;
+	__u8				nud_state;
+};
+
+static void rpl_rx_worker(struct work_struct *work)
+{
+	struct rpl_rx_work *rw = container_of(work, struct rpl_rx_work, work);
+	struct sk_buff *skb = rw->skb;
+	if (rw->dev == NULL) {
+		RPL_PRINTK(2, warn, "%s(): idev is null\n",
+			  __func__);
+	}
+	_rpl_rcv(rw->dev,skb);
+	dev_put(rw->dev);
+	kfree_skb(skb);
+	kfree(rw);
+}
+
+int rpl_rcv(struct sk_buff *skb)
+{
+	struct sk_buff *sskb;
+	struct rpl_rx_work *work = NULL;
+	//struct inet6_dev *idev;
+	struct net_device *dev;
+	struct net *net;
+
+	if (skb_linearize(skb))
+		return 0;
+
+	//idev = in6_dev_get(skb->dev);
+	dev = skb->dev;
+	net = dev_net(dev);
+	if (dev == NULL) {
+		RPL_PRINTK(2, warn, "%s(): idev is null\n",
+			  __func__);
+		return -EINVAL;
+	}
+
+	sskb = skb_clone(skb, GFP_ATOMIC);
+
+	work = kzalloc(sizeof(struct rpl_rx_work), GFP_ATOMIC);
+	if (!work)
+	{
+		kfree_skb(sskb);
+		return -ENOMEM;
+	}
+
+	INIT_WORK(&work->work, rpl_rx_worker);
+	work->skb = sskb;
+
+	dev_hold(dev);
+	work->dev = dev;
+
+	queue_work(net->ipv6.rpl.rpl_rx_wq, &work->work);
+
+	return 0;
+}
+
+static void rpl_neigh_check_worker(struct work_struct *work)
+{
+	int err = 0;
+	struct rpl_dag *dag;
+	struct net *net;
+	struct rpl_neigh_check_work *rw = container_of(work, struct rpl_neigh_check_work, work);
+	if (rw->dev == NULL) {
+		RPL_PRINTK(2, warn, "%s(): idev is null\n",__func__);
+	}
+	net = dev_net(rw->dev);
+	printk(KERN_DEBUG "RPL: call unlink: key: %pI6%%%s nud_state: 0x%02X (0x20 == NUD_FAILED)\n",&rw->neigh_addr,rw->dev->name,rw->nud_state);
+
+	mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+		if(rpl_dag_is_allowed(dag,rw->dev)){
+			err = rpl_dag_unlink_node(dag,rw->dev,&rw->neigh_addr);
+			if(err){
+				printk(KERN_ERR "RPL: error unlinking node (err %d)\n",err);
+			}
+
+			rpl_dag_dbg_dump(dag);
+
+			err = rpl_dag_target_unreachable(dag,rw->dev,&rw->neigh_addr);
+			if(err){
+				printk(KERN_ERR "RPL: error marking target unreachable (err %d)\n",err);
+			}
+		}
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	dev_put(rw->dev);
+	kfree(rw);
+}
+
+static int rpl_netevent_event(struct notifier_block *this, unsigned long event, void *ptr)
+{
+	struct neighbour *neigh;
+	struct rpl_neigh_check_work *work = NULL;
+	//struct inet6_dev *idev;
+	struct net_device *dev;
+	struct net *net;
+
+	switch(event)
+	{
+	case NETEVENT_NEIGH_UPDATE:
+		neigh = (struct neighbour *) ptr;
+		if(neigh && neigh->tbl && neigh->tbl->family == AF_INET6)
+		{
+			if(neigh->nud_state & NUD_FAILED){
+				// idev = in6_dev_get(neigh->dev);
+				dev = neigh->dev;
+				net = dev_net(dev);
+				if (dev == NULL) {
+					RPL_PRINTK(2, warn, "%s(): dev is null\n",__func__);
+					goto out;
+				}
+				dev_hold(dev);
+				work = kzalloc(sizeof(struct rpl_neigh_check_work), GFP_ATOMIC);
+				if (!work)
+				{
+					dev_put(dev);
+					goto out;
+				}
+
+				INIT_WORK(&work->work, rpl_neigh_check_worker);
+				work->dev = dev;
+				memcpy(&work->neigh_addr,neigh->primary_key,neigh->tbl->key_len);
+				work->nud_state = neigh->nud_state;
+
+				queue_work(net->ipv6.rpl.rpl_rx_wq, &work->work);
+			}
+		}
+		break;
+	default:
+
+		break;
+	}
+
+out:
+	return NOTIFY_DONE;
+}
+
+static int rpl_netdev_event(struct notifier_block *this, unsigned long event, void *ptr)
+{
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 11, 0))
+	struct net_device *dev = netdev_notifier_info_to_dev(ptr);
+#else
+	struct net_device *dev = ptr;
+#endif
+	struct inet6_dev *idev;
+
+	printk(KERN_DEBUG "%s: received event: %lu\n",__func__,event);
+	printk(KERN_DEBUG "%s: refcnt %d %s\n",dev->name, netdev_refcnt_read(dev), __FUNCTION__);
+
+	switch (event) {
+	case NETDEV_UP:
+	case NETDEV_CHANGE:
+		idev = in6_dev_get(dev);
+		if (!idev)
+			break;
+		printk(KERN_DEBUG "%s(): REMOVEME calling in6_dev_get: %s\n",__func__,dev->name);
+		if (idev->cnf.rpl_enabled && !idev->cnf.rpl_joined && (idev->if_flags & IF_READY)){
+			printk(KERN_DEBUG "%s: REMOVEME rpl_start(%s) here\n",__func__,dev->name);
+			if (rpl_start(NULL,dev)) {
+				printk(KERN_WARNING "RPL: error starting RPL on %s\n",dev->name);
+			}
+		}
+		printk(KERN_DEBUG "%s(): REMOVEME calling in6_dev_put: %s\n",__func__,dev->name);
+		in6_dev_put(idev);
+		break;
+	case NETDEV_DOWN:
+		//FIXME we should call rpl_stop
+		printk(KERN_DEBUG "%s(): NETDEV_DOWN: dev: %s\n",__func__,dev->name);
+		break;
+	case NETDEV_GOING_DOWN:
+		printk(KERN_DEBUG "%s(): NETDEV_GOING_DOWN: before get dev: %s\n",__func__,dev->name);
+		printk(KERN_DEBUG "%s(): REMOVEME calling in6_dev_get: %s\n",__func__,dev->name);
+		idev = in6_dev_get(dev);
+		if (!idev){
+			printk(KERN_DEBUG "%s(): dev is NULL: %s\n",__func__,dev->name);
+			break;
+		}
+		printk(KERN_DEBUG "%s(): before joined\n",__func__);
+		if (idev->cnf.rpl_joined){ //FIXME ...
+			printk(KERN_DEBUG "%s(): joined\n",__func__);
+			if (rpl_stop(dev)) {
+				printk(KERN_WARNING "RPL: error stopping RPL on %s\n",dev->name);
+			}
+		}
+		printk(KERN_DEBUG "%s(): REMOVEME calling in6_dev_put: %s\n",__func__,idev->dev->name);
+		if(idev)
+			in6_dev_put(idev);
+		break;
+	default:
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+static int rpl_inet6addr_event(struct notifier_block *this,
+			   unsigned long event, void *ptr)
+{
+	struct inet6_ifaddr *ifa = ptr;
+
+
+	printk(KERN_DEBUG "%s: received event: %lu %pI6%%%s\n",__func__,event,&ifa->addr,ifa->idev->dev->name);
+
+	//return masq_device_event(this, event, ifa->idev->dev);
+
+	// FIXME do we want to return DONE?
+	return NOTIFY_DONE;
+}
+
+//FIXME we must detect that interface will be down
+
+static struct notifier_block rpl_netdev_notifier = {
+	.notifier_call = rpl_netdev_event,
+};
+
+static struct notifier_block rpl_netevent_notifier = {
+	.notifier_call = rpl_netevent_event,
+};
+
+static struct notifier_block rpl_inet6addr_notifier = {
+	.notifier_call	= rpl_inet6addr_event,
+};
+
+const struct in6_addr in6addr_all_rpl_nodes = IN6ADDR_ALL_RPL_NODES_INIT;
+
+int rpl_sysctl_rpl_enabled(ctl_table *ctl, int write,
+			    void __user *buffer, size_t *lenp, loff_t *ppos)
+{
+	int ret;
+	struct inet6_dev *idev = NULL;
+	int old = 0;
+
+	if(write)
+	{
+		if(!ctl)
+		{
+			printk(KERN_WARNING "RPL: ctl is NULL\n");
+			return 0;
+		}
+		idev = (struct inet6_dev *)ctl->extra1;
+		if(!idev)
+		{
+			printk(KERN_WARNING "RPL: dev is NULL\n");
+			return 0;
+		}
+		old = idev->cnf.rpl_enabled;
+	}
+
+	if(!ctl)
+	{
+		printk(KERN_WARNING "RPL: ctl is NULL\n");
+	} else {
+		idev = (struct inet6_dev *)ctl->extra1;
+		if(!idev)
+		{
+			printk(KERN_WARNING "RPL: dev is NULL\n");
+		} else {
+			printk(KERN_DEBUG "RPL: %s(): called on %s\n",__func__,(idev && idev->dev)?idev->dev->name:"unknown");
+		}
+	}
+
+	ret = proc_dointvec(ctl, write, buffer, lenp, ppos);
+	if(ret)
+		return ret;
+
+	if(write && (idev->if_flags & IF_READY)){
+		if(old != idev->cnf.rpl_enabled)
+		{
+			if(idev->cnf.rpl_enabled && !idev->cnf.rpl_joined)
+			{
+				if (rpl_start(NULL,idev->dev)) {
+					printk(KERN_WARNING "RPL: error starting RPL\n");
+					ret = -EINVAL;
+					idev->cnf.rpl_enabled = old;
+				}
+			}else if(!idev->cnf.rpl_enabled && idev->cnf.rpl_joined) {
+				if (rpl_stop(idev->dev)) {
+					printk(KERN_WARNING "RPL: error stop RPL\n");
+					ret = -EINVAL;
+					idev->cnf.rpl_enabled = old;
+				}
+			}
+		} else {
+			rpl_dags_list_dump(dev_net(idev->dev));
+		}
+	}
+	return ret;
+}
+
+int rpl_sysctl_rpl_joined(ctl_table *ctl, int write,
+			    void __user *buffer, size_t *lenp, loff_t *ppos)
+{
+	int ret;
+	if(!write){
+		ret = proc_dointvec(ctl, 0, buffer, lenp, ppos);
+	} else {
+		ret = -EPERM;
+	}
+	return ret;
+}
+
+int rpl_sysctl_rpl_dodag_root(ctl_table *ctl, int write,
+			    void __user *buffer, size_t *lenp, loff_t *ppos)
+{
+	int ret;
+	ret = proc_dointvec(ctl, write, buffer, lenp, ppos);
+	return ret;
+}
+
+int rpl_sysctl_rpl_icmp_dump(ctl_table *ctl, int write,
+			    void __user *buffer, size_t *lenp, loff_t *ppos)
+{
+	int ret;
+	ret = proc_dointvec(ctl, write, buffer, lenp, ppos);
+	return ret;
+}
+
+static int __net_init rpl_net_init(struct net *net)
+{
+	struct ipv6_pinfo *np;
+	struct sock *sk;
+	int err = 0;
+
+	err = rpl_enabled_devices_list_init(&net->ipv6.rpl);
+	if(err)
+		goto out;
+	err = rpl_instances_list_init(&net->ipv6.rpl);
+	if(err)
+		goto out_free_devices_list;
+	err = rpl_dags_list_init(&net->ipv6.rpl);
+	if(err)
+		goto out_free_instances;
+
+	err = inet_ctl_sock_create(&sk, PF_INET6,
+				   SOCK_RAW, IPPROTO_ICMPV6, net);
+	if (err < 0) {
+		RPL_PRINTK(0, err,
+			  "RPL: Failed to initialize the control socket (err %d)\n",
+			  err);
+		goto out_free_dags;
+	}
+
+	net->ipv6.rpl.rpl_sk = sk;
+
+	np = inet6_sk(sk);
+	np->hop_limit = 255;
+	/* Do not loopback ndisc messages */
+	np->mc_loop = 0;
+	goto out;
+
+out_free_dags:
+	rpl_dags_list_cleanup(&net->ipv6.rpl);
+out_free_instances:
+	rpl_instances_list_cleanup(&net->ipv6.rpl);
+out_free_devices_list:
+	rpl_enabled_devices_list_cleanup(&net->ipv6.rpl);
+out:
+	return err;
+}
+
+static void __net_exit rpl_net_exit(struct net *net)
+{
+	// FIXME destroy RPL netns structure
+	inet_ctl_sock_destroy(net->ipv6.rpl.rpl_sk);
+	net->ipv6.rpl.rpl_sk = NULL;
+
+	rpl_dags_list_cleanup(&net->ipv6.rpl);
+	rpl_instances_list_cleanup(&net->ipv6.rpl);
+	rpl_enabled_devices_list_cleanup(&net->ipv6.rpl);
+}
+
+static struct pernet_operations rpl_net_ops = {
+	.init = rpl_net_init,
+	.exit = rpl_net_exit,
+};
+
+extern int rpl_of_list_init(void);
+extern int rpl_of_list_cleanup(void);
+
+int __init rpl_init(void)
+{
+	int err;
+
+	pr_info("RPL IPv6\n");
+
+	err = rpl_of_list_init();
+	if(err)
+		goto out;
+	err = register_pernet_subsys(&rpl_net_ops);
+	if (err)
+		goto out_free_of_list;
+	err = register_netdevice_notifier(&rpl_netdev_notifier);
+	if (err)
+		goto out_unregister_pernet;
+	err = register_netevent_notifier(&rpl_netevent_notifier);
+	if (err)
+		goto out_unregister_netdev;
+	err = register_inet6addr_notifier(&rpl_inet6addr_notifier);
+	if (err)
+		goto out_unregister_netevent;
+	err = rpl_nl_init();
+	if(err)
+		goto out_unregister_inet6addr;
+	led_trigger_register_simple("rpl",&ledtrig_rpl_joined);
+out:
+	return err;
+out_unregister_inet6addr:
+	unregister_inet6addr_notifier(&rpl_inet6addr_notifier);
+out_unregister_netevent:
+	unregister_netevent_notifier(&rpl_netevent_notifier);
+out_unregister_netdev:
+	unregister_netdevice_notifier(&rpl_netdev_notifier);
+out_unregister_pernet:
+	unregister_pernet_subsys(&rpl_net_ops);
+out_free_of_list:
+	rpl_of_list_cleanup();
+goto out;
+	return err;
+}
+
+void rpl_cleanup(void){
+	printk(KERN_DEBUG "%s: ...\n",__func__);
+	led_trigger_unregister_simple(ledtrig_rpl_joined);
+	rpl_nl_exit();
+	unregister_inet6addr_notifier(&rpl_inet6addr_notifier);
+	unregister_netevent_notifier(&rpl_netevent_notifier);
+	unregister_netdevice_notifier(&rpl_netdev_notifier);
+	unregister_pernet_subsys(&rpl_net_ops);
+	rpl_of_list_cleanup();
+}
diff --git a/net/ipv6/rpl/rpl_dag.c b/net/ipv6/rpl/rpl_dag.c
new file mode 100644
index 0000000..d76e1fc
--- /dev/null
+++ b/net/ipv6/rpl/rpl_dag.c
@@ -0,0 +1,2863 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_dag.c
+ *
+ * @date Aug 1, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#define pr_fmt(fmt) "RPL: " fmt
+
+#include <linux/kmod.h>
+#include <linux/slab.h>
+#include <linux/net.h>
+#include <linux/route.h>
+#include <linux/list_sort.h>
+#include <net/addrconf.h>
+#include <net/ip6_route.h>
+#include <net/rpl/rpl_debug.h>
+#include <net/rpl/rpl_constants.h>
+#include <net/rpl/rpl_internals.h>
+#include <net/rpl/rpl_dag.h>
+#include <net/rpl/rpl_trickle.h>
+
+#define RPL_DEBUG 3
+
+#define RPL_PRINTK(val, level, fmt, ...)				\
+do {								\
+	if (val <= RPL_DEBUG)					\
+		net_##level##_ratelimited(fmt, ##__VA_ARGS__);	\
+} while (0)
+
+static struct mutex of_list_mutex;
+static struct list_head of_list_head;
+
+/*
+ * Lollipop compare (from contiki rpl-dag.c)
+ */
+int lollipop_greater_than(int a, int b) {
+	/* Check if we are comparing an initial value with an old value */
+	if (a > RPL_LOLLIPOP_CIRCULAR_REGION && b <= RPL_LOLLIPOP_CIRCULAR_REGION) {
+		return (RPL_LOLLIPOP_MAX_VALUE + 1 + b - a)
+				> RPL_LOLLIPOP_SEQUENCE_WINDOW;
+	}
+	/* Otherwise check if a > b and comparable => ok, or
+	 if they have wrapped and are still comparable */
+	return (a > b && (a - b) < RPL_LOLLIPOP_SEQUENCE_WINDOW)
+			|| (a < b && (b - a) > (RPL_LOLLIPOP_CIRCULAR_REGION + 1 -
+			RPL_LOLLIPOP_SEQUENCE_WINDOW));
+}
+
+/*
+ * Objective Function Interface
+ */
+struct rpl_of *rpl_of_alloc(rpl_ocp_t ocp, struct rpl_of_ops *ops)
+{
+	struct rpl_of *of;
+	if(	!ops || !ops->reset || !ops->parent_state_callback ||
+		!ops->best_parent || !ops->best_dag || !ops->calculate_rank ||
+		!ops->update_metric_container){
+		RPL_PRINTK(2, err,
+				"%s: undefined RPL Objective Function operations\n",__func__);
+		goto out;
+	}
+	of = kzalloc(sizeof(struct rpl_of), GFP_KERNEL);
+	if(!of)
+		goto out;
+	INIT_LIST_HEAD(&of->of_list);
+	of->ocp = ocp;
+	of->ops = ops;
+	return of;
+out:
+	return NULL;
+}
+EXPORT_SYMBOL(rpl_of_alloc);
+
+void rpl_of_free(struct rpl_of *of)
+{
+	if(of)
+		kfree(of);
+}
+EXPORT_SYMBOL(rpl_of_free);
+
+int rpl_of_register(struct rpl_of *of)
+{
+	if(of){
+		mutex_lock(&of_list_mutex);
+		list_add(&of->of_list,&of_list_head);
+		mutex_unlock(&of_list_mutex);
+	}
+	return 0;
+}
+EXPORT_SYMBOL(rpl_of_register);
+
+void rpl_of_unregister(struct rpl_of *of)
+{
+	if(of){
+		mutex_lock(&of_list_mutex);
+		list_del(&of->of_list);
+		mutex_unlock(&of_list_mutex);
+	}
+}
+EXPORT_SYMBOL(rpl_of_unregister);
+
+struct rpl_of *rpl_of_get(rpl_ocp_t ocp)
+{
+	struct list_head *ptr;
+	struct rpl_of *entry;
+	mutex_lock(&of_list_mutex);
+	list_for_each(ptr, &of_list_head)
+	{
+		entry = list_entry(ptr,struct rpl_of,of_list);
+		if (entry->ocp == ocp) {
+			mutex_unlock(&of_list_mutex);
+			return entry;
+		}
+	}
+	mutex_unlock(&of_list_mutex);
+	request_module("rpl-of-%d",ocp);
+	mutex_lock(&of_list_mutex);
+	list_for_each(ptr, &of_list_head)
+	{
+		entry = list_entry(ptr,struct rpl_of,of_list);
+		if (entry->ocp == ocp) {
+			mutex_unlock(&of_list_mutex);
+			return entry;
+		}
+	}
+	mutex_unlock(&of_list_mutex);
+	return NULL;
+}
+EXPORT_SYMBOL(rpl_of_get);
+
+rpl_rank_t rpl_of_calculate_rank(struct rpl_of *of, struct rpl_node *parent, rpl_rank_t base, int *err)
+{
+	rpl_rank_t new_rank = RPL_INFINITE_RANK;
+	if(of && of->ops && of->ops->calculate_rank)
+	{
+		new_rank = of->ops->calculate_rank(parent,base);
+	}
+	return new_rank;
+}
+EXPORT_SYMBOL(rpl_of_calculate_rank);
+
+int rpl_of_compare_nodes(struct rpl_of *of, struct rpl_node *p1, struct rpl_node *p2, int *err)
+{
+	int res = 0;
+	if(of && of->ops && of->ops->compare_nodes)
+	{
+		res = of->ops->compare_nodes(p1,p2);
+	}
+	return res;
+}
+EXPORT_SYMBOL(rpl_of_compare_nodes);
+
+/*
+ * RPL Instances List Interface
+ */
+int rpl_instances_list_init(struct netns_rpl *rplns)
+{
+	INIT_LIST_HEAD(&rplns->rpl_instances_list_head);
+	mutex_init(&rplns->rpl_instances_list_mutex);
+	return 0;
+}
+
+int rpl_instances_list_cleanup(struct netns_rpl *rplns)
+{
+	BUG_ON(!list_empty(&rplns->rpl_instances_list_head));
+	mutex_destroy(&rplns->rpl_instances_list_mutex);
+	return 0;
+}
+
+struct rpl_instance *rpl_instances_find(struct net *net, __u8 instanceID)
+{
+	struct list_head *ptr;
+	struct rpl_instance *entry;
+	mutex_lock(&net->ipv6.rpl.rpl_instances_list_mutex);
+	list_for_each(ptr, &net->ipv6.rpl.rpl_instances_list_head)
+	{
+		entry = list_entry(ptr,struct rpl_instance,instances_list);
+		if (entry->instanceID == instanceID) {
+			mutex_unlock(&net->ipv6.rpl.rpl_instances_list_mutex);
+			rpl_instance_hold(entry);
+			return entry;
+		}
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_instances_list_mutex);
+	return NULL;
+}
+
+/*
+ * RPL Enabled Network Devices
+ */
+
+int rpl_enabled_devices_list_init(struct netns_rpl *rplns){
+	int ret = 0;
+	INIT_LIST_HEAD(&rplns->rpl_enabled_devices_list_head);
+	mutex_init(&rplns->rpl_enabled_devices_list_mutex);
+
+	rplns->rpl_rx_wq = create_singlethread_workqueue("rpl_rx");
+	if (!rplns->rpl_rx_wq)
+		ret = -ENOMEM;
+
+	return ret;
+}
+
+int rpl_enabled_devices_list_cleanup(struct netns_rpl *rplns)
+{
+	flush_workqueue(rplns->rpl_rx_wq);
+	destroy_workqueue(rplns->rpl_rx_wq);
+
+	BUG_ON(!list_empty(&rplns->rpl_enabled_devices_list_head));
+	mutex_destroy(&rplns->rpl_enabled_devices_list_mutex);
+	return 0;
+}
+
+static void rpl_dis_timer_handler(unsigned long arg){
+	int err = 0;
+	struct rpl_enabled_device *enabled = (struct rpl_enabled_device *)arg;
+
+	err = rpl_send_dis(enabled);
+	if(err){
+		RPL_PRINTK(1,err,"RPL: Error sending DIS: %d\n",err);
+	}
+	mod_timer(&enabled->dis_timer,jiffies + RPL_DIS_INTERVAL*HZ);
+}
+
+int rpl_enabled_device_del_dis_timer(struct rpl_enabled_device *enabled){
+	int err = 0;
+	if(timer_pending(&enabled->dis_timer)){
+		if((err = try_to_del_timer_sync(&enabled->dis_timer))<0){
+			RPL_PRINTK(0, err,"RPL: Failed to del dis timer (err %d)\n",err);
+		}
+	}
+	return err;
+}
+
+struct rpl_enabled_device *_rpl_enabled_device_get(struct net_device *dev){
+	struct list_head *ptr;
+	struct rpl_enabled_device *entry;
+	struct net *net;
+	if(dev){
+		net = dev_net(dev);
+		list_for_each(ptr, &net->ipv6.rpl.rpl_enabled_devices_list_head){
+			entry = list_entry(ptr,struct rpl_enabled_device,enabled_list);
+			if (entry && dev == entry->dev) {
+				return entry;
+			}
+		}
+	}
+	return NULL;
+}
+
+struct rpl_enabled_device *rpl_enabled_device_get(struct net_device *dev){
+	struct rpl_enabled_device *entry = NULL;
+	struct net *net;
+	if(dev){
+		net = dev_net(dev);
+		mutex_lock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+		entry = _rpl_enabled_device_get(dev);
+		mutex_unlock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+	}
+	return entry;
+}
+
+struct rpl_enabled_device *_rpl_enabled_device_find_by_name(struct net *net,const char name[IFNAMSIZ + 1]){
+	struct list_head *ptr;
+	struct rpl_enabled_device *entry;
+	if(name){
+		list_for_each(ptr, &net->ipv6.rpl.rpl_enabled_devices_list_head){
+			entry = list_entry(ptr,struct rpl_enabled_device,enabled_list);
+			if (entry && entry->dev && !strcmp(entry->dev->name,name)) {
+				return entry;
+			}
+		}
+	}
+	return NULL;
+}
+
+struct rpl_enabled_device *rpl_enabled_device_find_by_name(struct net *net, const char name[IFNAMSIZ + 1]){
+	struct rpl_enabled_device *entry = NULL;
+	if(name){
+		mutex_lock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+		entry = _rpl_enabled_device_find_by_name(net,name);
+		mutex_unlock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+	}
+	return entry;
+}
+
+struct net_device *rpl_enabled_device_find_idev_by_name(struct net *net, const char name[IFNAMSIZ + 1]){
+	struct rpl_enabled_device *entry = NULL;
+	struct net_device *dev = NULL;
+	if(name){
+		mutex_lock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+		entry = _rpl_enabled_device_find_by_name(net,name);
+		if(entry){
+			dev = entry->dev;
+			dev_hold(dev);
+		}
+		mutex_unlock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+	}
+	return dev;
+}
+
+int rpl_enabled_device_add_dis_timer(struct rpl_enabled_device *enabled){
+	int err = 0;
+	if (unlikely(mod_timer(&enabled->dis_timer, jiffies + RPL_DIS_INIT_INTERVAL*HZ))) {
+		printk("RPL: BUG, double timer add\n");
+		dump_stack();
+	}
+	return err;
+}
+
+struct rpl_enabled_device *rpl_enabled_devices_list_add(struct net_device *dev, int *err){
+	int ret = -EINVAL;
+	struct rpl_enabled_device *enabled = NULL;
+	struct inet6_dev *idev;
+	struct net *net;
+	if(dev){
+		net = dev_net(dev);
+		mutex_lock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+		enabled = _rpl_enabled_device_get(dev);
+
+		if(!enabled){
+			enabled = kmalloc(sizeof(struct rpl_enabled_device), GFP_KERNEL);
+			if(!enabled)
+			{
+				RPL_PRINTK(0, err,
+						"%s(): Error allocating memory to enabled device\n",
+						__func__);
+				ret = -ENOMEM;
+				mutex_unlock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+				goto out;
+			}
+			INIT_LIST_HEAD(&enabled->enabled_list);
+			enabled->dev = dev;
+
+			printk(KERN_DEBUG "%s(): REMOVEME calling in6_dev_get: %s\n",__func__,dev->name);
+			idev = in6_dev_get(dev);
+			if(!idev){
+				kfree(enabled);
+
+				mutex_unlock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+				ret = -ENOTSUPP;
+				goto out;
+			}
+			idev->cnf.rpl_enabled = 1;
+			printk(KERN_DEBUG "%s(): REMOVEME calling in6_dev_put: %s\n",__func__,dev->name);
+			in6_dev_put(idev);
+
+			enabled->joined_mc = false;
+			enabled->solicited_information = NULL;
+			dev_hold(dev);
+
+			setup_timer(&enabled->dis_timer, rpl_dis_timer_handler, (unsigned long) enabled);
+
+			list_add(&enabled->enabled_list,&net->ipv6.rpl.rpl_enabled_devices_list_head);
+		}
+		mutex_unlock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+		ret = 0;
+	}
+out:
+	if(err)
+		*err = ret;
+	return enabled;
+}
+
+int rpl_enabled_devices_list_del(struct net_device *dev){
+	int err = -EINVAL;
+	struct list_head *ptr,*next;
+	struct rpl_enabled_device *entry;
+	struct inet6_dev *idev;
+	struct net *net;
+	if(dev){
+		net = dev_net(dev);
+		mutex_lock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+		list_for_each_safe(ptr, next, &net->ipv6.rpl.rpl_enabled_devices_list_head){
+			entry = list_entry(ptr,struct rpl_enabled_device,enabled_list);
+			if (entry && dev == entry->dev) {
+				printk(KERN_DEBUG "%s(): REMOVEME calling in6_dev_get: %s\n",__func__,dev->name);
+				idev = in6_dev_get(entry->dev);
+				if(idev){
+					idev->cnf.rpl_enabled = 0;
+					printk(KERN_DEBUG "%s(): REMOVEME calling in6_dev_put: %s\n",__func__,dev->name);
+					in6_dev_put(idev);
+				}
+				list_del(&entry->enabled_list);
+				rpl_enabled_device_del_dis_timer(entry);
+				dev_put(entry->dev);
+				if(entry->solicited_information)
+					kfree(entry->solicited_information);
+				kfree(entry);
+				break;
+			}
+		}
+		mutex_unlock(&net->ipv6.rpl.rpl_enabled_devices_list_mutex);
+		err = 0;
+	}
+	return err;
+}
+
+/*
+ * RPL Objective Functions List
+ */
+int rpl_of_list_init(void)
+{
+	INIT_LIST_HEAD(&of_list_head);
+	mutex_init(&of_list_mutex);
+	return 0;
+}
+
+int rpl_of_list_cleanup(void)
+{
+	BUG_ON(!list_empty(&of_list_head));
+	mutex_destroy(&of_list_mutex);
+	return 0;
+}
+
+/*
+ * RPL Instance Functions
+ */
+
+int rpl_instance_add(struct rpl_instance *instance)
+{
+	struct list_head *ptr;
+	struct rpl_instance *entry;
+	struct net *net;
+	if(!instance){
+		return -EINVAL;
+	}
+	net = instance->net;
+	mutex_lock(&net->ipv6.rpl.rpl_instances_list_mutex);
+	list_for_each(ptr, &net->ipv6.rpl.rpl_instances_list_head)
+	{
+		entry = list_entry(ptr,struct rpl_instance,instances_list);
+		if (entry->instanceID == instance->instanceID &&
+				entry != instance) {
+			RPL_PRINTK(2, warn,
+					"%s: instance already exists\n",__func__);
+			mutex_unlock(&net->ipv6.rpl.rpl_instances_list_mutex);
+			return -EPERM;
+		}
+	}
+	list_add(&instance->instances_list,&net->ipv6.rpl.rpl_instances_list_head);
+	mutex_unlock(&net->ipv6.rpl.rpl_instances_list_mutex);
+	return 0;
+}
+
+int rpl_instance_del(struct rpl_instance *instance)
+{
+	struct net *net;
+	if(!instance){
+		return -EINVAL;
+	}
+	net = instance->net;
+	mutex_lock(&net->ipv6.rpl.rpl_instances_list_mutex);
+	list_del(&instance->instances_list);
+	mutex_unlock(&net->ipv6.rpl.rpl_instances_list_mutex);
+	return 0;
+}
+
+struct rpl_instance *rpl_instance_new(struct net *net, __u8 instanceID, rpl_ocp_t ocp)
+{
+	struct rpl_instance *instance = NULL;
+	instance = kzalloc(sizeof(struct rpl_instance), GFP_KERNEL);
+	if(!instance)
+		goto out;
+	INIT_LIST_HEAD(&instance->instances_list);
+
+	instance->instanceID = instanceID;
+	instance->net = net;
+	instance->of = rpl_of_get(ocp);
+	if(!instance->of)
+	{
+		RPL_PRINTK(2, warn,
+				"%s: Objective Function not supported\n",__func__);
+		rpl_instance_free(instance);
+		return NULL;
+	}
+
+	rpl_instance_hold(instance);
+
+	rpl_instance_add(instance);
+
+	return instance;
+out:
+	return NULL;
+
+}
+
+void rpl_instance_free(struct rpl_instance *instance)
+{
+	if(instance){
+		RPL_PRINTK(2, warn,
+						"%s: Freeing instance: 0x%02X\n",__func__,instance->instanceID);
+		rpl_instance_del(instance);
+		kfree(instance);
+	}
+}
+
+/*
+ * RPL DAG Functions
+ */
+
+void rpl_dag_dio_timer_handler(unsigned long arg)
+{
+	struct rpl_dag *dag = (struct rpl_dag *) arg;
+	int err = 0;
+	if(dag)
+	{
+		err = rpl_send_dio(dag,NULL,NULL,true,false);
+	}
+	return;
+}
+
+int rpl_dag_dio_timer_reset(struct rpl_dag *dag)
+{
+	int err = -EINVAL;
+	if(dag)
+	{
+		if(dag->dio_timer)
+		{
+			trickle_free(dag->dio_timer);
+		}
+		dag->dio_timer = trickle_new(1 << dag->DIOIntMin,dag->DIOIntDoubl,dag->DIORedun,rpl_dag_dio_timer_handler,(unsigned long)dag);
+		if(!dag->dio_timer)
+		{
+			RPL_PRINTK(0, err,
+					"%s(): Error creating trickle\n",
+					__func__);
+			err = -ENOMEM;
+			goto out;
+		}
+		err = trickle_start(dag->dio_timer);
+		if(err)
+		{
+			RPL_PRINTK(0, err,
+					"%s(): Error starting trickle\n",
+					__func__);
+			goto out;
+		}
+		msleep(500);
+	}
+out:
+	return err;
+}
+
+struct rpl_dao_tx_work {
+	struct work_struct 	work;
+	struct rpl_dag 		*dag;
+};
+
+static void rpl_dag_dao_tx_worker(struct work_struct *work){
+	int err = 0;
+	struct rpl_dao_tx_work *rw = container_of(work, struct rpl_dao_tx_work, work);
+
+	printk(KERN_DEBUG "%s(): called DAO trigger\n",__func__);
+
+	if(rw && rw->dag){
+		err = rpl_send_dao(rw->dag,NULL,true,false);
+		if(err)
+		{
+			RPL_PRINTK(1,err,"RPL: Error sending DAO to all nodes: %d\n",err);
+		}
+		err = rpl_send_dao(rw->dag,NULL,false,false);
+		if(err)
+		{
+			RPL_PRINTK(1,err,"RPL: Error sending DAO to DAO parents: %d\n",err);
+		}
+		rpl_dag_put(rw->dag);
+	}
+	if(rw)
+		kfree(rw);
+}
+
+static void rpl_dag_dao_timer_handler(unsigned long arg){
+	struct rpl_dao_tx_work *work;
+	struct rpl_dag *dag = (struct rpl_dag *) arg;
+	work = kzalloc(sizeof(struct rpl_dao_tx_work), GFP_ATOMIC);
+	if (!work)
+	{
+		goto out;
+	}
+	INIT_WORK(&work->work, rpl_dag_dao_tx_worker);
+	work->dag = dag;
+	queue_work(dag->dao_tx_wq, &work->work);
+out:
+	return;
+}
+
+void rpl_dag_cancel_dao_timer(struct rpl_dag *dag){
+	int err = 0;
+	if(dag && timer_pending(&dag->dao_timer)){
+		if((err = try_to_del_timer_sync(&dag->dao_timer))<0){
+			RPL_PRINTK(0, err,"%s(): Failed to del dis timer (err %d)\n",__func__,err);
+		}
+		rpl_dag_put(dag);
+	}
+}
+
+struct rpl_dag *rpl_dag_alloc(struct rpl_instance *instance, struct in6_addr *dodagid, int *err){
+	struct rpl_dag *dag;
+	dag = kzalloc(sizeof(struct rpl_dag), GFP_KERNEL);
+	if(!dag){
+		RPL_PRINTK(0, err,"%s(): Error allocating memory to dag\n",__func__);
+		*err = -ENOMEM;
+		goto out;
+	}
+	INIT_LIST_HEAD(&dag->dag_list);
+	memcpy(&dag->dodagid,dodagid,16);
+
+	setup_timer(&dag->dao_timer, rpl_dag_dao_timer_handler, (unsigned long) dag);
+	dag->dao_tx_wq = create_singlethread_workqueue("dao_tx_wq");
+	if(!dag->dao_tx_wq){
+		RPL_PRINTK(0, err,"%s(): Error creating workqueue\n",__func__);
+		*err = -ENOMEM;
+		kfree(dag);
+		goto out;
+	}
+
+	dag->DTSN = RPL_LOLLIPOP_INIT;
+	dag->version = RPL_LOLLIPOP_INIT;
+	dag->DAOSequence = RPL_LOLLIPOP_INIT;
+
+	rpl_dag_set_rank(dag,RPL_INFINITE_RANK);
+	dag->PCS = RPL_DEFAULT_PATH_CONTROL_SIZE;
+
+	dag->authenticated = false;
+
+	dag->DIOIntDoubl = RPL_DEFAULT_DIO_INTERVAL_DOUBLINGS;
+	dag->DIOIntMin = RPL_DEFAULT_DIO_INTERVAL_MIN;
+	dag->DIORedun = RPL_DEFAULT_DIO_REDUNDANCY_CONSTANT;
+
+	dag->MaxRankIncrease = RPL_DEFAULT_MAX_RANK_INCREASE;
+	dag->MinHopRankIncrease = RPL_DEFAULT_MIN_HOP_RANK_INCREASE;
+
+	dag->def_lifetime = 0xff;
+	dag->lifetime_unit = 0xffff;
+
+	dag->auto_gen = false;
+	dag->is_root = false;
+	dag->dio_timer = NULL;
+
+	dag->unreachable_counter = 0;
+
+	rpl_instance_hold(instance);
+	dag->instance = instance;
+
+	mutex_init(&dag->parents_lock);
+	INIT_LIST_HEAD(&dag->neighbours);
+	INIT_LIST_HEAD(&dag->dodag_parents);
+
+	INIT_LIST_HEAD(&dag->targets_head);
+
+	INIT_LIST_HEAD(&dag->allowed_interfaces);
+
+	rpl_dag_hold(dag);
+out:
+	return dag;
+}
+
+bool rpl_dag_is_allowed(struct rpl_dag *dag, struct net_device *dev){
+	bool allowed = false;
+	struct rpl_allowed_if *allowed_if;
+	if(dag){
+		if(dag->auto_gen){
+			allowed = true;
+		} else {
+			list_for_each_entry(allowed_if,&dag->allowed_interfaces,allowed_if_list){
+				//printk(KERN_DEBUG "%s(): checking %X %s and %X %s\n",__func__,dev,dev->name,allowed_if->dev,allowed_if->dev->name);
+				if(dev == allowed_if->dev){
+					if(allowed_if->enabled){
+						allowed = true;
+					}
+					break;
+				}
+			}
+		}
+	}
+	return allowed;
+}
+
+int rpl_dag_set_allowed(struct rpl_dag *dag, struct net_device *dev,
+		bool enabled, bool auto_gen, bool *should_trigger_dio) {
+	int err = -EINVAL;
+	bool updated = false;
+	struct rpl_allowed_if *allowed_if = NULL;
+	if(dag){
+		list_for_each_entry(allowed_if,&dag->allowed_interfaces,allowed_if_list){
+			if(!strcmp(dev->name,allowed_if->dev->name)){
+				if(dev != allowed_if->dev){
+					dev_put(allowed_if->dev);
+					dev_hold(dev);
+					allowed_if->dev = dev;
+				}
+				allowed_if->auto_gen = auto_gen;
+				allowed_if->enabled = true;
+				updated = true;
+				err = 0;
+				goto out;
+			}
+		}
+		allowed_if = kzalloc(sizeof(struct rpl_allowed_if), GFP_KERNEL);
+		if(!allowed_if)
+		{
+			RPL_PRINTK(0, err,"%s(): Error allocating memory to allowed interface\n",__func__);
+			err = -ENOMEM;
+			goto out;
+		}
+		allowed_if->node_addr_path_sequence = RPL_LOLLIPOP_INIT;
+		allowed_if->enabled = enabled;
+		if(enabled)
+			updated = true;
+		allowed_if->auto_gen = auto_gen;
+		dev_hold(dev);
+		allowed_if->dev = dev;
+		INIT_LIST_HEAD(&allowed_if->allowed_if_list);
+		list_add(&allowed_if->allowed_if_list,&dag->allowed_interfaces);
+		err = 0;
+	}
+out:
+	if(should_trigger_dio)
+		*should_trigger_dio = updated;
+	return err;
+}
+
+int rpl_dag_set_enabled(struct rpl_dag *dag, struct net_device *dev, bool enabled){
+	int err = -EINVAL;
+	struct rpl_allowed_if *allowed_if = NULL;
+	struct list_head *allowed_if_ptr,*allowed_if_next;
+	if(dag){
+		list_for_each_safe(allowed_if_ptr,allowed_if_next,&dag->allowed_interfaces){
+			allowed_if = list_entry(allowed_if_ptr,struct rpl_allowed_if,allowed_if_list);
+			if(!strcmp(dev->name,allowed_if->dev->name)){
+				if(dev != allowed_if->dev){
+					dev_put(allowed_if->dev);
+					dev_hold(dev);
+					allowed_if->dev = dev;
+				}
+				allowed_if->enabled = enabled;
+				//if(!allowed_if->enabled && allowed_if->auto_gen){
+				if(!allowed_if->enabled){ //FIXME we should allow the configuration to be persistent
+					list_del(&allowed_if->allowed_if_list);
+					dev_put(allowed_if->dev);
+					kfree(allowed_if);
+				}
+				err = 0;
+				break;
+			}
+		}
+		err = 0;
+	}
+	return err;
+}
+
+void rpl_dag_free(struct rpl_dag *dag)
+{
+	struct list_head *ptr,*next;
+	struct rpl_node *parent;
+	struct rpl_target *target;
+	struct rpl_allowed_if *allowed_if;
+	if(dag){
+		printk(KERN_DEBUG "rpl: %s: freeing dag: %pI6\n",__func__,&dag->dodagid);
+
+		// stop trickle timer
+		trickle_stop(dag->dio_timer);
+
+		// destroy dao_timer
+		rpl_dag_cancel_dao_timer(dag);
+
+		// destroy DAO TX workqueue
+		flush_workqueue(dag->dao_tx_wq);
+		destroy_workqueue(dag->dao_tx_wq);
+
+		// release prefix
+		if(dag->prefix_info)
+			kfree(dag->prefix_info);
+
+		// release parents
+		mutex_lock(&dag->parents_lock);
+		list_for_each_safe(ptr,next,&dag->neighbours)
+		{
+			parent = list_entry(ptr,struct rpl_node,node_list);
+			list_del(&parent->node_list);
+			rpl_node_free(parent);
+		}
+		list_for_each_safe(ptr,next,&dag->dodag_parents)
+		{
+			parent = list_entry(ptr,struct rpl_node,node_list);
+			list_del(&parent->node_list);
+			rpl_node_free(parent);
+		}
+		mutex_unlock(&dag->parents_lock);
+		mutex_destroy(&dag->parents_lock);
+
+		list_for_each_safe(ptr,next,&dag->targets_head)
+		{
+			target = list_entry(ptr,struct rpl_target,target_list);
+			list_del(&target->target_list);
+			rpl_target_free(target);
+		}
+
+		// free trickle timer
+		trickle_free(dag->dio_timer);
+
+		// cleaning up allowed interfaces list
+		list_for_each_safe(ptr,next,&dag->allowed_interfaces)
+		{
+			allowed_if = list_entry(ptr,struct rpl_allowed_if,allowed_if_list);
+			list_del(&allowed_if->allowed_if_list);
+			dev_put(allowed_if->dev);
+			kfree(allowed_if);
+		}
+
+		// decrementing instance refcount
+		rpl_instance_put(dag->instance);
+
+		// release kernel resources
+		kfree(dag);
+	}
+	return;
+}
+
+int rpl_dags_list_init(struct netns_rpl *rplns)
+{
+	INIT_LIST_HEAD(&rplns->rpl_dags_list_head);
+	mutex_init(&rplns->rpl_dags_list_mutex);
+	return 0;
+}
+
+int _rpl_dags_list_del(struct rpl_dag *dag);
+
+int rpl_dags_list_cleanup(struct netns_rpl *rplns){
+	struct rpl_dag *dag;
+	struct list_head *ptr,*next;
+	mutex_lock(&rplns->rpl_dags_list_mutex);
+	list_for_each_safe(ptr,next,&rplns->rpl_dags_list_head){
+		dag = list_entry(ptr,struct rpl_dag,dag_list);
+
+		// FIXME we should disjoin first if we are joined
+
+		// Cancelling dao timer to decrement the refcnt and allow the free
+		rpl_dag_cancel_dao_timer(dag);
+
+		_rpl_dags_list_del(dag);
+	}
+	mutex_unlock(&rplns->rpl_dags_list_mutex);
+	mutex_destroy(&rplns->rpl_dags_list_mutex);
+	return 0;
+}
+
+int rpl_dags_list_dump(struct net *net){
+	struct rpl_dag *dag;
+	mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+		rpl_dag_dbg_dump(dag);
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	return 0;
+}
+
+int rpl_dags_list_add(struct net *net, struct rpl_dag *dag){
+	int err = -EINVAL;
+	if(dag)
+	{
+		mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+		rpl_dag_hold(dag);
+		list_add(&dag->dag_list,&net->ipv6.rpl.rpl_dags_list_head);
+		mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+		err = 0;
+	}
+	return err;
+}
+
+int _rpl_dags_list_del(struct rpl_dag *dag){
+	int err = -EINVAL;
+	if(dag)
+	{
+		list_del(&dag->dag_list);
+		rpl_dag_put(dag);
+		err = 0;
+	}
+	return err;
+}
+
+int rpl_dags_list_del(struct net *net, struct rpl_dag *dag){
+	int err = -EINVAL;
+	if(dag)
+	{
+		mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+		_rpl_dags_list_del(dag);
+		mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+		err = 0;
+	}
+	return err;
+}
+
+struct rpl_dag *rpl_dag_find(struct net *net, __u8 instanceID, const struct in6_addr *dodagid)
+{
+	struct rpl_dag *dag = NULL;
+	mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+		if(dag->instance->instanceID == instanceID && ipv6_addr_equal(dodagid,&dag->dodagid)){
+			rpl_dag_hold(dag);
+			mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+			return dag;
+		}
+	}
+	mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	return NULL;
+}
+
+rpl_rank_t rpl_dag_calculate_rank(struct rpl_dag *dag, struct rpl_node *parent, rpl_rank_t base)
+{
+	rpl_rank_t new_rank = RPL_INFINITE_RANK;
+	int err = 0;
+	if(dag && dag->instance && dag->instance->of)
+	{
+		new_rank = rpl_of_calculate_rank(dag->instance->of,parent,base,&err);
+		if(err)
+		{
+			RPL_PRINTK(1, err,
+					"%s(): Error getting rank: %d\n",
+					__func__,err);
+			goto out;
+		}
+	}
+out:
+	return new_rank;
+}
+
+int rpl_dag_compare_nodes(struct rpl_dag *dag, struct rpl_node *p1, struct rpl_node *p2)
+{
+	int err = 0;
+	int res = 0;
+	if(dag && dag->instance && dag->instance->of)
+	{
+		res = rpl_of_compare_nodes(dag->instance->of,p1,p2,&err);
+		if(err)
+		{
+			RPL_PRINTK(1, err,
+					"%s(): Error getting compare result: %d\n",
+					__func__,err);
+			goto out;
+		}
+	}
+out:
+	return res;
+}
+
+struct rpl_node *rpl_dag_get_node(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *addr)
+{
+	struct list_head *ptr;
+	struct rpl_node *entry;
+	if(dag && dev && addr)
+	{
+		mutex_lock(&dag->parents_lock);
+		list_for_each(ptr, &dag->dodag_parents)
+		{
+			entry = list_entry(ptr,struct rpl_node,node_list);
+			if (dev == entry->dev && ipv6_addr_equal(addr,&entry->addr)) {
+				mutex_unlock(&dag->parents_lock);
+				return entry;
+			}
+		}
+		list_for_each(ptr, &dag->neighbours)
+		{
+			entry = list_entry(ptr,struct rpl_node,node_list);
+			if (dev == entry->dev && ipv6_addr_equal(addr,&entry->addr)) {
+				mutex_unlock(&dag->parents_lock);
+				return entry;
+			}
+		}
+		mutex_unlock(&dag->parents_lock);
+	}
+	if (!dag)
+		RPL_PRINTK(1, err, "%s(): dag is NULL\n", __func__);
+	if (!addr)
+		RPL_PRINTK(1, err, "%s(): addr is NULL\n", __func__);
+	return NULL;
+}
+
+/*
+ * when adding new target, if existing target is found, old target is merged with
+ * new one and new is the freed
+ */
+int rpl_dag_add_target(struct rpl_dag *dag, struct rpl_target *target, bool *updated) {
+	int err = -EINVAL;
+	struct rpl_target *old_target = NULL;
+	bool routes_updated = false;
+	if(!dag || !target)
+	{
+		if (!dag)
+			RPL_PRINTK(1, err, "%s(): dag is NULL\n", __func__);
+		if (!target)
+			RPL_PRINTK(1, err, "%s(): target is NULL\n", __func__);
+		goto out;
+	}
+
+	old_target = rpl_dag_get_target(dag,&target->prefix,target->prefix_len);
+	if(old_target)
+	{
+		err = rpl_target_merge_transit_info(old_target,target,updated);
+		if(err)
+		{
+			RPL_PRINTK(1, err, "%s(): Error merging targets transit infos: %d\n", __func__,err);
+			goto out;
+		}
+		rpl_target_free(target);
+		target = old_target;
+	} else {
+		list_add(&target->target_list,&dag->targets_head);
+		if(updated)
+			*updated |= true;
+	}
+
+	err = rpl_target_check_routes(target,&routes_updated);
+	if(err)
+	{
+		RPL_PRINTK(1, err, "%s(): Error updating routes: %d\n", __func__,err);
+	}
+	if(updated)
+		*updated |= routes_updated;
+out:
+	return err;
+}
+
+struct rpl_target *rpl_dag_get_target(struct rpl_dag *dag, const struct in6_addr *prefix, __u8 prefix_len)
+{
+	struct rpl_target *target = NULL;
+	if(!dag || !prefix)
+	{
+		RPL_PRINTK(0, err,"%s(): Invalid arguments\n",__func__);
+		goto out;
+	}
+	list_for_each_entry(target,&dag->targets_head,target_list){
+		if(target->prefix_len == prefix_len && ipv6_prefix_equal(prefix,&target->prefix,prefix_len))
+			return target;
+	}
+out:
+	return NULL;
+}
+
+int rpl_dag_add_node(struct rpl_dag *dag, struct rpl_node *node)
+{
+	int err = -EINVAL;
+	if(dag && node)
+	{
+		mutex_lock(&dag->parents_lock);
+		list_add(&node->node_list,&dag->neighbours);
+		node->dag = dag;
+		mutex_unlock(&dag->parents_lock);
+		err = 0;
+	}
+	return err;
+}
+
+int rpl_node_set_default_route(struct rpl_node *parent);
+int rpl_node_unset_default_route(struct rpl_node *parent);
+
+int rpl_dag_del_node(struct rpl_node *parent)
+{
+	int err = -EINVAL;
+	struct rpl_dag *dag;
+	if(parent)
+	{
+		dag = parent->dag;
+		if(dag){
+			mutex_lock(&dag->parents_lock);
+//			if(parent->is_dao_parent || parent->is_dodag_parent){
+			if(parent->is_preferred){
+				err = rpl_node_unset_default_route(parent);
+				if (err) {
+					RPL_PRINTK(2, err,
+							"%s(): error removing default route to parent: %d\n",
+							__func__, err);
+				}
+			}
+			list_del_init(&parent->node_list);
+			parent->dag = NULL;
+			mutex_unlock(&dag->parents_lock);
+		}
+		err = 0;
+	}
+	return err;
+}
+
+int rpl_dag_target_unreachable(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *addr)
+{
+	int err = -EINVAL;
+	struct rpl_target *target = NULL;
+	struct rpl_target_transit_info *transit_info = NULL;
+	if(dag){
+		// -------------------- prefix test -----------------
+		// if no target match, lets check prefix
+
+		if(ipv6_prefix_equal(addr,&dag->prefix_info->prefix,dag->prefix_info->prefix_len)){
+			dag->unreachable_counter++;
+			printk(KERN_DEBUG "%s(): address match prefix: %pI6/%d unreachable count: %d\n",__func__,&dag->prefix_info->prefix,dag->prefix_info->prefix_len,dag->unreachable_counter);
+		}
+
+		// -------------------- prefix test -----------------
+
+		list_for_each_entry(target,&dag->targets_head,target_list){
+			if(target){
+				if(ipv6_prefix_equal(addr,&target->prefix,target->prefix_len)){
+					transit_info = rpl_target_get_installed(target);
+					if (transit_info){
+						RPL_LOLLIPOP_INCREMENT(dag->DTSN);
+						rpl_dag_inconsistent(dag);
+						goto out;
+					}
+				}
+			} else {
+				printk(KERN_DEBUG "%s(): TARGET is NULL!!!\n",__func__);
+			}
+		}
+out:
+		err = 0;
+	}
+	return err;
+}
+
+int rpl_dag_purge_nodes(struct rpl_dag *dag){
+	int err = -EINVAL;
+	struct list_head *ptr,*next;
+	struct rpl_node *neighbor = NULL;
+	if(dag){
+		list_for_each_safe(ptr,next,&dag->neighbours){
+			neighbor = list_entry(ptr,struct rpl_node,node_list);
+			err = rpl_dag_purge_targets_by_nexthop(dag,neighbor->dev,&neighbor->addr);
+			if(err){
+				RPL_PRINTK(2, err, "%s(): error setting nexthop no-path to neigh: %d\n",__func__,err);
+				continue;
+			}
+			err = rpl_dag_del_node(neighbor);
+			if(err){
+				RPL_PRINTK(2, err, "%s(): error deleting node: %d\n",__func__,err);
+				continue;
+			}
+			err = rpl_node_free(neighbor);
+			if(err){
+				RPL_PRINTK(2, err, "%s(): error freeing node: %d\n",__func__,err);
+				continue;
+			}
+		}
+		list_for_each_safe(ptr,next,&dag->dodag_parents){
+			neighbor = list_entry(ptr,struct rpl_node,node_list);
+			err = rpl_dag_purge_targets_by_nexthop(dag,neighbor->dev,&neighbor->addr);
+			if(err){
+				RPL_PRINTK(2, err, "%s(): error setting nexthop no-path to neigh: %d\n",__func__,err);
+				continue;
+			}
+			err = rpl_dag_del_node(neighbor);
+			if(err){
+				RPL_PRINTK(2, err, "%s(): error deleting node: %d\n",__func__,err);
+				continue;
+			}
+			err = rpl_node_free(neighbor);
+			if(err){
+				RPL_PRINTK(2, err, "%s(): error freeing node: %d\n",__func__,err);
+				continue;
+			}
+		}
+		if(!dag->is_root && list_empty(&dag->dodag_parents)){
+			printk(KERN_ERR "%s(): dodag parents list is empty!!!\n",__func__);
+			rpl_dag_set_rank(dag,RPL_INFINITE_RANK);
+		}
+		err = 0;
+	}
+	return err;
+}
+
+int rpl_dag_unlink_nodes_by_dev(struct rpl_dag *dag, struct net_device *dev){
+	int err = -EINVAL;
+	bool updated = false;
+	struct rpl_node *neighbor = NULL;
+	struct list_head *ptr,*next;
+	if(dag){
+		list_for_each_safe(ptr,next,&dag->neighbours){
+			neighbor = list_entry(ptr,struct rpl_node,node_list);
+
+			//printk(KERN_DEBUG "%s(): checking %X %s and %X %s\n",__func__,dev,dev->name,neighbor->dev,neighbor->dev->name);
+
+			if(neighbor->dev != dev)
+				continue;
+
+			err = rpl_dag_purge_targets_by_nexthop(dag,neighbor->dev,&neighbor->addr);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error setting nexthop no-path to neigh: %d\n",__func__,err);
+				continue;
+			}
+
+			err = rpl_dag_del_node(neighbor);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error deleting node: %d\n",__func__,err);
+				continue;
+			}
+
+			err = rpl_node_free(neighbor);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error freeing node: %d\n",__func__,err);
+				continue;
+			}
+		}
+
+		list_for_each_safe(ptr,next,&dag->dodag_parents){
+			neighbor = list_entry(ptr,struct rpl_node,node_list);
+
+			//printk(KERN_DEBUG "%s(): checking %X %s and %X %s\n",__func__,dev,dev->name,neighbor->dev,neighbor->dev->name);
+
+			if(neighbor->dev != dev)
+				continue;
+
+			err = rpl_dag_purge_targets_by_nexthop(dag,neighbor->dev,&neighbor->addr);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error setting nexthop no-path to neigh: %d\n",__func__,err);
+				continue;
+			}
+
+			err = rpl_dag_del_node(neighbor);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error deleting node: %d\n",__func__,err);
+				continue;
+			}
+
+			err = rpl_node_free(neighbor);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error freeing node: %d\n",__func__,err);
+				continue;
+			}
+		}
+
+		err = rpl_dag_update_upward_routes(dag,&updated);
+		if(err)
+		{
+			RPL_PRINTK(2, err, "%s(): error updating upward routes: %d\n",__func__,err);
+			goto out;
+		}
+
+		if(!dag->is_root && list_empty(&dag->dodag_parents))
+		{
+			printk(KERN_ERR "%s(): dodag parents list is empty!!!\n",__func__);
+			rpl_dag_set_rank(dag,RPL_INFINITE_RANK);
+			updated = true;
+		}
+
+		if(updated)
+		{
+			rpl_dag_inconsistent(dag);
+			rpl_dag_trigger_dao_timer(dag);
+		}
+	}
+out:
+	return err;
+}
+
+int rpl_dag_unlink_node(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *addr){
+	int err = -EINVAL;
+	bool updated = false;
+	struct rpl_node *neighbor;
+
+	if(dag){
+		neighbor = rpl_dag_get_node(dag,dev,addr);
+		if(!neighbor)
+		{
+			RPL_PRINTK(2, err, "%s(): Neighbor not found\n",__func__);
+			//goto out;
+		}
+
+		err = rpl_dag_purge_targets_by_nexthop(dag,dev,addr);
+		if(err)
+		{
+			RPL_PRINTK(2, err, "%s(): error setting nexthop no-path to neigh: %d\n",__func__,err);
+			goto out;
+		}
+
+		if(neighbor){
+			err = rpl_dag_del_node(neighbor);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error deleting node: %d\n",__func__,err);
+				goto out;
+			}
+
+			err = rpl_node_free(neighbor);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error freeing node: %d\n",__func__,err);
+				goto out;
+			}
+
+			err = rpl_dag_update_upward_routes(dag,&updated);
+			if(err)
+			{
+				RPL_PRINTK(2, err, "%s(): error updating upward routes: %d\n",__func__,err);
+				goto out;
+			}
+
+			if(list_empty(&dag->dodag_parents))
+			{
+				printk(KERN_ERR "%s(): dodag parents list is empty!!!\n",__func__);
+				rpl_dag_set_rank(dag,RPL_INFINITE_RANK);
+				updated = true;
+			}
+		}
+		if(updated)
+		{
+			rpl_dag_inconsistent(dag);
+			rpl_dag_trigger_dao_timer(dag);
+		}
+		err = 0;
+	}
+out:
+	return err;
+}
+
+
+struct rpl_node *rpl_node_alloc(const struct in6_addr *addr, struct net_device *dev, rpl_rank_t rank, __u8 dtsn, int *err);
+
+void rpl_node_dbg_dump(struct rpl_node *node);
+void rpl_target_dbg_dump(struct rpl_target *target);
+
+void rpl_node_list_dbg_dump(struct list_head *head)
+{
+	struct rpl_node *parent;
+	if(head){
+		list_for_each_entry(parent,head,node_list)
+		{
+			rpl_node_dbg_dump(parent);
+		}
+	}
+}
+
+void rpl_target_list_dbg_dump(struct list_head *head)
+{
+	struct rpl_target *target;
+	list_for_each_entry(target,head,target_list)
+	{
+		rpl_target_dbg_dump(target);
+	}
+}
+
+void rpl_dag_dbg_dump(struct rpl_dag *dag)
+{
+	struct rpl_allowed_if *allowed_if;
+	if(dag)
+	{
+		if(dag->instance)
+			printk(KERN_DEBUG "%s(): instance: %d\n", __func__,dag->instance->instanceID);
+		if(dag->instance->of)
+			printk(KERN_DEBUG "%s(): OF: %d\n", __func__,dag->instance->of->ocp);
+		printk(KERN_DEBUG "%s(): Version: %d\n", __func__,dag->version);
+		printk(KERN_DEBUG "%s(): DodagID: %pI6\n",__func__,&dag->dodagid);
+		printk(KERN_DEBUG "%s(): Rank: %d\n", __func__,dag->rank);
+		printk(KERN_DEBUG "%s(): Grounded: %d\n", __func__,dag->grounded);
+		printk(KERN_DEBUG "%s(): MOP: %d\n", __func__,dag->mop);
+		printk(KERN_DEBUG "%s(): Prf: %d\n", __func__,dag->preference);
+		printk(KERN_DEBUG "%s(): DTSN: %d\n", __func__,dag->DTSN);
+		printk(KERN_DEBUG "%s(): Root: %d\n", __func__,dag->is_root);
+		printk(KERN_DEBUG "%s(): AutoGen: %d\n", __func__,dag->auto_gen);
+		printk(KERN_DEBUG "%s(): Auth: %d\n", __func__,dag->authenticated);
+		printk(KERN_DEBUG "%s(): PCS: %d\n", __func__,dag->PCS);
+		printk(KERN_DEBUG "%s(): DIOIntDoubl: %d\n", __func__,dag->DIOIntDoubl);
+		printk(KERN_DEBUG "%s(): DIOIntMin: %d\n", __func__,dag->DIOIntMin);
+		printk(KERN_DEBUG "%s(): DIORedun: %d\n", __func__,dag->DIORedun);
+		printk(KERN_DEBUG "%s(): MaxRankIncrease: %u\n", __func__,dag->MaxRankIncrease);
+		printk(KERN_DEBUG "%s(): MinHopRankIncrease: %u\n", __func__,dag->MinHopRankIncrease);
+		printk(KERN_DEBUG "%s(): def_lifetime: %d\n", __func__,dag->def_lifetime);
+		printk(KERN_DEBUG "%s(): lifetime_unit: %u\n", __func__,dag->lifetime_unit);
+
+		printk(KERN_DEBUG "%s(): Allowed Interfaces _____________\n", __func__);
+		list_for_each_entry(allowed_if,&dag->allowed_interfaces,allowed_if_list){
+			printk(KERN_DEBUG "%s(): %%%s enabled: %d auto_gen: %d\n", __func__,allowed_if->dev->name,allowed_if->enabled,allowed_if->auto_gen);
+		}
+
+		printk(KERN_DEBUG "%s(): Neighbors _____________\n", __func__);
+		rpl_node_list_dbg_dump(&dag->neighbours);
+		printk(KERN_DEBUG "%s(): DODAG Parents _____________\n", __func__);
+		rpl_node_list_dbg_dump(&dag->dodag_parents);
+		printk(KERN_DEBUG "%s(): Targets _____________\n", __func__);
+		rpl_target_list_dbg_dump(&dag->targets_head);
+	} else {
+		RPL_PRINTK(2, dbg, "%s(): null dag\n", __func__);
+	}
+}
+
+int ipv6_get_global_addr(struct net_device *dev, struct in6_addr *addr,
+		    unsigned char banned_flags)
+{
+	struct inet6_dev *idev;
+	int err = -EADDRNOTAVAIL;
+
+	rcu_read_lock();
+	idev = __in6_dev_get(dev);
+	if (idev) {
+		struct inet6_ifaddr *ifp;
+
+		read_lock_bh(&idev->lock);
+		list_for_each_entry(ifp, &idev->addr_list, if_list) {
+			if (ipv6_addr_src_scope(&ifp->addr) == IPV6_ADDR_SCOPE_GLOBAL &&
+			    !(ifp->flags & banned_flags)) {
+				*addr = ifp->addr;
+				err = 0;
+				break;
+			}
+		}
+		read_unlock_bh(&idev->lock);
+	}
+	rcu_read_unlock();
+	return err;
+}
+
+struct rpl_dag *rpl_dag_setup_using_conf(struct net *net, struct rpl_dag_conf *cfg, int *perr){
+	int err = 0;
+	struct rpl_dag *dag = NULL;
+	struct rpl_instance *instance;
+
+	if(cfg){
+		dag = rpl_dag_find(net,cfg->instanceID,&cfg->dodagid);
+		if(dag){
+			/*
+			 * Dag found. lets update configuration
+			 */
+			//TODO update dag parameters
+		} else {
+			/*
+			 * Dag not found. lets create a new one
+			 */
+			instance = rpl_instances_find(net,cfg->instanceID);
+			if(!instance){
+				instance = rpl_instance_new(net,cfg->instanceID,cfg->ocp);
+				if(!instance){
+					RPL_PRINTK(1, err,"%s(): Error creating new instance\n",__func__);
+					err = -EPERM;
+					goto out;
+				}
+			}
+
+			dag = rpl_dag_alloc(instance, &cfg->dodagid,&err);
+			if(!dag) {
+				RPL_PRINTK(1, err,
+						"%s(): Error allocating dag: %d\n",__func__,err);
+				rpl_instance_put(instance);
+				goto out;
+			}
+
+			if(!cfg->use_defaults){
+				dag->grounded = cfg->grounded;
+				dag->mop = cfg->mop;
+				dag->preference = cfg->preference;
+
+				dag->DIOIntDoubl = cfg->DIOIntDoubl;
+				dag->DIOIntMin = cfg->DIOIntMin;
+				dag->DIORedun = cfg->DIORedun;
+				dag->PCS = cfg->PCS;
+				dag->MinHopRankIncrease = cfg->MinHopRankIncrease;
+
+				if(dag->prefix_info)
+					kfree(dag->prefix_info);
+				dag->prefix_info = kmalloc(sizeof(struct prefix_info),GFP_ATOMIC);
+				if(!dag->prefix_info){
+					RPL_PRINTK(1, err,"%s(): Error creating prefix_info\n",__func__);
+				} else {
+					memcpy(dag->prefix_info, &cfg->prefix_info, sizeof(struct prefix_info));
+
+//					//FIXME should we set address?
+//					addrconf_prefix_rcv(skb->dev,(u8 *)prefix_option,
+//							sizeof(struct prefix_info),0);
+				}
+			}
+
+			if(cfg->root){
+				dag->is_root = true;
+				//dag->rank = RPL_ROOT_RANK;
+				rpl_dag_set_rank(dag,RPL_ROOT_RANK);
+			}
+
+			dag->auto_gen = false;
+
+			rpl_dags_list_add(net,dag);
+
+			if(instance)
+				rpl_instance_put(instance);
+		}
+		err = 0;
+	}
+out:
+	if(perr)
+		*perr = err;
+	return dag;
+}
+
+/*
+ * every router
+ * - RPLInstanceID
+ * - List of supported Objective Code Points (OCPs)
+ * - List of supported metrics
+ * - Prefix Information
+ * - Solicited Information
+ * - 'K' flag: when a node should set the 'K' flag in a DAO message
+ * - MOP
+ * - Route Information
+ *
+ * Non-DODAG-Root router
+ * - A RPL implementation MUST allow configuring the Target prefix [DAO
+   message, in RPL Target option].
+ *
+ * - Trigger a local repair.
+ *
+ * DODAG Root
+ * - DIOIntervalDoublings
+ * - DIOIntervalMin
+ * - DIORedundancyConstant
+ * - Path Control Size
+ * - MinHopRankIncrease
+ * - The DODAGPreference field
+ * - DODAGID
+ */
+
+void rpl_dag_conf_default_init(struct rpl_dag_conf *cfg){
+	if(cfg){
+		memset(cfg, 0, sizeof(*cfg));
+		/*
+		 * General config
+		 */
+		cfg->use_defaults = true;
+		cfg->root = false;
+		cfg->grounded = true;
+
+		/*
+		 * DODAG Root router config
+		 */
+		cfg->DIOIntDoubl = RPL_DEFAULT_DIO_INTERVAL_DOUBLINGS;
+		cfg->DIOIntMin = RPL_DEFAULT_DIO_INTERVAL_MIN;
+		cfg->DIORedun = RPL_DEFAULT_DIO_REDUNDANCY_CONSTANT;
+		cfg->PCS = RPL_DEFAULT_PATH_CONTROL_SIZE;
+		cfg->MinHopRankIncrease = RPL_DEFAULT_MIN_HOP_RANK_INCREASE;
+		cfg->preference = 0;
+		memcpy(&cfg->dodagid,&in6addr_any,sizeof(struct in6_addr));
+
+		/*
+		 * Every router config
+		 */
+		cfg->ocp = RPL_OF_OF0;
+		cfg->instanceID = RPL_DEFAULT_INSTANCE;
+		cfg->mop = RPL_MOP_STORING_MODE_WITHOUT_MC;
+	}
+}
+
+
+// FIXME we could use the *net from *dev
+int rpl_dag_start_root(struct net *net, struct rpl_dag_conf *cfg, struct net_device *dev){
+	struct rpl_instance *instance = NULL;
+	struct rpl_dag *dag = NULL;
+	int err = -EINVAL;
+	int addr_scope = 0;
+	bool add_new_dag = false;
+
+	//FIXME make use of rpl_dag_conf
+
+	rpl_ocp_t ocp = RPL_OF_OF0;
+	__u8 instanceID = 0;
+	bool grounded = true;
+	__u8 mop = RPL_MOP_STORING_MODE_WITHOUT_MC;
+	__u8 preference = 0;
+	struct prefix_info 	*prefix_info;
+	int prefix_len = 64;
+	struct in6_addr dodagid;
+
+	if(!dev)
+	{
+		RPL_PRINTK(0,err,"%s: NULL pointer, invalid argument: %d",__func__,err);
+		goto out;
+	}
+
+	instance = rpl_instances_find(net,instanceID);
+	if(instance == NULL)
+	{
+		instance = rpl_instance_new(net,instanceID, ocp);
+		if(instance == NULL)
+		{
+			RPL_PRINTK(1,dbg,"%s(): Error create new instance\n",__func__);
+			goto out;
+		}
+	}
+
+	// --- get global address BEGIN
+
+	ipv6_get_global_addr(dev,&dodagid,0);
+	addr_scope = ipv6_addr_src_scope(&dodagid);
+
+	if(addr_scope != IPV6_ADDR_SCOPE_GLOBAL)
+	{
+		printk(KERN_DEBUG "rpl: %s: Bad non global address: %pI6 scope: %X\n",__func__,&dodagid,addr_scope);
+		goto out;
+	}
+	else{
+		printk(KERN_DEBUG "rpl: %s: using global address: %pI6 scope: %X\n",__func__,&dodagid,addr_scope);
+	}
+
+	// -- get global address END
+
+	dag = rpl_dag_find(net,instanceID,&dodagid);
+	if(!dag){
+
+		dag = rpl_dag_alloc(instance, &dodagid,&err);
+		if(!dag){
+			RPL_PRINTK(1, err,"%s(): Error allocating dag: %d\n",__func__,err);
+			goto out;
+		}
+
+		prefix_info = kzalloc(sizeof(struct prefix_info),GFP_ATOMIC);
+		if(!prefix_info){
+			RPL_PRINTK(1, err, "%s(): Error creating prefix_info\n", __func__);
+			rpl_dag_put(dag);
+			dag = NULL;
+			goto out;
+		}
+
+		ipv6_addr_prefix(&prefix_info->prefix,&dodagid,prefix_len);
+		prefix_info->prefix_len = prefix_len;
+		prefix_info->autoconf = true;
+		prefix_info->valid = 0xffffffff;
+		prefix_info->prefered = 0xffffffff;
+
+		add_new_dag = true;
+
+		dag->prefix_info = prefix_info;
+	}
+
+	dag->grounded = grounded;
+	dag->mop = mop;
+	dag->preference = preference;
+	rpl_dag_set_rank(dag,RPL_ROOT_RANK);
+	dag->is_root = true;
+
+	rpl_dag_dio_timer_reset(dag);
+
+	if(add_new_dag)
+		rpl_dags_list_add(net,dag);
+
+	rpl_dag_set_allowed(dag,dev,true,dag->auto_gen,NULL);
+
+	rpl_dag_inconsistent(dag);
+
+	err = 0;
+out:
+	if(dag)
+		rpl_dag_put(dag);
+	if(instance)
+		rpl_instance_put(instance);
+	return err;
+}
+
+// FIXME we could use the *net from *dev
+struct rpl_dag *rpl_dag_new_from_dio(struct net *net, struct net_device *dev, struct sk_buff *skb){
+	int err = 0;
+
+	struct rpl_instance *instance;
+	struct rpl_dag *dag = NULL;
+
+	struct rpl_msg *msg;
+	const struct in6_addr *saddr;
+
+	struct prefix_info *prefix_option;
+
+	u_rpl_option *prefix_info_option;
+	u_rpl_option *dodag_conf_option;
+
+	msg = (struct rpl_msg *)skb_transport_header(skb);
+	if (msg->icmp6_code != ICMPV6_RPL_DIO) {
+		RPL_PRINTK(1, dbg,
+				"%s(): Invalid RPL Message. Unable to join\n",
+				__func__);
+		err = -EPERM;
+		goto out;
+	}
+	saddr = &ipv6_hdr(skb)->saddr;
+
+	// Get Prefix Information Option
+	prefix_info_option = icmpv6_rpl_find_option(skb, ICMPV6_RPL_OPT_Prefix_Information);
+
+	// Get DODAG Configuration Option
+	dodag_conf_option = icmpv6_rpl_find_option(skb, ICMPV6_RPL_OPT_DODAG_Configuration);
+
+	instance = rpl_instances_find(net,msg->base.dio.instanceID);
+	if(!instance && dodag_conf_option){
+		instance = rpl_instance_new(net,msg->base.dio.instanceID,be16_to_cpu(dodag_conf_option->dodag_configuration.OCP));
+		if(!instance){
+			RPL_PRINTK(1, err,"%s(): Error creating new instance\n",__func__);
+			err = -EPERM;
+			goto out;
+		}
+	}
+
+	dag = rpl_dag_alloc(instance, &msg->base.dio.dodagid,&err);
+	if(!dag)
+	{
+		RPL_PRINTK(1, err,
+				"%s(): Error allocating dag. Unable to join: %d\n",
+				__func__,err);
+		rpl_instance_put(instance);
+		goto out;
+	}
+
+	// Initiate DAG using DIO
+	dag->version = msg->base.dio.version;
+	dag->grounded = RPL_DIO_IS_GROUNDED(msg->base.dio.g_mop_prf);
+	dag->mop = RPL_DIO_MOP(msg->base.dio.g_mop_prf);
+	dag->preference = RPL_DIO_Prf(msg->base.dio.g_mop_prf);
+
+	// Process Prefix Information Option
+	if(prefix_info_option){
+		prefix_option = (struct prefix_info *) prefix_info_option;
+		addrconf_prefix_rcv(skb->dev,(u8 *)prefix_option,
+				sizeof(struct prefix_info),0);
+
+		//FIXME: check if we should change prefix!!!
+		if(dag->prefix_info)
+			kfree(dag->prefix_info);
+		dag->prefix_info = kmalloc(sizeof(struct prefix_info),GFP_ATOMIC);
+		if(!dag->prefix_info){
+			RPL_PRINTK(1, err,"%s(): Error creating prefix_info\n",__func__);
+		} else {
+			memcpy(dag->prefix_info, prefix_option, sizeof(struct prefix_info));
+		}
+	}
+
+	// Process DODAG Configuration Option
+	if(dodag_conf_option){
+		dag->authenticated =  RPL_DCO_A(dodag_conf_option->dodag_configuration.flags_A_PCS);
+		dag->PCS = RPL_DCO_PCS(dodag_conf_option->dodag_configuration.flags_A_PCS);
+		dag->DIOIntDoubl = dodag_conf_option->dodag_configuration.DIOIntDoubl;
+		dag->DIOIntMin = dodag_conf_option->dodag_configuration.DIOIntMin;
+		dag->DIORedun = dodag_conf_option->dodag_configuration.DIORedun;
+		dag->MaxRankIncrease = be16_to_cpu(dodag_conf_option->dodag_configuration.MaxRankIncrease);
+		dag->MinHopRankIncrease = be16_to_cpu(dodag_conf_option->dodag_configuration.MinHopRankIncrease);
+		dag->def_lifetime = dodag_conf_option->dodag_configuration.def_lifetime;
+		dag->lifetime_unit = be16_to_cpu(dodag_conf_option->dodag_configuration.lifetime_unit);
+	}
+
+	dag->auto_gen = true;
+
+	rpl_dag_dio_timer_reset(dag);
+
+	rpl_dags_list_add(net,dag);
+
+	rpl_dag_set_allowed(dag,dev,true,dag->auto_gen,NULL);
+
+	if(instance)
+		rpl_instance_put(instance);
+out:
+	return dag;
+}
+
+int rpl_dag_poison(struct rpl_dag *dag, struct net_device *dev){
+	int err = -EINVAL;
+	if(dag)
+	{
+		printk("%s: POISON.... REMOVEME\n",__func__);
+		err = rpl_send_dio(dag,dev,NULL,false,true);
+		if(err){
+			RPL_PRINTK(1, err,
+					"%s(): Error sending DIO: %d\n",
+					__func__,err);
+			goto out;
+		}
+	}
+out:
+	return err;
+}
+
+int rpl_dag_disjoin(struct rpl_dag *dag, struct net_device *dev)
+{
+	int err = -EINVAL;
+	bool enabled = false;
+	struct rpl_allowed_if *allowed_if = NULL;
+	/*
+	 * 3.2.2
+	 * DODAG disjoin
+	 * When a node is part of a DODAG and for metric or
+	 * administrative reasons wants to disassociate,
+	 * it will perform a disjoin.
+	 * This procedure consists in disabling the trickle timer (if it
+	 * was active), communicating the disjoin from the DODAG to
+	 * the neighbors by sending a poisoning DIO to each of them
+	 * and deleting all the rows from the routing table and the
+	 * neighbors set. The poisoning DIO will remove that node
+	 * from the routing table and the neighbors set. The node will
+	 * then try to join a new DODAG.
+	 */
+	if(dag)
+	{
+		err = rpl_dag_poison(dag,dev);
+		if(err){
+			RPL_PRINTK(1, err,"%s(): Error poisoning dag: %d\n",__func__,err);
+		} else if(!dag->is_root){
+			err = rpl_send_dao(dag,dev,true,true);
+			if(err)
+			{
+				RPL_PRINTK(1,err,"RPL: Error sending DAO to all nodes: %d\n",err);
+			}
+			err = rpl_send_dao(dag,dev,false,true);
+			if(err)
+			{
+				RPL_PRINTK(1,err,"RPL: Error sending DAO to DAO parents: %d\n",err);
+			}
+		}
+
+		err = rpl_dag_unlink_nodes_by_dev(dag,dev);
+		if(err){
+			RPL_PRINTK(2, err,"%s(): Error unlinking all nodes: %d\n",__func__,err);
+			goto out;
+		}
+
+		err = rpl_dag_purge_targets_by_dev(dag,dev);
+		if(err) {
+			RPL_PRINTK(2, err, "%s(): purging targets from device %s: %d\n",__func__,dev->name,err);
+			goto out;
+		}
+
+		rpl_dag_set_enabled(dag,dev,false);
+
+		list_for_each_entry(allowed_if,&dag->allowed_interfaces,allowed_if_list){
+			if(allowed_if->enabled){
+				enabled = true;
+				break;
+			}
+		}
+
+		if(!enabled){
+			rpl_dag_set_rank(dag,RPL_INFINITE_RANK);
+			rpl_dag_cancel_dao_timer(dag);
+		}
+	}
+out:
+	return err;
+}
+
+int rpl_dag_set_rank(struct rpl_dag *dag, rpl_rank_t rank){
+	int err = -EINVAL;
+	if(!dag)
+		return err;
+
+	dag->rank = rank;
+
+	// TODO refactor the ledtrigger
+	if(dag->rank == RPL_INFINITE_RANK){
+		led_trigger_event(ledtrig_rpl_joined,LED_OFF);
+	} else {
+		led_trigger_event(ledtrig_rpl_joined,LED_FULL);
+	}
+	return 0;
+}
+
+int rpl_dag_inconsistent(struct rpl_dag *dag)
+{
+	int err = -EINVAL;
+	if(dag)
+	{
+		err = trickle_hear_inconsistent(dag->dio_timer);
+	}
+	return err;
+}
+
+int rpl_dag_consistent(struct rpl_dag *dag)
+{
+	int err = -EINVAL;
+	if(dag)
+	{
+		err = trickle_hear_consistent(dag->dio_timer);
+	}
+	return err;
+}
+
+int rpl_dag_cleanup_no_path(struct rpl_dag *dag){
+	int err = -EINVAL;
+	struct rpl_target *target;
+	struct list_head *ptr_target,*next_target;
+	struct rpl_target_transit_info *transit_info = NULL;
+	struct list_head *ptr_transit,*next_transit;
+	if(dag){
+		list_for_each_safe(ptr_target,next_target,&dag->targets_head)
+		{
+			target = list_entry(ptr_target,struct rpl_target,target_list);
+			list_for_each_safe(ptr_transit,next_transit,&target->transit_head)
+			{
+				transit_info = list_entry(ptr_transit,struct rpl_target_transit_info,transit_info_list);
+				if(transit_info && transit_info->path_lifetime == 0x00 && !transit_info->installed)
+				{
+					list_del(&transit_info->transit_info_list);
+					rpl_transit_info_free(transit_info);
+				}
+			}
+			if(list_empty(&target->transit_head)){
+				list_del(&target->target_list);
+				rpl_target_free(target);
+			}
+		}
+		err = 0;
+	}
+	return err;
+}
+
+int rpl_dag_trigger_dao_timer(struct rpl_dag *dag)
+{
+	int err = -EINVAL;
+	if(dag && !dag->is_root){
+		if(!timer_pending(&dag->dao_timer))
+		{
+			printk(KERN_DEBUG "%s(): dao trigger\n",__func__);
+			rpl_dag_hold(dag);
+			if (unlikely(mod_timer(&dag->dao_timer, jiffies + RPL_DEFAULT_DAO_DELAY*HZ))) {
+				printk("RPL: BUG, DAO double timer add\n");
+				dump_stack();
+			}
+		}
+		err = 0;
+	} else if(dag->is_root){
+		err = rpl_dag_cleanup_no_path(dag);
+	}
+	return err;
+}
+
+int rpl_node_cmp(void *pdag, struct list_head *l1, struct list_head *l2);
+
+int rpl_add_route_nexthop(struct net_device *dev, const struct in6_addr *prefix,
+		__u8 prefix_len, const struct in6_addr *next_hop) {
+	int err = -EINVAL;
+	int pref = 0;
+	struct fib6_config cfg;
+	//FIXME check expires!!
+
+	memset(&cfg, 0, sizeof(cfg));
+	cfg.fc_table	= RT6_TABLE_DFLT;
+	cfg.fc_metric	= IP6_RT_PRIO_USER;
+	cfg.fc_ifindex	= dev->ifindex;
+	cfg.fc_flags	= RTF_GATEWAY | RTF_PREF(pref);
+	cfg.fc_nlinfo.portid = 0;
+	cfg.fc_nlinfo.nlh = NULL;
+	cfg.fc_nlinfo.nl_net = dev_net(dev);
+	cfg.fc_dst = *prefix;
+	cfg.fc_dst_len = prefix_len;
+	cfg.fc_gateway = *next_hop;
+
+//	RPL_PRINTK(1, err, "%s(): fc_ifindex: %d\n", __func__,cfg.fc_ifindex);
+//	RPL_PRINTK(1, err, "%s(): fc_src: %pI6/%d\n", __func__,&cfg.fc_src,cfg.fc_src_len);
+//	RPL_PRINTK(1, err, "%s(): fc_dst: %pI6/%d\n", __func__,&cfg.fc_dst,cfg.fc_dst_len);
+//	RPL_PRINTK(1, err, "%s(): fc_gw: %pI6\n", __func__,&cfg.fc_gateway);
+//	RPL_PRINTK(1, err, "%s(): fc_flags: %04X\n", __func__,cfg.fc_flags);
+
+	err = ip6_route_add(&cfg);
+
+	return err;
+}
+
+int rpl_dag_purge_targets_by_dev(struct rpl_dag *dag, struct net_device *dev){
+	/*
+	 * For all targets whose nexthop use idev, set no-path.
+	 * Iterate dag targets and set_no_path for those transit that use device
+	 * as nexthop. It might be necessary to reinstall a new transit/route to same
+	 * targets with known alternatives
+	 */
+
+	int err = -EINVAL;
+	struct rpl_target *target;
+	struct rpl_target_transit_info *transit_info;
+	bool updated = false;
+	bool trigger_dao = false;
+	if (!dag) {
+		RPL_PRINTK(1, err, "%s(): dag is NULL\n", __func__);
+		goto out;
+	}
+	list_for_each_entry(target,&dag->targets_head,target_list)
+	{
+		list_for_each_entry(transit_info,&target->transit_head,transit_info_list){
+			if(dev == transit_info->dev){
+				err = rpl_transit_info_update(target, transit_info,
+						transit_info->DAOSequence, transit_info->path_sequence, 0,
+						transit_info->path_control,&updated);
+				if (err) {
+					RPL_PRINTK(1, err, "%s(): Error updating transit: %d\n",
+							__func__, err);
+				}
+				trigger_dao |= updated;
+			}
+		}
+	}
+	if(trigger_dao)
+	{
+		rpl_dag_trigger_dao_timer(dag);
+	}
+	err = 0;
+out:
+	return err;
+}
+
+int rpl_dag_purge_targets_by_nexthop(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *addr){
+	/*
+	 * For all targets whose nexthop is neighbor->addr, set no-path.
+	 * Iterate dag targets and set_no_path for those transit that use neighbour
+	 * as nexthop. It might be necessary to reinstall a new transit/route to same
+	 * targets with known alternatives
+	 */
+
+	int err = -EINVAL;
+	struct rpl_target *target;
+	struct rpl_target_transit_info *transit_info;
+	bool updated = false;
+	bool trigger_dao = false;
+	if (!dag) {
+		RPL_PRINTK(1, err, "%s(): dag is NULL\n", __func__);
+		goto out;
+	}
+	list_for_each_entry(target,&dag->targets_head,target_list)
+	{
+		transit_info = rpl_target_find_transit_info(target,dev,addr);
+		if (transit_info) {
+			err = rpl_transit_info_update(target, transit_info,
+					transit_info->DAOSequence, transit_info->path_sequence, 0,
+					transit_info->path_control,&updated);
+			if (err) {
+				RPL_PRINTK(1, err, "%s(): Error updating transit: %d\n",
+						__func__, err);
+			}
+			trigger_dao |= updated;
+		} else {
+			RPL_PRINTK(1, dbg, "%s(): transit not found: %pI6%%%s\n",__func__,addr,dev->name);
+		}
+	}
+	if(trigger_dao)
+	{
+		rpl_dag_trigger_dao_timer(dag);
+	}
+	err = 0;
+out:
+	return err;
+}
+
+int rpl_dag_update_upward_routes(struct rpl_dag *dag, bool *updated)
+{
+	int err = -EINVAL;
+	rpl_rank_t candidate_rank;
+	struct list_head *ptr,*next;
+	bool parent_found = false;
+	bool preferred_found = false;
+	bool upward_routes_changed = false;
+	struct rpl_node *parent;
+
+	if(dag)
+	{
+		mutex_lock(&dag->parents_lock);
+
+		// move all parents from dodag_parents to neighbours
+		list_for_each_safe(ptr,next,&dag->dodag_parents)
+		{
+			parent = list_entry(ptr,struct rpl_node,node_list);
+			list_del_init(&parent->node_list);
+			list_add(&parent->node_list,&dag->neighbours);
+		}
+
+		// lets sort neighbours
+		list_sort(dag,&dag->neighbours,rpl_node_cmp);
+
+		// lets move best parents to dodag_parents and set default route
+		list_for_each_safe(ptr,next,&dag->neighbours)
+		{
+
+			parent = list_entry(ptr,struct rpl_node,node_list);
+
+			// check if is higher rank than best
+			if(!parent_found){
+				candidate_rank = rpl_dag_calculate_rank(dag,parent,0);
+
+				//printk(KERN_DEBUG "%s(): Candidate RANK: %u parent_rank: %u dag_rank: %u\n",__func__,candidate_rank,parent->rank,dag->rank);
+				if(DAGRank(candidate_rank,dag) > DAGRank(dag->rank,dag))
+				{
+					// We already found all best DODAG Parents
+					parent_found = true;
+				} else {
+					// this is the lowest (best) rank found
+
+					list_del_init(&parent->node_list);
+					list_add(&parent->node_list,&dag->dodag_parents);
+
+					if(!parent->is_dodag_parent){
+						// setting flags DAO parent and DODAG Parent
+						parent->is_dao_parent = true;
+						parent->is_dodag_parent = true;
+						parent->is_preferred = false;
+						upward_routes_changed = true;
+					}
+
+					if(!preferred_found){
+						// adding default route to this parent
+						if(!parent->is_preferred){
+							err = rpl_node_set_default_route(parent);
+							if(err){
+								RPL_PRINTK(2, err,
+										"%s(): error setting default route to parent: %d\n",
+										__func__,err);
+							}
+							parent->is_preferred = true;
+						}
+						preferred_found = true;
+					}
+
+					//dag->rank = rpl_dag_calculate_rank(dag,parent,0);
+					rpl_dag_set_rank(dag,rpl_dag_calculate_rank(dag,parent,0));
+				}
+			}
+
+			if(parent_found) {
+				/*
+				 *  we already found best DODAG parents.
+				 *  lets check if we need to remove some default route
+				 */
+				if(parent->is_dodag_parent)
+				{
+					/*
+					 * if parent were already found and we got a dodag parent,
+					 * we need to remove the route and update neighbour
+					 */
+					parent->is_dao_parent = false;
+					parent->is_dodag_parent = false;
+					upward_routes_changed = true;
+					if(parent->is_preferred){
+						err = rpl_node_unset_default_route(parent);
+						if(err){
+							RPL_PRINTK(2, err,
+									"%s(): error removing default route to parent: %d\n",
+									__func__,err);
+						}
+						parent->is_preferred = false;
+					}
+				}
+			}
+		}
+		mutex_unlock(&dag->parents_lock);
+		err = 0;
+		if(updated)
+			*updated = upward_routes_changed;
+		//printk(KERN_DEBUG "%s(): FINAL BEST RANK: %u dag_rank: %u\n",__func__,best,dag->rank);
+
+	}
+	return err;
+}
+
+/*
+ * RPL Node Functions
+ */
+
+struct rpl_node *rpl_node_alloc(const struct in6_addr *addr, struct net_device *dev, rpl_rank_t rank, __u8 dtsn, int *err)
+{
+	struct rpl_node *node;
+	node = kzalloc(sizeof(struct rpl_node), GFP_KERNEL);
+	if(!node)
+	{
+		RPL_PRINTK(0, err,
+				"%s(): Error allocating memory to node\n",
+				__func__);
+		*err = -ENOMEM;
+		goto out;
+	}
+	INIT_LIST_HEAD(&node->node_list);
+	node->rank = rank;
+	node->dtsn = dtsn;
+	node->dev = dev;
+	node->is_dao_parent = false;
+	node->is_dodag_parent = false;
+	node->is_preferred = false;
+	dev_hold(node->dev);
+	memcpy(&node->addr,addr,16);
+out:
+	return node;
+}
+
+int rpl_node_free(struct rpl_node *node)
+{
+	int err = -EINVAL;
+	if(node)
+	{
+		if(node->dev){
+			dev_put(node->dev);
+		}
+		kfree(node);
+		err = 0;
+		goto out;
+	}
+out:
+	return err;
+}
+
+int rpl_node_cmp(void *pdag, struct list_head *l1, struct list_head *l2)
+{
+	struct rpl_dag *dag = (struct rpl_dag *) pdag;
+	struct rpl_node *p1,*p2;
+	int res = 0;
+	if(!dag)
+		return res;
+	p1 = list_entry(l1,struct rpl_node,node_list);
+	p2 = list_entry(l2,struct rpl_node,node_list);
+	res = rpl_dag_compare_nodes(dag,p1,p2);
+	//printk(KERN_DEBUG "%s(): RES: %d p1: %pI6 rank: %u p2: %pI6 rank: %u\n",__func__,res,&p1->addr,p1->rank,&p2->addr,p2->rank);
+	return res;
+}
+
+/*
+ * RPL Target Functions
+ */
+
+struct rpl_target *rpl_target_alloc(const struct in6_addr *prefix, __u8 prefix_len, int *err) {
+	struct rpl_target *target;
+	target = kzalloc(sizeof(struct rpl_target), GFP_KERNEL);
+	if(!target)
+	{
+		RPL_PRINTK(0, err,
+				"%s(): Error allocating memory to target\n",
+				__func__);
+		if(err)
+			*err = -ENOMEM;
+		goto out;
+	}
+	INIT_LIST_HEAD(&target->target_list);
+	INIT_LIST_HEAD(&target->transit_head);
+	memcpy(&target->prefix,prefix,16);
+	target->prefix_len = prefix_len;
+out:
+	return target;
+}
+
+void rpl_target_free(struct rpl_target *target)
+{
+	struct rpl_target_transit_info *transit_info;
+	struct list_head *ptr,*next;
+	if(target)
+	{
+		list_for_each_safe(ptr,next,&target->transit_head)
+		{
+			transit_info = list_entry(ptr,struct rpl_target_transit_info,transit_info_list);
+			list_del(&transit_info->transit_info_list);
+			rpl_transit_info_free(transit_info);
+		}
+		kfree(target);
+	}
+}
+
+struct rpl_target_transit_info *rpl_target_get_installed(struct rpl_target *target)
+{
+	struct rpl_target_transit_info *transit_info = NULL;
+	if(target){
+		list_for_each_entry(transit_info,&target->transit_head,transit_info_list){
+			if(transit_info->installed == true){
+				return transit_info;
+			}
+		}
+	}
+	return NULL;
+}
+
+/*
+ * when adding transit information to target, if there's already a transit info from
+ * such node, it will only update info if path sequence is newer.
+ * Upon existing transit_info found, the given transit info is freed and MUST not be accessed
+ */
+int rpl_target_add_transit_info(struct rpl_target *target, struct rpl_target_transit_info *transit_info, bool *updated)
+{
+	int err = -EINVAL;
+	struct rpl_target_transit_info *old = NULL;
+	bool transit_info_updated = false;
+	if(target && transit_info){
+		old = rpl_target_find_transit_info(target,transit_info->dev,&transit_info->next_hop);
+		if(old){
+			if (transit_info->path_lifetime == 0x00 || lollipop_greater_than(transit_info->path_sequence,old->path_sequence)) {
+				err = rpl_transit_info_update(target, old,
+						transit_info->DAOSequence, transit_info->path_sequence,
+						transit_info->path_lifetime,
+						transit_info->path_control,
+						&transit_info_updated);
+				if (err) {
+					RPL_PRINTK(0, err,"%s(): error updating transit info: %d\n", __func__,err);
+					goto out;
+				}
+			}
+			rpl_transit_info_free(transit_info);
+			if(updated)
+				*updated = transit_info_updated;
+		} else {
+			list_add(&transit_info->transit_info_list,&target->transit_head);
+			if(updated)
+				*updated = true;
+		}
+		err = 0;
+	}
+out:
+	return err;
+}
+
+struct rpl_target_transit_info *rpl_target_find_transit_info(struct rpl_target *target,
+		struct net_device *dev, const struct in6_addr *next_hop) {
+	struct rpl_target_transit_info *transit_info = NULL;
+	if(!target || !dev || !next_hop)
+	{
+		RPL_PRINTK(0, err,"%s(): Invalid arguments\n",__func__);
+		goto out;
+	}
+	list_for_each_entry(transit_info,&target->transit_head,transit_info_list){
+		if(dev == transit_info->dev && ipv6_addr_equal(next_hop,&transit_info->next_hop))
+			return transit_info;
+	}
+out:
+	return NULL;
+}
+
+int rpl_target_merge_transit_info(struct rpl_target *old_target,struct rpl_target *new_target, bool *updated)
+{
+	int err = -EINVAL;
+	bool transit_info_updated = false;
+	struct rpl_target_transit_info *transit_info = NULL;
+	struct list_head *ptr,*next;
+	if(!old_target || !new_target)
+	{
+		RPL_PRINTK(0, err,"%s(): Invalid arguments\n",__func__);
+		goto out;
+	}
+	list_for_each_safe(ptr,next,&new_target->transit_head)
+	{
+		transit_info = list_entry(ptr,struct rpl_target_transit_info,transit_info_list);
+		list_del(&transit_info->transit_info_list);
+		rpl_target_add_transit_info(old_target,transit_info,&transit_info_updated);
+		*updated |= transit_info_updated;
+		transit_info = NULL;
+	}
+	err = 0;
+out:
+	return err;
+}
+
+int rpl_transit_info_cmp(void *ptarget, struct list_head *l1, struct list_head *l2);
+int rpl_del_route(struct net_device *dev, const struct in6_addr *target_addr,
+		__u8 target_addr_len, const struct in6_addr *next_hop);
+
+int rpl_target_check_routes(struct rpl_target *target, bool *routes_updated)
+{
+	struct rpl_target_transit_info *transit_info = NULL;
+	bool first = true;
+	bool updated = false;
+	int err = 0;
+	/*
+	 * this function must check all available transit info for target and select the best
+	 * next_hop. if changes are applied, the old route must be removed and new must be installed.
+	 * on changes,
+	 * http://tools.ietf.org/html/rfc6550#section-9.6
+	 */
+	if(!target)
+	{
+		RPL_PRINTK(0, err,"%s(): Invalid arguments\n",__func__);
+		err = -EINVAL;
+		goto out;
+	}
+
+	// sort all transit_infos. Best route will be in first element
+	list_sort(target,&target->transit_head,rpl_transit_info_cmp);
+
+	list_for_each_entry(transit_info,&target->transit_head,transit_info_list){
+		if(first){
+			if(!transit_info->installed)
+			{
+				err = rpl_add_route_nexthop(transit_info->dev, &target->prefix,
+						target->prefix_len, &transit_info->next_hop);
+				if(err){
+					RPL_PRINTK(0, err,"%s(): error adding route: %d\n",__func__,err);
+					if(err == -EEXIST){
+						transit_info->installed = true;
+					}
+				} else {
+					transit_info->installed = true;
+					updated = true;
+				}
+			}
+			first = false;
+		} else {
+			if(transit_info->installed)
+			{
+				err = rpl_del_route(transit_info->dev, &target->prefix,
+						target->prefix_len, &transit_info->next_hop);
+				if(err){
+					RPL_PRINTK(0, err,"%s(): error adding route: %d\n",__func__,err);
+				}
+				transit_info->installed = false;
+				updated = true;
+			}
+		}
+	}
+	if(routes_updated)
+		*routes_updated = updated;
+	err = 0;
+out:
+	return err;
+}
+
+int rpl_target_set_no_path(struct net *net, __u8 instanceID, const struct in6_addr *dodagid,
+		struct net_device *dev, const struct in6_addr *target_prefix,
+		__u8 target_prefix_len, const struct in6_addr *next_hop) {
+	int err = -EINVAL;
+	struct rpl_target *target;
+	struct rpl_target_transit_info *transit_info;
+	struct rpl_dag *dag;
+	bool transit_info_updated = false;
+
+	if(dodagid){
+		/*
+		 * Set no_path to target found in specified dodagid
+		 */
+		dag = rpl_dag_find(net,instanceID,dodagid);
+		if(dag){
+			target = rpl_dag_get_target(dag,target_prefix,target_prefix_len);
+			if(target){
+				transit_info = rpl_target_find_transit_info(target,dev,next_hop);
+				err = rpl_transit_info_update(target,transit_info,
+						transit_info->DAOSequence, transit_info->path_sequence,
+						0, transit_info->path_control,&transit_info_updated);
+				if(err)
+				{
+					RPL_PRINTK(0, err,"%s(): Error updating transit: %d\n",__func__,err);
+					rpl_dag_put(dag);
+					dag = NULL;
+					goto out;
+				}
+				if(transit_info_updated)
+				{
+					rpl_dag_trigger_dao_timer(dag);
+				}
+			}
+			rpl_dag_put(dag);
+		}
+	} else
+	{
+		/*
+		 * Set no_path to target found for all dodags to given instanceID
+		 */
+		mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+		list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+			if(dag == NULL){
+				BUG();
+				printk(KERN_DEBUG "%s(): DAG is NULL!!!\n",__func__);
+			}
+			if(instanceID == dag->instance->instanceID && rpl_dag_is_allowed(dag,dev)){
+				target = rpl_dag_get_target(dag,target_prefix,target_prefix_len);
+				if(target)
+				{
+					transit_info = rpl_target_find_transit_info(target,dev,next_hop);
+					if(transit_info){
+						err = rpl_transit_info_update(target,transit_info,
+								transit_info->DAOSequence, transit_info->path_sequence,
+								0, transit_info->path_control,&transit_info_updated);
+						if(err)
+						{
+							RPL_PRINTK(0, err,"%s(): Error updating transit: %d\n",__func__,err);
+						}
+						if(transit_info_updated)
+						{
+							rpl_dag_trigger_dao_timer(dag);
+						}
+					}
+				}
+			}
+		}
+		mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	}
+out:
+	return err;
+}
+
+struct rpl_target_transit_info *rpl_transit_info_alloc(const struct in6_addr *next_hop, struct net_device *dev, bool is_one_hop, int *err)
+{
+	struct rpl_target_transit_info *transit_info;
+	transit_info = kzalloc(sizeof(struct rpl_target_transit_info), GFP_KERNEL);
+	if(!transit_info)
+	{
+		RPL_PRINTK(0, err,
+				"%s(): Error allocating memory to transit info\n",
+				__func__);
+		if(err)
+			*err = -ENOMEM;
+		goto out;
+	}
+	INIT_LIST_HEAD(&transit_info->transit_info_list);
+	memcpy(&transit_info->next_hop,next_hop,16);
+	dev_hold(dev);
+	transit_info->dev = dev;
+	transit_info->installed = false;
+	transit_info->one_hop = is_one_hop;
+out:
+	return transit_info;
+}
+
+void rpl_transit_info_free(struct rpl_target_transit_info *transit_info)
+{
+	if(transit_info){
+		if(transit_info->dev){
+			dev_put(transit_info->dev);
+		}
+		kfree(transit_info);
+	}
+}
+
+int rpl_transit_info_update(struct rpl_target *target, struct rpl_target_transit_info *transit_info,
+		__u8 DAOSequence, __u8 path_sequence, __u8 path_lifetime,
+		__u8 path_control, bool *updated)
+{
+	int err = -EINVAL;
+	bool update_required = false;
+	if(!target || !transit_info)
+	{
+		RPL_PRINTK(0, err, "RPL: %s: transit is NULL\n", __func__);
+		goto out;
+	}
+	if(transit_info->DAOSequence != DAOSequence){
+		transit_info->DAOSequence = DAOSequence;
+		update_required = true;
+	}
+	if(transit_info->path_sequence != path_sequence){
+		transit_info->path_sequence = path_sequence;
+		update_required = true;
+	}
+	if(transit_info->path_lifetime != path_lifetime){
+		transit_info->path_lifetime = path_lifetime;
+		update_required = true;
+	}
+	if(transit_info->path_control != path_control){
+		transit_info->path_control = path_control;
+		update_required = true;
+	}
+	if((update_required || transit_info->path_lifetime == 0) && transit_info->installed){
+		rpl_del_route(transit_info->dev, &target->prefix,
+				target->prefix_len, &transit_info->next_hop);
+	}
+	transit_info->installed = false;
+	if(updated)
+		*updated = update_required;
+	err = 0;
+out:
+	return err;
+}
+
+/*
+ * This function compares two transit info to a given target.
+ * This function is to be used with list_sort.
+ * It compares two transit info with goal of sorting a list of transit infos from
+ * best transit info, to worst.
+ *
+ * It first compares path_sequences, choosing higher value.
+ * For same path_sequences, it chooses higher path_lifetime.
+ * If same path_lifetime, it chooses one_hop transit_info.
+ */
+int rpl_transit_info_cmp(void *ptarget, struct list_head *l1, struct list_head *l2)
+{
+	struct rpl_target *target = (struct rpl_target *) ptarget;
+	struct rpl_target_transit_info *t1,*t2;
+	int res = 0;
+	if(!target)
+		return res;
+	t1 = list_entry(l1,struct rpl_target_transit_info,transit_info_list);
+	t2 = list_entry(l2,struct rpl_target_transit_info,transit_info_list);
+
+	if(lollipop_greater_than(t1->path_sequence,t2->path_sequence)){
+		/*
+		 * most recent
+		 */
+		res = 1;
+	} else if(t1->path_sequence == t2->path_sequence){
+		if(t1->path_lifetime > t2->path_lifetime){
+			res = -1;
+		} else if(t1->path_lifetime < t2->path_lifetime){
+			res = 1;
+		} else {
+			if(t1->one_hop && !t2->one_hop){
+				res = -1;
+			} else if(!t1->one_hop && t2->one_hop){
+				res = 1;
+			} else {
+				res = 0;
+			}
+		}
+	} else {
+		res = -1;
+	}
+	return res;
+}
+
+int rpl_node_unset_default_route(struct rpl_node *parent)
+{
+	struct rt6_info *rt = NULL;
+	struct neighbour *neigh = NULL;
+	int err = -EINVAL;
+
+	if(parent)
+	{
+		rt = rt6_get_dflt_router(&parent->addr, parent->dev);
+		if (rt) {
+			neigh = dst_neigh_lookup(&rt->dst, &parent->addr);
+			if (!neigh) {
+				RPL_PRINTK(0, err,
+					  "RPL: %s got default router without neighbour\n",
+					  __func__);
+				ip6_rt_put(rt);
+				err = -ENXIO;
+				goto out;
+			}
+		}
+		if (rt) {
+			err = ip6_del_rt(rt);
+			if(err){
+				RPL_PRINTK(0, err,
+					  "RPL: %s some error occur removing default route\n",
+					  __func__);
+			}
+			rt = NULL;
+		}
+		err = 0;
+		if(neigh)
+			neigh_release(neigh);
+	}
+out:
+	return err;
+}
+
+int rpl_node_set_default_route(struct rpl_node *parent)
+{
+	int err = -EINVAL;
+	struct rt6_info *rt = NULL;
+	struct neighbour *neigh = NULL;
+	int lifetime;
+	int pref = 0;
+
+	if(parent)
+	{
+		rt = rt6_get_dflt_router(&parent->addr, parent->dev);
+		if (rt) {
+			neigh = dst_neigh_lookup(&rt->dst, &parent->addr);
+			if (!neigh) {
+				RPL_PRINTK(0, err,
+					  "RPL: %s got default router without neighbour\n",
+					  __func__);
+				ip6_rt_put(rt);
+				rt = NULL;
+				err = -ENXIO;
+				goto out;
+			}
+		}
+		if (rt) {
+			err = ip6_del_rt(rt);
+			if(err){
+				RPL_PRINTK(0, err,
+					  "RPL: %s some error occur removing default route\n",
+					  __func__);
+			}
+			rt = NULL;
+		}
+		lifetime = parent->dag->lifetime_unit*parent->dag->def_lifetime;
+		lifetime &= 0xFFFF; //FIXME kernel 3.8.13 complain about lifetime too big >4bytes (int?)
+		if (rt == NULL && lifetime) {
+			RPL_PRINTK(3, dbg, "RPL: adding default router\n");
+
+			rt = rt6_add_dflt_router(&parent->addr, parent->dev, pref);
+			if (rt == NULL) {
+				RPL_PRINTK(0, err,
+					  "RPL: %s failed to add default route\n",
+					  __func__);
+				err = -ENXIO;
+				goto out;
+			}
+
+			neigh = dst_neigh_lookup(&rt->dst, &parent->addr);
+			if (neigh == NULL) {
+				RPL_PRINTK(0, err,
+					  "RPL: %s got default router without neighbour\n",
+					  __func__);
+				ip6_rt_put(rt);
+				rt = NULL;
+				err = -ENXIO;
+				goto out;
+			}
+			neigh->flags |= NTF_ROUTER;
+		} else if (rt) {
+			rt->rt6i_flags = (rt->rt6i_flags & ~RTF_PREF_MASK) | RTF_PREF(pref);
+		}
+
+		if (rt)
+			rt6_set_expires(rt, jiffies + (HZ * lifetime));
+
+		err = 0;
+	}
+out:
+	if(rt)
+		ip6_rt_put(rt);
+	if (neigh)
+		neigh_release(neigh);
+	return err;
+}
+
+
+static int __ip6_del_rt(struct rt6_info *rt, struct nl_info *info)
+{
+	int err;
+	struct fib6_table *table;
+	struct net *net = dev_net(rt->dst.dev);
+
+	if (rt == net->ipv6.ip6_null_entry) {
+		err = -ENOENT;
+		goto out;
+	}
+
+	table = rt->rt6i_table;
+	write_lock_bh(&table->tb6_lock);
+	err = fib6_del(rt, info);
+	write_unlock_bh(&table->tb6_lock);
+
+out:
+	ip6_rt_put(rt);
+	return err;
+}
+
+static int ip6_route_del(struct fib6_config *cfg)
+{
+	struct fib6_table *table;
+	struct fib6_node *fn;
+	struct rt6_info *rt;
+	int err = -ESRCH;
+
+	table = fib6_get_table(cfg->fc_nlinfo.nl_net, cfg->fc_table);
+	if (!table)
+		return err;
+
+	read_lock_bh(&table->tb6_lock);
+
+	fn = fib6_locate(&table->tb6_root,
+			 &cfg->fc_dst, cfg->fc_dst_len,
+			 &cfg->fc_src, cfg->fc_src_len);
+
+	if (fn) {
+		for (rt = fn->leaf; rt; rt = rt->dst.rt6_next) {
+			if (cfg->fc_ifindex &&
+			    (!rt->dst.dev ||
+			     rt->dst.dev->ifindex != cfg->fc_ifindex))
+				continue;
+			if ((cfg->fc_flags & RTF_GATEWAY) &&
+			    !ipv6_addr_equal(&cfg->fc_gateway, &rt->rt6i_gateway))
+				continue;
+			if (cfg->fc_metric && cfg->fc_metric != rt->rt6i_metric)
+				continue;
+			dst_hold(&rt->dst);
+			read_unlock_bh(&table->tb6_lock);
+
+			return __ip6_del_rt(rt, &cfg->fc_nlinfo);
+		}
+	}
+	read_unlock_bh(&table->tb6_lock);
+
+	return err;
+}
+
+int rpl_del_route(struct net_device *dev, const struct in6_addr *target_addr,
+		__u8 target_addr_len, const struct in6_addr *next_hop) {
+	int err = -EINVAL;
+	int pref = 0;
+	struct fib6_config cfg;
+
+	if(!dev || !target_addr || !next_hop) {
+		RPL_PRINTK(0, err,
+				"%s(): Null pointers.\n",
+				__func__);
+		goto out;
+	}
+
+//	RPL_PRINTK(1, err, "%s(): target: %pI6/%d\n", __func__,target_addr,target_addr_len);
+//	RPL_PRINTK(1, err, "%s(): next_hop: %pI6\n", __func__,next_hop);
+
+	memset(&cfg, 0, sizeof(cfg));
+	cfg.fc_table	= RT6_TABLE_DFLT;
+	cfg.fc_metric	= IP6_RT_PRIO_USER;
+	cfg.fc_ifindex	= dev->ifindex;
+	cfg.fc_flags	= RTF_GATEWAY | RTF_PREF(pref);
+	cfg.fc_nlinfo.portid = 0;
+	cfg.fc_nlinfo.nlh = NULL;
+	cfg.fc_nlinfo.nl_net = dev_net(dev);
+	cfg.fc_dst = *target_addr;
+	cfg.fc_dst_len = target_addr_len;
+	cfg.fc_gateway = *next_hop;
+
+	err = ip6_route_del(&cfg);
+
+	err = 0;
+out:
+	return err;
+}
+
+void rpl_transit_info_dbg_dump(struct rpl_target_transit_info *transit_info)
+{
+	if(transit_info)
+	{
+		printk(KERN_DEBUG "%s(): NextHop: %pI6%%%s\n",__func__,&transit_info->next_hop,transit_info->dev->name);
+		printk(KERN_DEBUG "%s(): DAOSequence: %u\n", __func__,transit_info->DAOSequence);
+		printk(KERN_DEBUG "%s(): Path Sequence: %u\n", __func__,transit_info->path_sequence);
+		printk(KERN_DEBUG "%s(): Path Lifetime: %u\n", __func__,transit_info->path_lifetime);
+		printk(KERN_DEBUG "%s(): Path Control: %u\n", __func__,transit_info->path_control);
+		printk(KERN_DEBUG "%s(): OneHop: %s\n", __func__,(transit_info->one_hop)?"Yes":"No");
+		printk(KERN_DEBUG "%s(): Installed: %s\n", __func__,(transit_info->installed)?"Yes":"No");
+	}
+}
+
+void rpl_target_dbg_dump(struct rpl_target *target)
+{
+	struct rpl_target_transit_info *transit_info;
+	if(target)
+	{
+		printk(KERN_DEBUG "%s(): Prefix: %pI6/%u\n",__func__,&target->prefix,target->prefix_len);
+		list_for_each_entry(transit_info,&target->transit_head,transit_info_list)
+		{
+			rpl_transit_info_dbg_dump(transit_info);
+		}
+	}
+}
+
+void rpl_node_dbg_dump(struct rpl_node *node)
+{
+	if(node)
+	{
+		printk(KERN_DEBUG "%s(): Addr: %pI6%%%s\n",__func__,&node->addr,node->dev->name);
+		if(node->dag)
+		{
+			printk(KERN_DEBUG "%s(): DodagID: %pI6\n",__func__,&node->dag->dodagid);
+		}
+		printk(KERN_DEBUG "%s(): IsDAOParent: %u\n", __func__,node->is_dao_parent);
+		printk(KERN_DEBUG "%s(): IsDODAGParent: %u\n", __func__,node->is_dodag_parent);
+		printk(KERN_DEBUG "%s(): IsPreferred: %u\n", __func__,node->is_preferred);
+
+		printk(KERN_DEBUG "%s(): Rank: %u\n", __func__,node->rank);
+		printk(KERN_DEBUG "%s(): DTSN: %u\n", __func__,node->dtsn);
+		printk(KERN_DEBUG "%s(): LinkMetric: %u\n", __func__,node->metric_link);
+	} else {
+		RPL_PRINTK(2, dbg, "%s(): null parent\n", __func__);
+	}
+}
diff --git a/net/ipv6/rpl/rpl_debug.c b/net/ipv6/rpl/rpl_debug.c
new file mode 100644
index 0000000..06210ba
--- /dev/null
+++ b/net/ipv6/rpl/rpl_debug.c
@@ -0,0 +1,472 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_debug.c
+ *
+ * @date Jul 23, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#define DEBUG 1
+
+#ifdef __KERNEL__
+#include <linux/inet.h>
+#include <net/sock.h>
+#include <net/rpl/rpl_debug.h>
+#include <net/rpl/rpl_constants.h>
+#else
+#include <stdio.h>
+#include <arpa/inet.h>
+#endif /* __KERNEL__ */
+
+#ifdef RPL_CONFIG_DEBUG_NETDEV
+/* This is for debugging reference counting of devices */
+int netdev_debug __read_mostly = 1;
+
+void __dev_hold(struct net_device *dev, const char *func)
+{
+	this_cpu_inc(*dev->pcpu_refcnt);
+	if (unlikely(netdev_debug))
+		printk(KERN_DEBUG "%s(%X): dev_hold %d %s\n",dev->name, dev, netdev_refcnt_read(dev), func);
+}
+EXPORT_SYMBOL(__dev_hold);
+
+void __dev_put(struct net_device *dev, const char *func)
+{
+	BUG_ON(netdev_refcnt_read(dev) == 0);
+	if (unlikely(netdev_debug))
+		printk(KERN_DEBUG "%s(%X): dev_put %d %s\n",dev->name, dev, netdev_refcnt_read(dev), func);
+	this_cpu_dec(*dev->pcpu_refcnt);
+}
+EXPORT_SYMBOL(__dev_put);
+#endif
+
+ssize_t icmpv6_rpl_print_option(__u8 *offset)
+{
+	int i = 0;
+	__u8 type = 0;
+	__u8 len = 0;
+	u_rpl_option *option = NULL;
+#ifndef __KERNEL__
+	char s_in6_addr[INET6_ADDRSTRLEN] = {};
+#endif
+	if(!offset)
+		return -1;
+	type = *(offset);
+
+	printk(KERN_DEBUG "%s(): ___________________________________\n", __func__);
+	/*
+	 * NOTE!  The format of the Pad1 option is a special case,
+	 * it has neither Option Length nor Option Data fields.
+	 */
+	if(type == ICMPV6_RPL_OPT_Pad1)
+	{
+		printk(KERN_DEBUG "%s(): Type: Pad1\n", __func__);
+		return 1;
+	}
+
+	len = *(offset+1);
+
+	printk(KERN_DEBUG "%s(): Length: %u\n", __func__,len);
+
+	option = (u_rpl_option *) offset;
+
+	switch(type){
+	case ICMPV6_RPL_OPT_PadN:
+		printk(KERN_DEBUG "%s(): Type: PadN\n", __func__);
+		break;
+	case ICMPV6_RPL_OPT_DAG_Metric_Container:
+		printk(KERN_DEBUG "%s(): Type: DAG Metric Container\n", __func__);
+		printk(KERN_DEBUG "%s(): Data: ", __func__);
+		for(i=0;i<len;i++){
+			printk("%02X ",option->dag_metric_container.data[i]);
+		}
+		printk("\n");
+		break;
+	case ICMPV6_RPL_OPT_Route_Information:
+		printk(KERN_DEBUG "%s(): Type: Route Information\n", __func__);
+		printk(KERN_DEBUG "%s(): Prefix Length: %d\n", __func__,option->route_information.prefix_length);
+		printk(KERN_DEBUG "%s(): Preference: %d\n", __func__,RPL_RIO_Prf(option->route_information.Resvd_Prf_Resvd));
+		printk(KERN_DEBUG "%s(): Route Lifetime: %d\n", __func__,be32_to_cpu(option->route_information.route_lifetime));
+		printk(KERN_DEBUG "%s(): Prefix: ", __func__);
+		for(i=0;i<option->route_information.prefix_length/8;i++){
+			printk("%02X ",option->route_information.prefix[i]);
+		}
+		printk("\n");
+		break;
+	case ICMPV6_RPL_OPT_DODAG_Configuration:
+		printk(KERN_DEBUG "%s(): Type: DODAG Configuration\n", __func__);
+		if(RPL_DCO_A(option->dodag_configuration.flags_A_PCS))
+		{
+			printk(KERN_DEBUG "%s(): Authentication Enabled: Yes\n", __func__);
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): Authentication Enabled: NO\n", __func__);
+		}
+		printk(KERN_DEBUG "%s(): Path Control Size(PCS): %d\n", __func__,RPL_DCO_PCS(option->dodag_configuration.flags_A_PCS));
+		printk(KERN_DEBUG "%s(): Flags: %d\n", __func__,RPL_DCO_Flags(option->dodag_configuration.flags_A_PCS));
+
+		printk(KERN_DEBUG "%s(): DIOIntDoubl: %d\n", __func__,option->dodag_configuration.DIOIntDoubl);
+		printk(KERN_DEBUG "%s(): DIOIntMin: %d\n", __func__,option->dodag_configuration.DIOIntMin);
+		printk(KERN_DEBUG "%s(): DIORedun: %d\n", __func__,option->dodag_configuration.DIORedun);
+
+		printk(KERN_DEBUG "%s(): MaxRankIncrease: %u\n", __func__,be16_to_cpu(option->dodag_configuration.MaxRankIncrease));
+		printk(KERN_DEBUG "%s(): MinHopRankIncrease: %u\n", __func__,be16_to_cpu(option->dodag_configuration.MinHopRankIncrease));
+
+		printk(KERN_DEBUG "%s(): OCP: %d\n", __func__,be16_to_cpu(option->dodag_configuration.OCP));
+		printk(KERN_DEBUG "%s(): Default Lifetime: %d\n", __func__,option->dodag_configuration.def_lifetime);
+		printk(KERN_DEBUG "%s(): Lifetime Unit: %u\n", __func__,be16_to_cpu(option->dodag_configuration.lifetime_unit));
+		break;
+	case ICMPV6_RPL_OPT_RPL_Target:
+		printk(KERN_DEBUG "%s(): Type: RPL Target\n", __func__);
+		printk(KERN_DEBUG "%s(): Prefix Length: %d\n", __func__,option->rpl_target.prefix_length);
+		if(option->rpl_target.prefix_length == 128)
+		{
+#ifdef __KERNEL__
+			printk(KERN_DEBUG "%s(): Prefix: %pI6\n",__func__,&option->rpl_target.prefix);
+#else
+			inet_ntop(AF_INET6, &option->rpl_target.prefix, s_in6_addr, INET6_ADDRSTRLEN);
+			printk(KERN_DEBUG "%s(): Prefix: %s\n", __func__,s_in6_addr);
+#endif /* __KERNEL__*/
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): Prefix: ", __func__);
+			for(i=0;i<option->rpl_target.prefix_length/8;i++){
+				printk("%02X ",option->rpl_target.prefix[i]);
+			}
+			printk("\n");
+		}
+		break;
+	case ICMPV6_RPL_OPT_Transit_Information:
+		printk(KERN_DEBUG "%s(): Type: Transit Information\n", __func__);
+		if(RPL_TIO_E(option->transit_information.E_flags))
+		{
+			printk(KERN_DEBUG "%s(): External: Yes\n", __func__);
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): External: NO\n", __func__);
+		}
+		printk(KERN_DEBUG "%s(): PathControl: 0x%02X\n", __func__,option->transit_information.path_control);
+		printk(KERN_DEBUG "%s(): PathSequence: %d\n", __func__,option->transit_information.path_sequence);
+		printk(KERN_DEBUG "%s(): PathLifetime: %d\n", __func__,option->transit_information.path_lifetime);
+		if(len > 4)
+		{
+#ifdef __KERNEL__
+			printk(KERN_DEBUG "%s(): Parent: %pI6\n",__func__,&option->transit_information.parent);
+#else
+			inet_ntop(AF_INET6, &option->transit_information.parent, s_in6_addr, INET6_ADDRSTRLEN);
+			printk(KERN_DEBUG "%s(): Parent: %s\n", __func__,s_in6_addr);
+#endif /* __KERNEL__*/
+		}
+		break;
+	case ICMPV6_RPL_OPT_Solicited_Information:
+		printk(KERN_DEBUG "%s(): Type: Solicited Information\n", __func__);
+		printk(KERN_DEBUG "%s(): InstanceID: %d\n", __func__,option->solicited_information.instanceID);
+
+		if(RPL_SIO_V(option->solicited_information.VID_flags))
+		{
+			printk(KERN_DEBUG "%s(): Version Predicate: Yes\n", __func__);
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): Version Predicate: NO\n", __func__);
+		}
+
+		if(RPL_SIO_I(option->solicited_information.VID_flags))
+		{
+			printk(KERN_DEBUG "%s(): InstanceID Predicate: Yes\n", __func__);
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): InstanceID Predicate: NO\n", __func__);
+		}
+
+		if(RPL_SIO_D(option->solicited_information.VID_flags))
+		{
+			printk(KERN_DEBUG "%s(): DodagID Predicate: Yes\n", __func__);
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): DodagID Predicate: NO\n", __func__);
+		}
+#ifdef __KERNEL__
+		printk(KERN_DEBUG "%s(): DodagID: %pI6\n",__func__,&option->solicited_information.dodagid);
+#else
+		inet_ntop(AF_INET6, &option->solicited_information.dodagid, s_in6_addr, INET6_ADDRSTRLEN);
+		printk(KERN_DEBUG "%s(): DodagID: %s\n", __func__,s_in6_addr);
+#endif /* __KERNEL__*/
+
+		printk(KERN_DEBUG "%s(): Version: %d\n", __func__,option->solicited_information.version);
+		break;
+	case ICMPV6_RPL_OPT_Prefix_Information:
+		printk(KERN_DEBUG "%s(): Type: Prefix Information\n", __func__);
+		printk(KERN_DEBUG "%s(): Prefix Length: %d\n", __func__,option->prefix_information.prefix_length);
+		if(RPL_PIO_L(option->prefix_information.LAR_reserved1))
+		{
+			printk(KERN_DEBUG "%s(): On-Link Flag: Yes\n", __func__);
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): On-Link Flag: NO\n", __func__);
+		}
+		if(RPL_PIO_A(option->prefix_information.LAR_reserved1))
+		{
+			printk(KERN_DEBUG "%s(): Autonomous Address-Configuration: Yes\n", __func__);
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): Autonomous Address-Configuration: NO\n", __func__);
+		}
+		if(RPL_PIO_R(option->prefix_information.LAR_reserved1))
+		{
+			printk(KERN_DEBUG "%s(): Router Address: Yes\n", __func__);
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): Router Address: NO\n", __func__);
+		}
+		printk(KERN_DEBUG "%s(): Valid Lifetime: %u\n", __func__,be32_to_cpu(option->prefix_information.valid_lifetime));
+		printk(KERN_DEBUG "%s(): Preferred Lifetime: %u\n", __func__,be32_to_cpu(option->prefix_information.preferred_lifetime));
+		if(option->prefix_information.prefix_length == 128)
+		{
+#ifdef __KERNEL__
+			printk(KERN_DEBUG "%s(): Prefix: %pI6\n",__func__,&option->prefix_information.prefix);
+#else
+			inet_ntop(AF_INET6, &option->prefix_information.prefix, s_in6_addr, INET6_ADDRSTRLEN);
+			printk(KERN_DEBUG "%s(): Prefix: %s\n", __func__,s_in6_addr);
+#endif /* __KERNEL__*/
+		}
+		else
+		{
+			printk(KERN_DEBUG "%s(): Prefix: ", __func__);
+			for(i=0;i<option->prefix_information.prefix_length/8;i++){
+				printk("%02X ",option->prefix_information.prefix[i]);
+			}
+			printk("\n");
+		}
+		break;
+	case ICMPV6_RPL_OPT_RPL_Target_Descriptor:
+		printk(KERN_DEBUG "%s(): Type: Target Descriptor\n", __func__);
+		printk(KERN_DEBUG "%s(): Descriptor: %u\n", __func__,be32_to_cpu(option->rpl_target_descriptor.descriptor));
+		break;
+	default:
+		printk(KERN_DEBUG "%s(): Type: Unknown (0x%02X)\n", __func__,type);
+	}
+	return len+2;
+}
+
+void icmpv6_rpl_print_options(__u8 *offset, size_t len)
+{
+	size_t len_printed = 0;
+	ssize_t option_len = 0;
+	while(len_printed<len){
+		if((option_len = icmpv6_rpl_print_option(offset+len_printed))<0)
+			break;
+		len_printed += option_len;
+	}
+}
+
+void icmpv6_rpl_print_msg(struct rpl_msg *msg, size_t len)
+{
+	size_t non_options_len = 4;
+#ifndef __KERNEL__
+	char s_in6_addr[INET6_ADDRSTRLEN] = {};
+#endif
+	if(msg)
+	{
+		if(msg->icmp6_type != ICMPV6_RPL){
+			pr_debug("%s: not RPL message\n",__func__);
+			return;
+		}
+		printk(KERN_DEBUG "%s(): ______________________________________________________\n", __func__);
+		switch (msg->icmp6_code) {
+			case ICMPV6_RPL_DIS:
+				printk(KERN_DEBUG "%s(): Code: DIS\n", __func__);
+				printk(KERN_DEBUG "%s(): Flags: 0x%02X\n", __func__,msg->base.dis.flags);
+				printk(KERN_DEBUG "%s(): Reserved: 0x%02X\n", __func__,msg->base.dis.reserved);
+				non_options_len += 2;
+				icmpv6_rpl_print_options((__u8 *)msg->base.dis.dis_options,len-non_options_len);
+				break;
+			case ICMPV6_RPL_DIO:
+				printk(KERN_DEBUG "%s(): Code: DIO\n", __func__);
+				printk(KERN_DEBUG "%s(): InstanceID: %d\n", __func__,msg->base.dio.instanceID);
+				printk(KERN_DEBUG "%s(): Version: %d\n", __func__,msg->base.dio.version);
+				printk(KERN_DEBUG "%s(): Rank: %u\n", __func__,be16_to_cpu(msg->base.dio.rank));
+				if(RPL_DIO_IS_GROUNDED(msg->base.dio.g_mop_prf))
+				{
+					printk(KERN_DEBUG "%s(): Grounded: Yes\n", __func__);
+				}
+				else
+				{
+					printk(KERN_DEBUG "%s(): Grounded: No, floating\n", __func__);
+				}
+				printk(KERN_DEBUG "%s(): MOP: %d\n", __func__,RPL_DIO_MOP(msg->base.dio.g_mop_prf));
+				switch(RPL_DIO_MOP(msg->base.dio.g_mop_prf))
+				{
+				case 0:
+					printk(KERN_DEBUG "%s(): MOP: 0: No Downward routes maintained by RPL\n",__func__);
+					break;
+				case 1:
+					printk(KERN_DEBUG "%s(): MOP: 1: Non-Storing Mode of Operation\n",__func__);
+					break;
+				case 2:
+					printk(KERN_DEBUG "%s(): MOP: 2: Storing Mode of Operation with no multicast support\n",__func__);
+					break;
+				case 3:
+					printk(KERN_DEBUG "%s(): MOP: 3: Storing Mode of Operation with multicast support\n",__func__);
+					break;
+				default:
+					printk(KERN_DEBUG "%s(): MOP: %d: unassigned\n",__func__,RPL_DIO_MOP(msg->base.dio.g_mop_prf));
+				}
+				printk(KERN_DEBUG "%s(): Prf: %d\n", __func__,RPL_DIO_Prf(msg->base.dio.g_mop_prf));
+				printk(KERN_DEBUG "%s(): DTSN: %d\n", __func__,msg->base.dio.DTSN);
+				printk(KERN_DEBUG "%s(): Flags: 0x%02X\n", __func__,msg->base.dio.flags);
+				printk(KERN_DEBUG "%s(): Reserved: 0x%02X\n", __func__,msg->base.dio.reserved);
+#ifdef __KERNEL__
+				printk(KERN_DEBUG "%s(): DodagID: %pI6\n",__func__,&msg->base.dio.dodagid);
+#else
+				inet_ntop(AF_INET6, &msg->base.dio.dodagid, s_in6_addr, INET6_ADDRSTRLEN);
+				printk(KERN_DEBUG "%s(): DodagID: %s\n", __func__,s_in6_addr);
+#endif /* __KERNEL__*/
+				non_options_len += 24;
+				icmpv6_rpl_print_options((__u8 *)msg->base.dio.dio_options,len-non_options_len);
+				break;
+			case ICMPV6_RPL_DAO:
+				printk(KERN_DEBUG "%s(): Code: DAO\n", __func__);
+				printk(KERN_DEBUG "%s(): InstanceID: %d\n", __func__,msg->base.dao.instanceID);
+				printk(KERN_DEBUG "%s(): DAOSequence: %d\n", __func__,msg->base.dao.DAOSequence);
+				if(RPL_DAO_K(msg->base.dao.KD_flags))
+				{
+					printk(KERN_DEBUG "%s(): DAO-ACK: Expected\n", __func__);
+				}
+				else
+				{
+					printk(KERN_DEBUG "%s(): DAO-ACK: Not expected\n", __func__);
+				}
+				printk(KERN_DEBUG "%s(): Flags: 0x%02X\n", __func__,RPL_DAO_FLAGS(msg->base.dao.KD_flags));
+				printk(KERN_DEBUG "%s(): Reserved: 0x%02X\n", __func__,msg->base.dao.reserved);
+				if(RPL_DAO_D(msg->base.dao.KD_flags))
+				{
+					// the DODAGID field is present
+#ifdef __KERNEL__
+					printk(KERN_DEBUG "%s(): DodagID: %pI6\n",__func__,&msg->base.dao.u_with_dodagid.dodagid);
+#else
+					inet_ntop(AF_INET6, &msg->base.dao.u_with_dodagid.dodagid, s_in6_addr, INET6_ADDRSTRLEN);
+					printk(KERN_DEBUG "%s(): DodagID: %s\n", __func__,s_in6_addr);
+#endif /* __KERNEL__*/
+
+					non_options_len  += 20;
+					icmpv6_rpl_print_options((__u8 *)msg->base.dao.u_with_dodagid.dao_options,len-non_options_len);
+				}
+				else
+				{
+					non_options_len += 4;
+					// the DODAGID field is NOT present
+					icmpv6_rpl_print_options((__u8 *)msg->base.dao.u_no_dodagid.dao_options,len-non_options_len);
+				}
+				break;
+			case ICMPV6_RPL_DAO_ACK:
+				printk(KERN_DEBUG "%s(): Code: DAO_ACK\n", __func__);
+				printk(KERN_DEBUG "%s(): InstanceID: %d\n", __func__,msg->base.dao_ack.instanceID);
+				printk(KERN_DEBUG "%s(): DAOSequence: %d\n", __func__,msg->base.dao_ack.DAOSequence);
+				printk(KERN_DEBUG "%s(): Reserved: 0x%02X\n", __func__,RPL_DAO_ACK_Reserved(msg->base.dao_ack.D_reserved));
+				if(msg->base.dao_ack.status == 0)
+				{
+					printk(KERN_DEBUG "%s(): Status: 0: Unqualified acceptance\n", __func__);
+				}
+				else if( msg->base.dao_ack.status < 128)
+				{
+					printk(KERN_DEBUG "%s(): Status: %d: Not an outright rejection\n", __func__,msg->base.dao_ack.status);
+				}
+				else
+				{
+					printk(KERN_DEBUG "%s(): Status: %d: Rejection\n", __func__,msg->base.dao_ack.status);
+				}
+				if(RPL_DAO_ACK_D(msg->base.dao_ack.D_reserved))
+				{
+					non_options_len += 20;
+					// the DODAGID field is present
+#ifdef __KERNEL__
+					printk(KERN_DEBUG "%s(): DodagID: %pI6\n",__func__,&msg->base.dao_ack.u_with_dodagid.dodagid);
+#else
+					inet_ntop(AF_INET6, &msg->base.dao_ack.u_with_dodagid.dodagid, s_in6_addr, INET6_ADDRSTRLEN);
+					printk(KERN_DEBUG "%s(): DodagID: %s\n", __func__,s_in6_addr);
+#endif /* __KERNEL__*/
+					icmpv6_rpl_print_options((__u8 *)msg->base.dao_ack.u_with_dodagid.dao_ack_options,len-non_options_len);
+				}
+				else
+				{
+					non_options_len += 4;
+					// the DODAGID field is NOT present
+					icmpv6_rpl_print_options((__u8 *)msg->base.dao_ack.u_no_dodagid.dao_ack_options,len-non_options_len);
+				}
+				break;
+			case ICMPV6_RPL_SEC_DIS:
+				printk(KERN_DEBUG "%s(): Code: SEC_DIS\n", __func__);
+				break;
+			case ICMPV6_RPL_SEC_DIO:
+				printk(KERN_DEBUG "%s(): Code: SEC_DIO\n", __func__);
+				break;
+			case ICMPV6_RPL_SEC_DAO:
+				printk(KERN_DEBUG "%s(): Code: SEC_DAO\n", __func__);
+				break;
+			case ICMPV6_RPL_SEC_DAO_ACK:
+				printk(KERN_DEBUG "%s(): Code: SEC_DAO_ACK\n", __func__);
+				break;
+			case ICMPV6_RPL_CC:
+				printk(KERN_DEBUG "%s(): Code: CC\n", __func__);
+				printk(KERN_DEBUG "%s(): InstanceID: %d\n", __func__,msg->base.cc.instanceID);
+				if(RPL_CC_IS_RESPONSE(msg->base.cc.R_flags))
+				{
+					printk(KERN_DEBUG "%s(): Is Response: Yes\n", __func__);
+				}
+				else
+				{
+					printk(KERN_DEBUG "%s(): Is Response: NO\n", __func__);
+				}
+				printk(KERN_DEBUG "%s(): Flags: 0x%02X\n", __func__,RPL_CC_Flags(msg->base.cc.R_flags));
+				printk(KERN_DEBUG "%s(): Nonce: %d\n", __func__,msg->base.cc.CCNonce);
+#ifdef __KERNEL__
+				printk(KERN_DEBUG "%s(): DodagID: %pI6\n",__func__,&msg->base.cc.dodagid);
+#else
+				inet_ntop(AF_INET6, &msg->base.cc.dodagid, s_in6_addr, INET6_ADDRSTRLEN);
+				printk(KERN_DEBUG "%s(): DodagID: %s\n", __func__,s_in6_addr);
+#endif /* __KERNEL__*/
+				printk(KERN_DEBUG "%s(): Destination Counter: %u\n", __func__,be32_to_cpu(msg->base.cc.dest_counter));
+				non_options_len += 24;
+				// TODO print options
+				break;
+			default:
+				printk(KERN_DEBUG "%s(): Code: Unknown (0x%02X)\n", __func__,msg->icmp6_code);
+				break;
+		}
+	} else {
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+	}
+}
+/*
+void rpl_msg_buf_print(struct rpl_msg_buf *rpl_msg_buf)
+{
+	if(rpl_msg_buf)
+	{
+		printk(KERN_DEBUG "%s(): buf len: %d\n", __func__,rpl_msg_buf->len);
+		icmpv6_rpl_print_msg(rpl_msg_buf->rpl_msg,rpl_msg_buf->len);
+	} else {
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+	}
+}
+*/
diff --git a/net/ipv6/rpl/rpl_icmp6.c b/net/ipv6/rpl/rpl_icmp6.c
new file mode 100644
index 0000000..524764d
--- /dev/null
+++ b/net/ipv6/rpl/rpl_icmp6.c
@@ -0,0 +1,1883 @@
+/*
+ *	RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_icmp6.c
+ *
+ * @date Aug 3, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#define pr_fmt(fmt) "ICMPv6: " fmt
+
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/socket.h>
+#include <linux/netdevice.h>
+#include <linux/ipv6.h>
+#include <net/if_inet6.h>
+#include <net/ip6_route.h>
+#include <net/addrconf.h>
+#include <net/rpl/rpl_constants.h>
+#include <net/rpl/rpl_internals.h>
+#include <net/rpl/rpl_debug.h>
+
+#define RPL_DEBUG 3
+
+#define RPL_PRINTK(val, level, fmt, ...)				\
+do {								\
+	if (val <= RPL_DEBUG)					\
+		net_##level##_ratelimited(fmt, ##__VA_ARGS__);	\
+} while (0)
+
+static void ip6_rpl_hdr(struct sk_buff *skb,
+		       const struct in6_addr *saddr,
+		       const struct in6_addr *daddr,
+		       int hop_limit, int len)
+{
+	struct ipv6hdr *hdr;
+
+	skb_push(skb, sizeof(*hdr));
+	skb_reset_network_header(skb);
+	hdr = ipv6_hdr(skb);
+
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 9, 0))
+	*(__be32 *)hdr = htonl(0x60000000 | (0 << 20)) | 0;
+#else
+	ip6_flow_hdr(hdr, 0, 0);
+#endif
+
+	hdr->payload_len = htons(len);
+	hdr->nexthdr = IPPROTO_ICMPV6;
+	hdr->hop_limit = hop_limit;
+
+	hdr->saddr = *saddr;
+	hdr->daddr = *daddr;
+}
+
+static void rpl_send_skb(struct sk_buff *skb, const struct in6_addr *daddr,
+		const struct in6_addr *saddr) {
+	struct dst_entry *dst = skb_dst(skb);
+	struct net *net = dev_net(skb->dev);
+	struct sock *sk = net->ipv6.rpl.rpl_sk;
+	struct inet6_dev *idev;
+	int err;
+	struct icmp6hdr *icmp6h = icmp6_hdr(skb);
+	u8 type;
+
+	type = icmp6h->icmp6_type;
+
+	if (!dst) {
+		struct sock *sk = net->ipv6.rpl.rpl_sk;
+		struct flowi6 fl6;
+
+		icmpv6_flow_init(sk, &fl6, type, saddr, daddr, skb->dev->ifindex);
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 9, 0))
+		dst = icmp6_dst_alloc(skb->dev, NULL, &fl6);
+#else
+		dst = icmp6_dst_alloc(skb->dev, &fl6);
+#endif
+		if (IS_ERR(dst)) {
+			kfree_skb(skb);
+			return;
+		}
+
+		skb_dst_set(skb, dst);
+	}
+	icmp6h->icmp6_cksum = 0;
+
+	icmp6h->icmp6_cksum = csum_ipv6_magic(saddr, daddr, skb->len,
+			IPPROTO_ICMPV6, csum_partial(icmp6h, skb->len, 0));
+
+	ip6_rpl_hdr(skb, saddr, daddr, inet6_sk(sk)->hop_limit, skb->len);
+
+	rcu_read_lock();
+	idev = __in6_dev_get(dst->dev);
+	IP6_UPD_PO_STATS(net, idev, IPSTATS_MIB_OUT, skb->len);
+
+	err = NF_HOOK(NFPROTO_IPV6, NF_INET_LOCAL_OUT, skb, NULL, dst->dev,
+			dst_output);
+	if (!err) {
+		ICMP6MSGOUT_INC_STATS(net, idev, type);
+		ICMP6_INC_STATS(net, idev, ICMP6_MIB_OUTMSGS);
+	}
+
+	rcu_read_unlock();
+}
+
+int rpl_send_dis(struct rpl_enabled_device *enabled_device) {
+	int err = 0;
+	struct sk_buff *skb;
+	struct in6_addr addr_buf;
+	struct in6_addr *saddr;
+
+	if ((err = ipv6_get_lladdr(enabled_device->dev, &addr_buf,
+			(IFA_F_TENTATIVE | IFA_F_OPTIMISTIC))) != 0) {
+		RPL_PRINTK(0, err, "rpl: %s: failed calling ipv6_get_lladdr, err=%d\n",
+				__func__, err);
+		goto out;
+	}
+	saddr = &addr_buf;
+	skb = icmpv6_rpl_dis_new(enabled_device->dev);
+	if (!skb) {
+		err = -ENOMEM;
+		goto out;
+	}
+
+	if(enabled_device->solicited_information){
+		icmpv6_rpl_add_option_solicited_information(
+				skb,
+				enabled_device->solicited_information->instanceID,
+				RPL_SIO_V(enabled_device->solicited_information->VID_flags),
+				RPL_SIO_I(enabled_device->solicited_information->VID_flags),
+				RPL_SIO_D(enabled_device->solicited_information->VID_flags),
+				&enabled_device->solicited_information->dodagid,
+				enabled_device->solicited_information->version);
+	}
+
+	rpl_send_skb(skb, &in6addr_all_rpl_nodes, saddr);
+out:
+	return err;
+}
+
+static int _rpl_send_dio(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *daddr, bool add_dodag_conf_option, bool poison){
+	int err = 0;
+	struct sk_buff *skb;
+	struct in6_addr addr_buf;
+	struct in6_addr *saddr;
+
+	if ((err = ipv6_get_lladdr(dev, &addr_buf, (IFA_F_TENTATIVE | IFA_F_OPTIMISTIC))) != 0)
+	{
+		RPL_PRINTK(0, err, "rpl: %s: failed calling ipv6_get_lladdr, err=%d\n",
+			  __func__, err);
+		goto out;
+	}
+
+	saddr = &addr_buf;
+	skb = icmpv6_rpl_dio_new(dev, dag->instance->instanceID,
+			dag->version, (poison)?RPL_INFINITE_RANK:dag->rank, dag->grounded, dag->mop, dag->preference,
+			dag->DTSN, &dag->dodagid);
+	if (!skb)
+	{
+		err = -ENOMEM;
+		goto out;
+	}
+
+	if((daddr == NULL || add_dodag_conf_option) && !poison)
+	{
+		icmpv6_rpl_add_option_dodag_configuration(skb, dag->authenticated,
+				dag->PCS, dag->DIOIntDoubl, dag->DIOIntMin, dag->DIORedun,
+				dag->MaxRankIncrease, dag->MinHopRankIncrease,
+				dag->instance->of->ocp, dag->def_lifetime, dag->lifetime_unit);
+	}
+	if((daddr == NULL && dag->prefix_info) && !poison)
+	{
+		icmpv6_rpl_add_option_prefix_information(skb,
+				dag->prefix_info->prefix_len, dag->prefix_info->onlink,
+				dag->prefix_info->autoconf, 0, be32_to_cpu(dag->prefix_info->valid),
+				be32_to_cpu(dag->prefix_info->prefered), (__u8*)&dag->prefix_info->prefix);
+	}
+
+	if(!daddr)
+	{
+		daddr = &in6addr_all_rpl_nodes;
+	}
+	rpl_send_skb(skb, daddr, saddr);
+
+	err = 0;
+out:
+	return err;
+}
+
+int rpl_send_dio(struct rpl_dag *dag, struct net_device *dev, const struct in6_addr *daddr, bool add_dodag_conf_option, bool poison){
+	int err = 0;
+	struct rpl_allowed_if *allowed_if = NULL;
+
+	if(!dag)
+	{
+		RPL_PRINTK(0, err, "rpl: %s: dag is NULL\n",__func__);
+		goto out;
+	}
+
+	if(dev){
+		if(rpl_dag_is_allowed(dag,dev)){
+			err = _rpl_send_dio(dag,dev,daddr,add_dodag_conf_option,poison);
+			if (err){
+				RPL_PRINTK(0, err, "%s: failed send dio, err=%d\n",__func__, err);
+				goto out;
+			}
+		}
+	} else {
+		list_for_each_entry(allowed_if, &dag->allowed_interfaces,allowed_if_list){
+			if(allowed_if->enabled){
+				err = _rpl_send_dio(dag,allowed_if->dev,daddr,add_dodag_conf_option,poison);
+				if (err){
+					RPL_PRINTK(0, err, "%s: failed send dio, err=%d\n",__func__, err);
+					break;
+				}
+			}
+		}
+	}
+out:
+	return err;
+}
+
+/*
+ * RESET DAO Timer: When send DAOs:
+ * 1. the Path Lifetime is to be updated 										(check rpl_transit update) #1 DONE
+ * 3. when it receives DAO messages 											(on changes after rpl_recv_dao) #2
+ * 4. changes in its DAO parent set 											(on update upward routes) #3 DONE
+ * 5. expiry of a related prefix lifetime ???
+ * 6. it matters whether the DAO message is "new" or contains new information
+ * 		Storing Mode, DAO message is "new" if a target:
+ * 		6.1. it has a newer Path Sequence number								(on rpl_target_add and/or merge with new path_sequence) #4 DONE
+ * 		6.2. it has additional Path Control bits ???
+ * 		6.3. it is a No-Path DAO message 										(on rpl_target_set_no_path) #5 DONE
+ * 7. receiving a unicast DAO can trigger sending a unicast DAO to a DAO parent (same as 3.)
+ * 8. On receiving a unicast DAO message with updated information, such as
+ * 		containing a Transit Information option with a new Path Sequence		(same as 6.1)
+ * 9. When a node adds a node to its DAO parent set								(same as 4)
+ * 10. If a node hears one of its DAO parents increment its DTSN,				(on rpl_recv_dio new DTSN) #7
+ * 		the node MUST schedule a DAO message
+ * 11. as part of routine routing table updates and maintenance,
+ * 		a storing node MAY increment DTSN
+ * 12. 9.8 2) On receiving a unicast DAO, a node MUST compute if the DAO would	(same as 6.1, 6.3)
+       change the set of prefixes that the node itself advertises.  This
+       computation SHOULD include consultation of the Path Sequence
+       information in the Transit Information options associated with
+       the DAO, to determine if the DAO message contains newer
+       information that supersedes the information already stored at the
+       node.  If so, the node MUST generate a new DAO message and
+       transmit it, following the rules in Section 9.5.  Such a change
+       includes receiving a No-Path DAO
+ * 14. When a node removes a node from its DAO parent set, it SHOULD			(same as 4.)
+       send a No-Path DAO message (Section 6.4.3) to that removed DAO
+       parent to invalidate the existing route
+ */
+
+/* FIXME beaglebone black kernel 3.8.13
+ * [   54.238605] BUG: scheduling while atomic: swapper/0/0/0x40000100
+[   54.244889] Modules linked in: rpl_of_of0 g_multi libcomposite rfcomm ircomm_tty ircomm irda ipv6 hidp bluetooth rfkill autofs4
+[   54.257041] [<c001051d>] (unwind_backtrace+0x1/0x8c) from [<c03740b3>] (__schedule_bug+0x33/0x48)
+[   54.266315] [<c03740b3>] (__schedule_bug+0x33/0x48) from [<c0377573>] (__schedule+0x47/0x4c4)
+[   54.275230] [<c0377573>] (__schedule+0x47/0x4c4) from [<c0043727>] (__cond_resched+0x1b/0x24)
+[   54.284136] [<c0043727>] (__cond_resched+0x1b/0x24) from [<c0377a4d>] (_cond_resched+0x25/0x28)
+[   54.293228] [<c0377a4d>] (_cond_resched+0x25/0x28) from [<c000ec93>] (dump_mem+0x53/0xbc)
+[   54.301776] [<c000ec93>] (dump_mem+0x53/0xbc) from [<c0010599>] (unwind_backtrace+0x7d/0x8c)
+[   54.310602] [<c0010599>] (unwind_backtrace+0x7d/0x8c) from [<c002b51f>] (warn_slowpath_common+0x33/0x48)
+[   54.320513] [<c002b51f>] (warn_slowpath_common+0x33/0x48) from [<c002b543>] (warn_slowpath_null+0xf/0x10)
+[   54.330507] [<c002b543>] (warn_slowpath_null+0xf/0x10) from [<c0376ed1>] (__mutex_lock_slowpath+0x39/0x204)
+[   54.340698] [<c0376ed1>] (__mutex_lock_slowpath+0x39/0x204) from [<c03770ab>] (mutex_lock+0xf/0x20)
+[   54.350408] [<c03770ab>] (mutex_lock+0xf/0x20) from [<bf871edb>] (rpl_send_dao+0x36/0x308 [ipv6])
+[   54.359906] [<bf871edb>] (rpl_send_dao+0x36/0x308 [ipv6]) from [<bf86eb35>] (rpl_dag_dao_timer_handler+0x14/0x54 [ipv6])
+[   54.371380] [<bf86eb35>] (rpl_dag_dao_timer_handler+0x14/0x54 [ipv6]) from [<c0032ffd>] (call_timer_fn.isra.24+0x15/0x54)
+[   54.382833] [<c0032ffd>] (call_timer_fn.isra.24+0x15/0x54) from [<c0033141>] (run_timer_softirq+0x105/0x138)
+[   54.393109] [<c0033141>] (run_timer_softirq+0x105/0x138) from [<c002ff39>] (__do_softirq+0x95/0x124)
+[   54.402649] [<c002ff39>] (__do_softirq+0x95/0x124) from [<c0030197>] (irq_exit+0x2d/0x56)
+[   54.411197] [<c0030197>] (irq_exit+0x2d/0x56) from [<c000cefb>] (handle_IRQ+0x3f/0x5c)
+[   54.419470] [<c000cefb>] (handle_IRQ+0x3f/0x5c) from [<c0008565>] (omap3_intc_handle_irq+0x39/0x5c)
+[   54.428919] [<c0008565>] (omap3_intc_handle_irq+0x39/0x5c) from [<c000c1db>] (__irq_svc+0x3b/0x5c)
+[   54.438281] Exception stack(0xc0627f68 to 0xc0627fb0)
+[   54.443563] 7f60:                   ffffffed 00000000 004df000 00000000 c0626000 c037d1e8
+[   54.452107] 7f80: c0698288 c0afec80 80004059 413fc082 00000000 00000000 00000000 c0627fb0
+[   54.460642] 7fa0: c000d047 c000d048 60000033 ffffffff
+[   54.465927] [<c000c1db>] (__irq_svc+0x3b/0x5c) from [<c000d048>] (default_idle+0x12/0x1a)
+[   54.474472] [<c000d048>] (default_idle+0x12/0x1a) from [<c000d15b>] (cpu_idle+0x63/0xa0)
+[   54.482934] [<c000d15b>] (cpu_idle+0x63/0xa0) from [<c05ef583>] (start_kernel+0x1ff/0x254)
+[   54.498502] 7f80: c0698288 c0afec80 80004059 413fc082 00000000 00000000 00000000 c0627fb0
+ *
+ */
+
+int rpl_send_dao(struct rpl_dag *dag, struct net_device *dev, bool allnodes, bool no_path){
+	int err = -EINVAL;
+	struct rpl_allowed_if *allowed_if = NULL;
+
+	struct in6_addr saddr_global_tmp;
+
+	struct rpl_node *dao_parent;
+	struct in6_addr *dao_parent_addr;
+
+	struct in6_addr *saddr;
+	struct in6_addr addr_buf;
+
+	int addr_scope = 0;
+	struct sk_buff *skb;
+
+	struct rpl_target_transit_info *transit_info = NULL;
+	struct rpl_target *target;
+
+	bool add_transit_info_active_targets = false;
+	bool add_transit_info_no_path = false;
+
+	if(!dag){
+		RPL_PRINTK(0, err, "rpl: %s: dag is NULL\n",__func__);
+		goto out;
+	}
+
+	if(allnodes){
+		list_for_each_entry(allowed_if,&dag->allowed_interfaces,allowed_if_list){
+
+			// If device set, only send to the given device
+			if(dev && allowed_if->dev != dev)
+				continue;
+
+			// Ignore disabled devices
+			if(!allowed_if->enabled)
+				continue;
+
+			ipv6_dev_get_saddr(dev_net(allowed_if->dev),NULL,&dag->dodagid,0,&saddr_global_tmp);
+			addr_scope = ipv6_addr_src_scope(&saddr_global_tmp);
+
+			if(addr_scope != IPV6_ADDR_SCOPE_GLOBAL) {
+				printk(KERN_DEBUG "rpl: %s: ignoring non global address: %pI6 dag: %pI6 scope: %X\n",__func__,&saddr_global_tmp,&dag->dodagid,addr_scope);
+
+				rpl_dag_trigger_dao_timer(dag);
+				continue;
+			}
+			else{printk(KERN_DEBUG "rpl: %s: using global address: %pI6 scope: %X\n",__func__,&saddr_global_tmp,addr_scope);}
+
+			if(!ipv6_addr_equal(&allowed_if->global_addr,&saddr_global_tmp))
+			{
+				RPL_LOLLIPOP_INCREMENT(allowed_if->node_addr_path_sequence);
+				memcpy(&allowed_if->global_addr,&saddr_global_tmp,16);
+
+				/*
+				 * FIXME here, we only increment DAOSequence if global address changes,
+				 * but we MUST check if transit information is different. If it does, we
+				 * must increment DAO sequence even if global address keeps the same
+				 */
+				RPL_LOLLIPOP_INCREMENT(dag->DAOSequence);
+			}
+
+			skb = icmpv6_rpl_dao_new(allowed_if->dev,
+					dag->instance->instanceID,
+					0,
+					dag->DAOSequence,
+					NULL);
+			if (!skb)
+			{
+				err = -ENOMEM;
+				break;
+			}
+
+			printk(KERN_DEBUG "%s(): global address of %s: %pI6, %X\n",__func__,allowed_if->dev->name,&saddr_global_tmp,addr_scope);
+
+			icmpv6_rpl_add_option_rpl_target(skb,128,(__u8*) &saddr_global_tmp);
+			//FIXME specify path control: http://tools.ietf.org/html/rfc6550#section-9.9
+			icmpv6_rpl_add_option_transit_information(skb,0,0,allowed_if->node_addr_path_sequence,(no_path || dag->rank == RPL_INFINITE_RANK)?0:0xFF,NULL);
+
+			// getting scope link source address
+			if ((err = ipv6_get_lladdr(allowed_if->dev, &addr_buf, (IFA_F_TENTATIVE | IFA_F_OPTIMISTIC))) != 0)
+			{
+				printk(KERN_ERR "rpl: %s: failed calling ipv6_get_lladdr, err=%d\n",
+					  __func__, err);
+				break;
+			}
+			saddr = &addr_buf;
+
+			// sending DAO message
+			rpl_send_skb(skb, &in6addr_all_rpl_nodes, saddr);
+		}
+		err = 0;
+	} else {
+		printk(KERN_DEBUG "rpl: %s: sending data to DAO Parent here...\n",__func__);
+
+		/*
+		 * for each DAO parent, lets send a DAO message
+		 */
+
+		if(!mutex_trylock(&dag->parents_lock))
+		{
+			rpl_dag_trigger_dao_timer(dag);
+			goto out;
+		}
+
+		list_for_each_entry(dao_parent,&dag->dodag_parents,node_list){
+
+			// If device set, only send to the given device
+			if(dev && dao_parent->dev != dev)
+				continue;
+
+			if(!dao_parent->is_dao_parent)
+				continue;
+
+			// Ignore disabled devices
+			if(!rpl_dag_is_allowed(dag,dao_parent->dev))
+				continue;
+
+			add_transit_info_active_targets = false;
+			add_transit_info_no_path = false;
+
+			RPL_LOLLIPOP_INCREMENT(dag->DAOSequence);
+
+			skb = icmpv6_rpl_dao_new(dao_parent->dev,
+					dag->instance->instanceID,
+					0,
+					dag->DAOSequence,
+					NULL);
+			if (!skb)
+			{
+				err = -ENOMEM;
+				continue;
+			}
+
+			saddr = &addr_buf;
+			dao_parent_addr = &dao_parent->addr;
+
+			// lets create active targets options
+			list_for_each_entry(target,&dag->targets_head,target_list){
+				transit_info =
+						(!list_empty(&target->transit_head)) ?
+								list_first_entry(&target->transit_head,struct rpl_target_transit_info,transit_info_list) :
+								NULL;
+				if(transit_info && transit_info->path_lifetime > 0x00)
+				{
+					if(!ipv6_addr_equal(dao_parent_addr,&transit_info->next_hop)){
+						// active target with transit_info
+						icmpv6_rpl_add_option_rpl_target(skb,target->prefix_len,(__u8*) &target->prefix);
+						add_transit_info_active_targets = true;
+					}
+				}
+			}
+			if(add_transit_info_active_targets && transit_info)
+			{
+				icmpv6_rpl_add_option_transit_information(skb,0,0,transit_info->path_sequence,(no_path || dag->rank == RPL_INFINITE_RANK)?0:0xFF,NULL);
+			}
+
+			transit_info = NULL;
+
+			// lets create no-path targets options
+			list_for_each_entry(target,&dag->targets_head,target_list){
+				transit_info =
+						(!list_empty(&target->transit_head)) ?
+								list_first_entry(&target->transit_head,struct rpl_target_transit_info,transit_info_list) :
+								NULL;
+				if(transit_info && transit_info->path_lifetime == 0x00)
+				{
+					if(!ipv6_addr_equal(dao_parent_addr,&transit_info->next_hop)){
+						// no-path target with transit_info
+						icmpv6_rpl_add_option_rpl_target(skb,target->prefix_len,(__u8*) &target->prefix);
+						add_transit_info_no_path = true;
+					}
+				}
+			}
+			if(add_transit_info_no_path && transit_info)
+			{
+				icmpv6_rpl_add_option_transit_information(skb,0,0,transit_info->path_sequence,0x00,NULL);
+			}
+
+			// getting scope link source address
+			if ((err = ipv6_get_lladdr(dao_parent->dev, &addr_buf, (IFA_F_TENTATIVE | IFA_F_OPTIMISTIC))) != 0)
+			{
+				printk(KERN_ERR "rpl: %s: failed calling ipv6_get_lladdr, err=%d\n",
+					  __func__, err);
+				kfree_skb(skb);
+				continue;
+			}
+
+			rpl_send_skb(skb, dao_parent_addr, saddr);
+
+		}
+		mutex_unlock(&dag->parents_lock);
+
+		err = rpl_dag_cleanup_no_path(dag);
+		if(err){
+			RPL_PRINTK(2,err,"%s: some error occur cleaning no_path targets: %d\n",__func__,err);
+		}
+
+		err = 0;
+	}
+out:
+	return err;
+}
+
+int rpl_send_dao_ack(struct net_device *dev, __u8 instanceID, const struct in6_addr *daddr, __u8 DAOSequence, const struct in6_addr *dodagid, __u8 status)
+{
+	int err = -EINVAL;
+	struct in6_addr *saddr;
+	struct in6_addr addr_buf;
+	struct sk_buff *skb;
+
+	if(!dev){
+		RPL_PRINTK(0, err, "rpl: %s dev is NULL, err=%d\n", __func__, err);
+		goto out;
+	}
+
+	skb = icmpv6_rpl_dao_ack_new(dev,instanceID,DAOSequence,status,dodagid);
+	if (!skb)
+	{
+		err = -ENOMEM;
+		goto out;
+	}
+
+	// getting scope link source address
+	if ((err = ipv6_get_lladdr(dev, &addr_buf,
+			(IFA_F_TENTATIVE | IFA_F_OPTIMISTIC))) != 0) {
+		printk(KERN_ERR "rpl: %s: failed calling ipv6_get_lladdr, err=%d\n",
+				__func__, err);
+		kfree_skb(skb);
+		goto out;
+	}
+	saddr = &addr_buf;
+
+	// sending DAO message
+	rpl_send_skb(skb, daddr, saddr);
+
+	err = 0;
+out:
+	return err;
+}
+
+
+static struct sk_buff *rpl_alloc_skb(struct net_device *dev, int len)
+{
+	int hlen = LL_RESERVED_SPACE(dev);
+//	int tlen = dev->needed_tailroom;
+	struct sock *sk = dev_net(dev)->ipv6.rpl.rpl_sk;
+	struct sk_buff *skb;
+	int err;
+
+	skb = sock_alloc_send_skb(sk,
+				  dev->mtu, //FIXME we shouldnt use mtu
+				  1, &err);
+//	skb = sock_alloc_send_skb(sk,
+//				  hlen + sizeof(struct ipv6hdr) + len + tlen,
+//				  1, &err);
+	if (!skb) {
+		RPL_PRINTK(0, err, "rpl: %s failed to allocate an skb, err=%d\n",
+			  __func__, err);
+		return NULL;
+	}
+
+	skb->protocol = htons(ETH_P_IPV6);
+	skb->dev = dev;
+
+	skb_reserve(skb, hlen + sizeof(struct ipv6hdr));
+	skb_reset_transport_header(skb);
+
+	return skb;
+}
+
+int rpl_recv_dis(struct net_device *dev, struct sk_buff *skb)
+{
+	/*
+	 * http://tools.ietf.org/html/rfc6550#section-8
+	 * */
+/**
+ * DIS receive
+ *
+ * Upon receiving a DIS, a node creates a DIO containing
+ * DODAG Configuration option and sends it back. This also
+ * triggers a trickle timer reset (if active). The trickle timer is
+ * used to send periodic, unsolicited, DIOs.
+ *
+ * The DIS source node is also added to the neighbors set as
+ * ’NEIGHBOR NOT IN DODAG’ and a temporary route is
+ * created. The route will be discarded as soon as the DIO is
+ * sent.
+ */
+	struct net *net = dev_net(dev);
+	struct rpl_dag *dag;
+	u_rpl_option *option;
+	struct rpl_msg *msg;
+	const struct in6_addr *saddr, *daddr;
+	msg = (struct rpl_msg *)skb_transport_header(skb);
+
+	saddr = &ipv6_hdr(skb)->saddr;
+	daddr = &ipv6_hdr(skb)->daddr;
+
+	option = icmpv6_rpl_find_option(skb,ICMPV6_RPL_OPT_Solicited_Information);
+
+	if(option)
+	{
+		RPL_PRINTK(1,dbg,"%s(): Solicited Information Option found\n",__func__);
+		icmpv6_rpl_print_option((__u8*)option);
+		if (ipv6_addr_equal(daddr,&in6addr_all_rpl_nodes)) {
+			 /* multicast all-RPL-nodes */
+			// TODO: Check if node match all predicates in option
+
+			//rpl_ipv6_signal_inconsistency(idev);
+		}
+
+	} else if(ipv6_addr_equal(daddr,&in6addr_all_rpl_nodes)){
+		 /* multicast all-RPL-nodes */
+		mutex_lock(&net->ipv6.rpl.rpl_dags_list_mutex);
+		list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+			if(rpl_dag_is_allowed(dag,dev)){
+				rpl_dag_inconsistent(dag);
+			}
+		}
+		mutex_unlock(&net->ipv6.rpl.rpl_dags_list_mutex);
+	}
+	return 0;
+}
+
+int rpl_recv_dio(struct net_device *dev, struct sk_buff *skb)
+{
+	struct net *net = dev_net(skb->dev);
+	int err = 0;
+	struct rpl_dag *dag;
+	struct rpl_node *neighbor;
+	struct rpl_msg *msg;
+	const struct in6_addr *saddr, *daddr;
+	bool updated = false;
+	bool check_prefix = false;
+	struct in6_addr global_addr;
+	u_rpl_option *prefix_info_option;
+	struct prefix_info *prefix_option;
+	struct inet6_dev *idev;
+
+	idev = __in6_dev_get(dev);
+	if(!idev){
+		err = -ENOTSUPP;
+		goto out;
+	}
+
+	msg = (struct rpl_msg *)skb_transport_header(skb);
+
+	saddr = &ipv6_hdr(skb)->saddr;
+	daddr = &ipv6_hdr(skb)->daddr;
+
+	if(idev->cnf.rpl_dodag_root)
+	{
+		dag = rpl_dag_find(net,msg->base.dio.instanceID,&msg->base.dio.dodagid);
+		if(dag){
+			if(lollipop_greater_than(msg->base.dio.version,dag->version)){
+				dag->version = msg->base.dio.version;
+				RPL_LOLLIPOP_INCREMENT(dag->version);
+				rpl_dag_inconsistent(dag);
+			}
+			rpl_dag_put(dag);
+		}
+		if(idev->cnf.rpl_icmp_dump)
+			printk(KERN_DEBUG "RPL: DODAG Root received a DIO. Ignoring\n");
+		err = 0;
+		goto out;
+	}
+/*
+ * DIO receive
+ *
+ * The actions that follow the receipt of a DIO are different
+ * according to the state of the node. For convenience, given
+ * the considerable length of the diagram, we decided to omit
+ * it and insert just the description.
+ *
+ * The node can be in one of these two states:
+ * 	(1) it is not yet joined to a DODAG or
+ * 	(2) it is already joined to one.
+ */
+	dag = rpl_dag_find(net,msg->base.dio.instanceID,&msg->base.dio.dodagid);
+	if(!dag){
+		/*
+		 * 1) This case is the consequence of a DODAG join attempt.
+		 * Hence, the node will copy the values contained in the DIO
+		 * in his DODAG attributes, his rank will be calculated, its
+		 * status updated and, if it is a ’ROUTER’, the trickle timer
+		 * is launched. The DIO sender will be stored in the neighbors
+		 * set with type ’DODAG PARENT ONLY PRF’. The sender,
+		 * of course, will be automatically selected as the preferred
+		 * DODAG parent. The routing table is updated accordingly.
+		 */
+		dag = rpl_dag_new_from_dio(net,dev,skb);
+		if(!dag){
+			RPL_PRINTK(1,dbg,"%s(): Error creating new DAG\n",__func__);
+			goto out;
+		}
+		updated = true;
+	} else {
+		if(dag->auto_gen){
+			rpl_dag_set_allowed(dag,dev,true,true,&updated);
+			check_prefix = true;
+		} else if(!rpl_dag_is_allowed(dag,dev)){
+			goto discard_it;
+		} else {
+			check_prefix = true;
+		}
+	}
+
+	if(check_prefix){
+		if(ipv6_get_global_addr(dev,&global_addr,0)){
+			prefix_info_option = icmpv6_rpl_find_option(skb, ICMPV6_RPL_OPT_Prefix_Information);
+			if(prefix_info_option){
+				prefix_option = (struct prefix_info *) prefix_info_option;
+				addrconf_prefix_rcv(skb->dev,(u8 *)prefix_option,sizeof(struct prefix_info),0);
+
+				if(dag->prefix_info)
+					kfree(dag->prefix_info);
+				dag->prefix_info = kmalloc(sizeof(struct prefix_info),GFP_ATOMIC);
+				if(!dag->prefix_info){
+					RPL_PRINTK(1, err,"%s(): Error creating prefix_info\n",__func__);
+				} else {
+					memcpy(dag->prefix_info, prefix_option, sizeof(struct prefix_info));
+				}
+			}
+		}
+	}
+
+	/*
+	 * 2) In the second case we have two more possibilities:
+	 * 	(a) the DIO is a poisoning one or
+	 * 	(b) it is a periodic DIO sent to maintain the upward routes.
+	 */
+
+	if(msg->base.dio.rank == RPL_INFINITE_RANK) {
+		 /* a) In this first case the node will need to delete all the
+		 * sender’s entry and all the routes that have the sender as
+		 * next hop from the routing table. The sender is also removed
+		 * from the neighbors set . If the sender was a preferred parent,
+		 * another parent is searched in the neighbor set. If no parent
+		 * is found, the node will disjoin himself from the DODAG.
+		 */
+
+		printk(KERN_DEBUG "%s(): DIO received INFINITE_RANK..!!\n",__func__);
+
+		err = rpl_dag_unlink_node(dag,dev,saddr);
+		if(err)
+		{
+			printk(KERN_ERR "%s(): Error unlinking node: %d\n",__func__,err);
+			goto put_dag;
+		}
+	} else {
+		/* 1)
+		 * b) In the event that the DIO is a periodic message then the
+		 * node will check if the version of DODAG has been increased
+		 * or not.
+		 */
+		if(lollipop_greater_than(msg->base.dio.version,dag->version)){
+			printk(KERN_DEBUG "%s(): New DAG Version!!\n",__func__);
+
+			/*
+			 * i) If so the node will join the new version of DODAG, so
+			 * it will reset the routing table, the neighbors set and, if it is
+			 * active, the trickle timer. This is an implementation choice,
+			 * as the standard does not suggest anything about this point.
+			 * Better choices could be tested in the future.
+			 */
+
+			dag->version = msg->base.dio.version;
+			RPL_LOLLIPOP_INCREMENT(dag->DTSN);
+
+			// TODO update dag version
+			// TODO increment DTSN
+			// TODO delete all neighbors with old version
+			// TODO update parents set
+
+			err = rpl_dag_purge_nodes(dag);
+			if(err){
+				RPL_PRINTK(1, err,"%s(): Error resetting neighbors set: %d\n",__func__,err);
+				err = 0;
+			}
+
+		}
+		//else
+		{
+			if(idev->cnf.rpl_icmp_dump)
+				printk(KERN_DEBUG "%s(): DAG Version Unchanged!!\n",__func__);
+			/*
+			 * ii) If the DODAG version is unchanged, then the ’DTSN’
+			 * field is checked. If it is different from the last one that the
+			 * sending node sent, a DAO will be scheduled. Then, if the
+			 * rank of the sender node is lesser than the one of the current
+			 * node, the sender will be stored in neighbors set, checking if
+			 * the new node is to become the preferred parent and, as a
+			 * consequence, to update the node’s rank. The sender node is
+			 * in any case stored in the neighbor set and the routing table
+			 * is updated accordingly.
+			 */
+
+			neighbor = rpl_dag_get_node(dag,dev,saddr);
+			if(!neighbor)
+			{
+				RPL_PRINTK(1, dbg, "%s(): Unknown Neighbor!!\n",__func__);
+
+				neighbor = rpl_node_alloc(saddr,dev,be16_to_cpu(msg->base.dio.rank),msg->base.dio.DTSN,&err);
+				if(!neighbor)
+				{
+					RPL_PRINTK(1, err,
+							"%s(): Error allocating neighbor: %d\n",
+							__func__,err);
+					goto put_dag;
+				}
+				err = rpl_dag_add_node(dag,neighbor);
+				if(err)
+				{
+					RPL_PRINTK(1, err,
+							"%s(): Error adding neighbor to dag: %d\n",
+							__func__, err);
+					rpl_node_free(neighbor);
+					goto put_dag;
+				}
+			} else {
+				if(neighbor->is_dao_parent && lollipop_greater_than(msg->base.dio.DTSN,neighbor->dtsn))
+				{
+					neighbor->dtsn = msg->base.dio.DTSN;
+					rpl_dag_trigger_dao_timer(dag);
+				}
+				neighbor->rank = be16_to_cpu(msg->base.dio.rank);
+			}
+
+			err = rpl_dag_update_upward_routes(dag,&updated);
+			if(err)
+			{
+				printk(KERN_ERR "%s(): error updating upward routes: %d\n",__func__,err);
+				goto put_dag;
+			}
+
+			if(list_empty(&dag->dodag_parents))
+			{
+				printk(KERN_ERR "%s(): dodag parents list is empty!!!\n",__func__);
+				rpl_dag_set_rank(dag,RPL_INFINITE_RANK);
+				updated = true;
+			}
+
+			if(updated)
+			{
+				rpl_dag_inconsistent(dag);
+				rpl_dag_trigger_dao_timer(dag);
+			}
+		}
+	}
+
+// FIXME when will we call rpl_dag_consistent???
+
+discard_it:
+put_dag:
+	if(dag)
+		rpl_dag_put(dag);
+out:
+	return err;
+}
+
+__u8 *icmpv6_rpl_get_options(struct sk_buff *skb, size_t *p_non_options_len);
+
+int rpl_recv_dao(struct net_device *dev, struct sk_buff *skb){
+	int err = 0;
+
+	struct net *net = dev_net(dev);
+
+	struct rpl_msg *msg;
+	struct list_head *target_ptr,*target_next;
+	const struct in6_addr *saddr, *daddr;
+	const struct in6_addr *dodagid = NULL;
+	size_t non_options_len = 0;
+	size_t options_len = 0;
+	size_t option_len = 0;
+
+	struct rpl_dag *dag;
+
+	u_rpl_option *first,*option = NULL;
+
+	struct rpl_node *dao_parent;
+
+	struct rpl_target_transit_info *transit_info;
+	struct rpl_target *target_copy;
+	struct rpl_target *target;
+	bool target_updated = false;
+	bool trigger_dao = false;
+	bool is_one_hop = false; // see 9.10.  Multicast Destination Advertisement Messages
+
+	struct list_head targets; // struct rpl_target list
+	bool is_transit_info_last_opt = false;
+	INIT_LIST_HEAD(&targets);
+
+	msg = (struct rpl_msg *)skb_transport_header(skb);
+
+	saddr = &ipv6_hdr(skb)->saddr;
+	daddr = &ipv6_hdr(skb)->daddr;
+
+	first = (u_rpl_option *)icmpv6_rpl_get_options(skb,&non_options_len);
+	option = first;
+	options_len = skb->len-non_options_len;
+
+	if (RPL_DAO_K(msg->base.dao.KD_flags) &&
+			ipv6_addr_equal(daddr, &in6addr_all_rpl_nodes)) {
+		RPL_PRINTK(1,dbg,"%s(): Error: can't send ACK from multicast DAO\n",__func__);
+		return 0;
+	}
+
+	if(ipv6_addr_equal(daddr, &in6addr_all_rpl_nodes))
+		is_one_hop = true;
+
+	if(RPL_DAO_D(msg->base.dao.KD_flags))
+	{
+		dodagid = &msg->base.dao.u_with_dodagid.dodagid;
+	}else{
+		dodagid = NULL;
+	}
+
+	while(option && options_len > 0){
+		//icmpv6_rpl_print_option((__u8*)option);
+
+		if(icmpv6_rpl_option_get_code(option) == ICMPV6_RPL_OPT_RPL_Target)
+		{
+			if(is_transit_info_last_opt)
+			{
+				if(!list_empty(&targets)){
+					RPL_PRINTK(1,dbg,"%s(): Targets list should be empty at this point.\n",__func__);
+					list_for_each_safe(target_ptr,target_next,&targets)
+					{
+						target = list_entry(target_ptr,struct rpl_target,target_list);
+						list_del(&target->target_list);
+						rpl_target_free(target);
+					}
+					target = NULL;
+				}
+				is_transit_info_last_opt = false;
+			}
+			target = rpl_target_alloc(
+					(const struct in6_addr *)option->rpl_target.prefix,
+					option->rpl_target.prefix_length,&err);
+			if(!target)
+			{
+				RPL_PRINTK(1,dbg,"%s(): Error allocating new target: %d\n",__func__,err);
+			} else {
+				list_add(&target->target_list,&targets);
+			}
+		} else if(icmpv6_rpl_option_get_code(option) == ICMPV6_RPL_OPT_RPL_Target_Descriptor)
+		{
+			if(target)
+			{
+				/*
+				 * At most, there can be one descriptor per target.  The descriptor is
+				 * set by the node that injects the Target in the RPL network.  It MUST
+				 * be copied but not modified by routers that propagate the Target Up
+				 * the DODAG in DAO messages.
+				 */
+				target->target_descriptor = be32_to_cpu(option->rpl_target_descriptor.descriptor);
+				target = NULL;
+			}
+		} else if(icmpv6_rpl_option_get_code(option) == ICMPV6_RPL_OPT_Transit_Information)
+		{
+			is_transit_info_last_opt = true;
+
+			if(RPL_TIO_E(option->transit_information.E_flags))
+			{
+
+			}
+
+			if(option->transit_information.path_control == 0)
+			{
+				// 9.9.  Path Control
+			}
+
+			if(option->transit_information.path_lifetime == 0)
+			{
+				list_for_each_safe(target_ptr,target_next,&targets)
+				{
+					target = list_entry(target_ptr,struct rpl_target,target_list);
+					rpl_target_set_no_path(net,msg->base.dao.instanceID,dodagid,dev,&target->prefix,target->prefix_len,saddr);
+					list_del(&target->target_list);
+					rpl_target_free(target);
+				}
+				target = NULL;
+			}else if(option->transit_information.path_lifetime == 0xff)
+			{
+				//for each target in targets
+				list_for_each_safe(target_ptr,target_next,&targets)
+				{
+					target = list_entry(target_ptr,struct rpl_target,target_list);
+					// add target to dodagid or to all dags in idev
+
+					// ... for all dags, if idev allowed && enabled
+					list_for_each_entry(dag,&net->ipv6.rpl.rpl_dags_list_head,dag_list){
+						if(rpl_dag_is_allowed(dag,dev)) {
+							trigger_dao = false;
+							target_updated = false;
+
+							if(is_one_hop /* multicast DAO */) {
+								dao_parent = rpl_dag_get_node(dag,dev,saddr);
+								if(dao_parent && dao_parent->is_dao_parent)
+								{
+									/*
+									 *  DAO Parent found on this DAG via this interface.
+									 *  Since it's a mcast DAO, we must ignore it
+									 */
+									break;
+								}
+							}
+
+							target_copy = rpl_target_alloc(&target->prefix,target->prefix_len,&err);
+							if(target_copy){
+								transit_info = rpl_transit_info_alloc(saddr,dev,is_one_hop,&err);
+								transit_info->DAOSequence = msg->base.dao.DAOSequence;
+								transit_info->path_control = option->transit_information.path_control;
+								transit_info->path_lifetime = option->transit_information.path_lifetime;
+								transit_info->path_sequence = option->transit_information.path_sequence;
+								rpl_target_add_transit_info(target_copy,transit_info,NULL);
+								if(dodagid){
+									if(msg->base.dao.instanceID == dag->instance->instanceID &&
+											ipv6_addr_equal(dodagid,&dag->dodagid)){
+										rpl_dag_add_target(dag,target_copy,&target_updated);
+									} else {
+										rpl_target_free(target_copy);
+									}
+								} else if(msg->base.dao.instanceID == dag->instance->instanceID){
+									rpl_dag_add_target(dag,target_copy,&target_updated);
+								} else {
+									rpl_target_free(target_copy);
+								}
+							}
+							trigger_dao |= target_updated;
+
+							/*
+							 * If target processing result in targets updates, lets trigger DAO for this DAG
+							 */
+							if(trigger_dao){
+								rpl_dag_trigger_dao_timer(dag);
+							}
+						}
+					}
+					list_del(&target->target_list);
+					rpl_target_free(target);
+				}
+				target = NULL;
+			} else
+			{
+				// ?? path_lifetime not 0 (zero) nor 0xFF (infinite)
+			}
+
+			// TODO: compute best routes to each known neighbour based on DAOs //FIXME trigger DAO
+
+		}
+		target = NULL;
+
+		//FIXME option = icmpv6_rpl_option_get_next(first,option,skb->len-non_options_len);
+		option_len = icmpv6_rpl_option_get_length(option);
+		if(option_len){
+			option = (u_rpl_option*) (((__u8*)option)+option_len);
+			options_len -= option_len;
+		} else {
+			option = NULL;
+		}
+	}
+
+	// TODO add a "send_ack" bool after check that instanceID exists
+	if(!is_one_hop && RPL_DAO_K(msg->base.dao.KD_flags))
+	{
+		err = rpl_send_dao_ack(dev,msg->base.dao.instanceID, saddr,msg->base.dao.DAOSequence,dodagid, 0 /* status */);
+		if(err)
+		{
+			RPL_PRINTK(1,dbg,"%s(): Error: sending DAO_ACK: %d\n",__func__,err);
+		}
+	}
+
+/**
+ * DAO receive
+ *
+ * DAO messages are used to inform the nodes about the
+ * downward routes. A DAO might require an acknowledge-
+ * ment; in this case a DAO-ACK is sent.
+ * The DAO message is then processed and, for each entry
+ * contained in it (the exact DAO message structure is too
+ * complex to be described here) the routing table is updated
+ * accordingly, adding (or updating) each entry and setting the
+ * DAO sender as next hop.
+ * After the update, the changed entries are stored in a new
+ * DAO message and this is immediately sent to the Dao par-
+ * ments. Usually the DAO parent is just the preferred parent,
+ * but the standard allows multiple DAO parents in order to
+ * optimize routes and/or have fallback downward paths. This
+ * immediate send is important to quickly update the down-
+ * ward routes of the upper nodes, i.e., the ones along the path
+ * towards the root.
+ *
+ */
+	return err;
+}
+
+struct sk_buff *icmpv6_rpl_dis_new(struct net_device *dev)
+{
+	struct sk_buff *skb = NULL;
+	struct rpl_msg *rpl_msg = NULL;
+	size_t msg_length = 0;
+	msg_length += 1 /* icmp type */ + 1 /* icmp code */ + 2 /* icmp chksum */;
+	msg_length += 2 /* flags + reserved */;
+	if((skb = rpl_alloc_skb(dev,msg_length)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating buf\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_put(skb, msg_length);
+
+	rpl_msg->icmp6_type = ICMPV6_RPL;
+	rpl_msg->icmp6_code = ICMPV6_RPL_DIS;
+	rpl_msg->base.dis.flags = 0;
+	rpl_msg->base.dis.reserved = 0;
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_dio_new(
+		struct net_device *dev,
+		__u8 instanceID,
+		__u8 version,
+		rpl_rank_t rank,
+		bool grounded,
+		__u8 mop,
+		__u8 prf,
+		__u8 DTSN,
+		struct in6_addr *dodagid)
+{
+	struct sk_buff *skb = NULL;
+	struct rpl_msg *rpl_msg = NULL;
+	size_t msg_length = 0;
+	if(!dodagid)
+	{
+		printk(KERN_ERR "%s(): dodagID NULL pointer\n", __func__);
+		return NULL;
+	}
+	msg_length += 1 /* icmp type */ + 1 /* icmp code */ + 2 /* icmp chksum */;
+	msg_length += 1 /* instance */ + 1 /* version */ + 2 /* rank */;
+	msg_length += 1 /* G0_MOP_Prf */ + 1 /* DTSN  */ + 1 /* Flags */ + 1 /* reserved */;
+	msg_length += 16 /* dodagID */;
+	if((skb = rpl_alloc_skb(dev,msg_length)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating buf\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_put(skb, msg_length);
+	rpl_msg->icmp6_type = ICMPV6_RPL;
+	rpl_msg->icmp6_code = ICMPV6_RPL_DIO;
+	rpl_msg->base.dio.instanceID = instanceID;
+	rpl_msg->base.dio.version = version;
+	rpl_msg->base.dio.rank = cpu_to_be16(rank);
+	rpl_msg->base.dio.DTSN = DTSN;
+	rpl_msg->base.dio.g_mop_prf = 0;
+	rpl_msg->base.dio.g_mop_prf |= ((((grounded)?1:0) & 0x01) << 7);
+	rpl_msg->base.dio.g_mop_prf |= ((mop & 0x07) << 3);
+	rpl_msg->base.dio.g_mop_prf |= ((prf & 0x07) << 0);
+	rpl_msg->base.dio.flags = 0;
+	rpl_msg->base.dio.reserved = 0;
+	memcpy(&rpl_msg->base.dio.dodagid,dodagid,16);
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_dao_new(
+		struct net_device *dev,
+		__u8 instanceID,
+		__u8 expect_DAO_ACK,
+		__u8 DAOSequence,
+		struct in6_addr *dodagid)
+{
+	struct sk_buff *skb = NULL;
+	struct rpl_msg *rpl_msg = NULL;
+	size_t msg_length = 0;
+	msg_length += 1 /* icmp type */ + 1 /* icmp code */ + 2 /* icmp chksum */;
+	msg_length += 1 /* instanceID */ + 1 /* KD_flags */ + 1 /* reserved */ + 1 /* DAOSequence */;
+	if(dodagid)
+		msg_length += 16 /* dodagID */;
+	if((skb = rpl_alloc_skb(dev,msg_length)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating buf\n", __func__);
+		return NULL;
+	}
+
+	rpl_msg = (struct rpl_msg *)skb_put(skb, msg_length);
+	rpl_msg->icmp6_type = ICMPV6_RPL;
+	rpl_msg->icmp6_code = ICMPV6_RPL_DAO;
+
+	rpl_msg->base.dao.instanceID = instanceID;
+	rpl_msg->base.dao.KD_flags = 0;
+	rpl_msg->base.dao.KD_flags |= ((expect_DAO_ACK & 0x01) << 7);
+	rpl_msg->base.dao.reserved = 0;
+	rpl_msg->base.dao.DAOSequence = DAOSequence;
+	if(dodagid)
+	{
+		rpl_msg->base.dao.KD_flags |= (1 << 6);
+		memcpy(&rpl_msg->base.dao.u_with_dodagid.dodagid,dodagid,16);
+	}
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_dao_ack_new(
+		struct net_device *dev,
+		__u8 instanceID,
+		__u8 DAOSequence,
+		__u8 status,
+		const struct in6_addr *dodagid)
+{
+	struct sk_buff *skb = NULL;
+	struct rpl_msg *rpl_msg = NULL;
+	size_t msg_length = 0;
+	msg_length += 1 /* icmp type */ + 1 /* icmp code */ + 2 /* icmp chksum */;
+	msg_length += 1 /* instanceID */ + 1 /* D_reserved */ + 1 /* DAOSequence */ + 1 /* status */;
+	if(dodagid)
+		msg_length += 16 /* dodagID */;
+	if((skb = rpl_alloc_skb(dev,msg_length)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating buf\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_put(skb, msg_length);
+	rpl_msg->icmp6_type = ICMPV6_RPL;
+	rpl_msg->icmp6_code = ICMPV6_RPL_DAO_ACK;
+
+	rpl_msg->base.dao_ack.instanceID = instanceID;
+	rpl_msg->base.dao_ack.D_reserved = 0;
+	rpl_msg->base.dao_ack.DAOSequence = DAOSequence;
+	rpl_msg->base.dao_ack.status = status;
+	if(dodagid)
+	{
+		rpl_msg->base.dao_ack.D_reserved |= (1 << 7);
+		memcpy(&rpl_msg->base.dao_ack.u_with_dodagid.dodagid,dodagid,16);
+	}
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_cc_new(
+		struct net_device *dev,
+		__u8 instanceID,
+		__u8 is_response,
+		__u16 CCNonce,
+		struct in6_addr *dodagid,
+		__u32 dest_counter
+		)
+{
+	struct sk_buff *skb = NULL;
+	struct rpl_msg *rpl_msg = NULL;
+	size_t msg_length = 0;
+	msg_length += 1 /* icmp type */ + 1 /* icmp code */ + 2 /* icmp chksum */;
+	msg_length += 1 /* instanceID */ + 1 /* R_flags */ + 2 /* CCNonce */;
+	msg_length += 16 /* dodagID */;
+	msg_length += 4 /* destination counter */;
+	if(!dodagid)
+	{
+		printk(KERN_ERR "%s(): dodagID NULL pointer\n", __func__);
+		return NULL;
+	}
+	if((skb = rpl_alloc_skb(dev,msg_length)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating buf\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_put(skb, msg_length);
+	rpl_msg->icmp6_type = ICMPV6_RPL;
+	rpl_msg->icmp6_code = ICMPV6_RPL_CC;
+	rpl_msg->base.cc.instanceID = instanceID;
+	rpl_msg->base.cc.R_flags = 0;
+	rpl_msg->base.cc.R_flags |= ((is_response & 0x01) << 7);
+	rpl_msg->base.cc.CCNonce = cpu_to_be16(CCNonce);
+	memcpy(&rpl_msg->base.cc.dodagid,dodagid,16);
+	rpl_msg->base.cc.dest_counter = cpu_to_be32(dest_counter);
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_pad1(struct sk_buff *skb)
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_Pad1))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	if((option = (u_rpl_option *) skb_put(skb,1)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->pad1.type = ICMPV6_RPL_OPT_Pad1;
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_padn(struct sk_buff *skb, __u8 n)
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	__u8 i = 0;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_PadN))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	if((option = (u_rpl_option *) skb_put(skb,n-2)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->padn.base.type = ICMPV6_RPL_OPT_PadN;
+	option->padn.base.length = n - 2;
+	for(i=0;i<n-2;option->padn.zeros[i++]=0);
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_dag_metric_container(struct sk_buff *skb, __u8 *metric_data, __u8 metric_data_len)
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_DAG_Metric_Container))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	if((option = (u_rpl_option *) skb_put(skb,metric_data_len+2)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->dag_metric_container.base.type = ICMPV6_RPL_OPT_DAG_Metric_Container;
+	option->dag_metric_container.base.length = metric_data_len;
+	memcpy(option->dag_metric_container.data,metric_data,metric_data_len);
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_route_information(
+		struct sk_buff *skb,
+		__u8 prefix_length,
+		__u8 prf,
+		__u32 route_lifetime,
+		__u8 prefix[16])
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	__u8 option_length = 0;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_Route_Information))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	option_length += 1 /* prefix len */;
+	option_length += 1 /* resvd + prf + resvd */;
+	option_length += 4 /* route lifetime */;
+
+	/*
+	 * Prefix Length: 8-bit unsigned integer.  The number of leading bits in
+	 * the prefix that are valid.  The value ranges from 0 to 128.
+	 * The Prefix field has the number of bytes inferred from the
+	 * Option Length field, that must be at least the Prefix Length.
+	 * Note that in RPL, this means that the Prefix field may have
+	 * lengths other than 0, 8, or 16.
+	 */
+	option_length += prefix_length/8+((prefix_length%8)?1:0) /* prefix (variable length) */;
+	if((option = (u_rpl_option *) skb_put(skb,option_length+2)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->route_information.base.type = ICMPV6_RPL_OPT_Route_Information;
+	option->route_information.base.length = option_length;
+	option->route_information.prefix_length = prefix_length;
+	option->route_information.Resvd_Prf_Resvd = 0;
+	option->route_information.Resvd_Prf_Resvd |= ((prf & 0x03) << 3);
+	option->route_information.route_lifetime = cpu_to_be32(route_lifetime);
+	memcpy(option->route_information.prefix,prefix,prefix_length/8+((prefix_length%8)?1:0));
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_dodag_configuration(
+		struct sk_buff *skb,
+		bool auth,
+		__u8 PCS,
+		__u8 DIOIntDoubl,
+		__u8 DIOIntMin,
+		__u8 DIORedun,
+		rpl_rank_t MaxRankIncrease,
+		rpl_rank_t MinHopRankIncrease,
+		rpl_ocp_t OCP,
+		__u8 def_lifetime,
+		__u16 lifetime_unit)
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_DODAG_Configuration))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	if((option = (u_rpl_option *) skb_put(skb,16)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->dodag_configuration.base.type = ICMPV6_RPL_OPT_DODAG_Configuration;
+	option->dodag_configuration.base.length = 14;
+	option->dodag_configuration.flags_A_PCS = 0;
+	option->dodag_configuration.flags_A_PCS |= ((auth & 0x01) << 3);
+	option->dodag_configuration.flags_A_PCS |= ((PCS & 0x07) << 0);
+	option->dodag_configuration.DIOIntDoubl = DIOIntDoubl;
+	option->dodag_configuration.DIOIntMin = DIOIntMin;
+	option->dodag_configuration.DIORedun = DIORedun;
+	option->dodag_configuration.MaxRankIncrease = cpu_to_be16(MaxRankIncrease);
+	option->dodag_configuration.MinHopRankIncrease = cpu_to_be16(MinHopRankIncrease);
+	option->dodag_configuration.OCP = cpu_to_be16(OCP);
+	option->dodag_configuration.reserved = 0;
+	option->dodag_configuration.def_lifetime = def_lifetime;
+	option->dodag_configuration.lifetime_unit = cpu_to_be16(lifetime_unit);
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_rpl_target(
+		struct sk_buff *skb,
+		__u8 prefix_length,
+		__u8 target_prefix[16])
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	__u8 option_length = 0;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_RPL_Target))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	option_length += 1 /* flags */;
+	option_length += 1 /* prefix len */;
+
+	/*
+	 * Prefix Length: 8-bit unsigned integer.  The number of leading bits in
+	 * the prefix that are valid.  The value ranges from 0 to 128.
+	 * The Prefix field has the number of bytes inferred from the
+	 * Option Length field, that must be at least the Prefix Length.
+	 * Note that in RPL, this means that the Prefix field may have
+	 * lengths other than 0, 8, or 16.
+	 */
+	option_length += prefix_length/8+((prefix_length%8)?1:0) /* prefix (variable length) */;
+	if((option = (u_rpl_option *) skb_put(skb,option_length+2)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->rpl_target.base.type = ICMPV6_RPL_OPT_RPL_Target;
+	option->rpl_target.base.length = option_length;
+	option->rpl_target.prefix_length = prefix_length;
+	memcpy(option->rpl_target.prefix,target_prefix,prefix_length/8+((prefix_length%8)?1:0));
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_transit_information(
+		struct sk_buff *skb,
+		__u8 external,
+		__u8 path_control,
+		__u8 path_sequence,
+		__u8 path_lifetime,
+		struct in6_addr *parent_address)
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	__u8 option_length = 0;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	option_length += 1 /* E_flags */;
+	option_length += 3 /* path_control + path_sequence + path_lifetime */;
+	if(parent_address)
+	{
+		option_length += 16; /* parent address if present */
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_Transit_Information))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	if((option = (u_rpl_option *) skb_put(skb,option_length+2)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->transit_information.base.type = ICMPV6_RPL_OPT_Transit_Information;
+	option->transit_information.base.length = option_length;
+	option->transit_information.E_flags = 0;
+	option->transit_information.E_flags |= ((external & 0x01) << 7);
+	option->transit_information.path_control = path_control;
+	option->transit_information.path_sequence = path_sequence;
+	option->transit_information.path_lifetime = path_lifetime;
+	if(parent_address)
+	{
+		memcpy(&option->transit_information.parent,parent_address,16);
+	}
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_solicited_information(
+		struct sk_buff *skb,
+		__u8 instanceID,
+		__u8 version_predicate,
+		__u8 instanceID_predicate,
+		__u8 DODAGID_predicate,
+		struct in6_addr *dodagid,
+		__u8 version)
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	if(!skb)
+	{
+		printk(KERN_ERR "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_Solicited_Information))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	if((option = (u_rpl_option *) skb_put(skb,21)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->solicited_information.base.type = ICMPV6_RPL_OPT_Solicited_Information;
+	option->solicited_information.base.length = 19;
+	option->solicited_information.instanceID = instanceID;
+	option->solicited_information.VID_flags = 0;
+	option->solicited_information.VID_flags |= ((version_predicate & 0x01) << 7);
+	option->solicited_information.VID_flags |= ((instanceID_predicate & 0x01) << 6);
+	option->solicited_information.VID_flags |= ((DODAGID_predicate & 0x01) << 5);
+	memcpy(&option->solicited_information.dodagid,dodagid,16);
+	option->solicited_information.version = version;
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_prefix_information(
+		struct sk_buff *skb,
+		__u8 prefix_length,
+		__u8 on_link,
+		__u8 autonomous,
+		__u8 router_address,
+		__u32	valid_lifetime,
+		__u32	preferred_lifetime,
+		__u8 prefix[16])
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_Prefix_Information))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	if((option = (u_rpl_option *) skb_put(skb,32)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->prefix_information.base.type = ICMPV6_RPL_OPT_Prefix_Information;
+	option->prefix_information.base.length = 30;
+	option->prefix_information.prefix_length = prefix_length;
+	option->prefix_information.LAR_reserved1 = 0;
+	option->prefix_information.LAR_reserved1 |= ((on_link & 0x01) << 7);
+	option->prefix_information.LAR_reserved1 |= ((autonomous & 0x01) << 6);
+	option->prefix_information.LAR_reserved1 |= ((router_address & 0x01) << 5);
+	option->prefix_information.valid_lifetime = cpu_to_be32(valid_lifetime);
+	option->prefix_information.preferred_lifetime = cpu_to_be32(preferred_lifetime);
+	option->prefix_information.reserved2 = 0;
+	memcpy(&option->prefix_information.prefix,prefix,16);
+	return skb;
+}
+
+struct sk_buff *icmpv6_rpl_add_option_rpl_target_descriptor(
+		struct sk_buff *skb,
+		__u32 descriptor)
+{
+	struct rpl_msg *rpl_msg = NULL;
+	u_rpl_option *option = NULL;
+	if(!skb)
+	{
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+		return NULL;
+	}
+	rpl_msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(!icmpv6_rpl_is_option_allowed(rpl_msg->icmp6_code,ICMPV6_RPL_OPT_RPL_Target_Descriptor))
+	{
+		printk(KERN_ERR "%s(): option not allowed to message: 0x%02X\n", __func__,rpl_msg->icmp6_code);
+		return NULL;
+	}
+	if((option = (u_rpl_option *) skb_put(skb,6)) == NULL)
+	{
+		printk(KERN_ERR "%s(): error allocating memory to option\n", __func__);
+		return NULL;
+	}
+	option->rpl_target_descriptor.base.type = ICMPV6_RPL_OPT_RPL_Target_Descriptor;
+	option->rpl_target_descriptor.base.length = 4;
+	option->rpl_target_descriptor.descriptor = cpu_to_be32(descriptor);
+	return skb;
+}
+
+__u8 *icmpv6_rpl_get_options(struct sk_buff *skb, size_t *p_non_options_len)
+{
+	size_t non_options_len = 4;
+	struct rpl_msg *msg;
+	__u8 *options = NULL;
+	msg = (struct rpl_msg *)skb_transport_header(skb);
+	if(msg)
+	{
+		if(msg->icmp6_type != ICMPV6_RPL){
+			goto out;
+		}
+		switch (msg->icmp6_code) {
+			case ICMPV6_RPL_DIS:
+				non_options_len += 2;
+				options = (__u8 *)msg->base.dis.dis_options;
+				goto out;
+				break;
+			case ICMPV6_RPL_DIO:
+				non_options_len += 24;
+				options = (__u8 *)msg->base.dio.dio_options;
+				goto out;
+				break;
+			case ICMPV6_RPL_DAO:
+				if(RPL_DAO_D(msg->base.dao.KD_flags))
+				{
+					// the DODAGID field is present
+					non_options_len  += 20;
+					options = (__u8 *)msg->base.dao.u_with_dodagid.dao_options;
+					goto out;
+				}
+				else
+				{
+					non_options_len += 4;
+					// the DODAGID field is NOT present
+					options = (__u8 *)msg->base.dao.u_no_dodagid.dao_options;
+					goto out;
+				}
+				break;
+			case ICMPV6_RPL_DAO_ACK:
+				if(RPL_DAO_ACK_D(msg->base.dao_ack.D_reserved))
+				{
+					non_options_len += 20;
+					// the DODAGID field is present
+					options = (__u8 *)msg->base.dao_ack.u_with_dodagid.dao_ack_options;
+					goto out;
+				}
+				else
+				{
+					non_options_len += 4;
+					// the DODAGID field is NOT present
+					options = (__u8 *)msg->base.dao_ack.u_no_dodagid.dao_ack_options;
+					goto out;
+				}
+				break;
+			case ICMPV6_RPL_SEC_DIS:
+				break;
+			case ICMPV6_RPL_SEC_DIO:
+				break;
+			case ICMPV6_RPL_SEC_DAO:
+				break;
+			case ICMPV6_RPL_SEC_DAO_ACK:
+				break;
+			case ICMPV6_RPL_CC:
+				non_options_len += 24;
+				options = (__u8 *)msg->base.cc.cc_options;
+				goto out;
+				break;
+			default:
+				printk(KERN_DEBUG "%s(): Code: Unknown (0x%02X)\n", __func__,msg->icmp6_code);
+				break;
+		}
+	} else {
+		printk(KERN_DEBUG "%s(): null pointer\n", __func__);
+	}
+out:
+	*p_non_options_len=non_options_len;
+	return options;
+}
+
+__u8 icmpv6_rpl_option_get_length(u_rpl_option *option)
+{
+	if(option){
+		if(*((__u8*)option) == ICMPV6_RPL_OPT_Pad1)
+			return 1;
+		else
+			return *((__u8*)option + 1) + 2;
+	}
+	return 0;
+}
+
+__u8 icmpv6_rpl_option_get_code(u_rpl_option *option)
+{
+	if(option)
+		return *((__u8*)option);
+	return 0;
+}
+
+u_rpl_option *icmpv6_rpl_option_get_next(u_rpl_option *first, u_rpl_option *current_option, size_t len)
+{
+	__u8 type = 0;
+	__u8 option_len = 0;
+
+	if(!first)
+		return NULL;
+	if(!current_option)
+		return NULL;
+	if(current_option >= first+len)
+		return NULL;
+
+	type = *((__u8*)current_option);
+
+	if(type == ICMPV6_RPL_OPT_Pad1)
+	{
+		return (u_rpl_option *) (current_option+1);
+	}
+
+	option_len = *((__u8*)current_option+1);
+
+	/* last one */
+	if(current_option+option_len >= first+len)
+		return NULL;
+
+	return (u_rpl_option *) (current_option+option_len+2);
+}
+
+u_rpl_option *icmpv6_rpl_find_option(struct sk_buff *skb, __u8 req_type)
+{
+	u_rpl_option *option = NULL;
+	__u8 type = 0;
+	__u8 len = 0;
+	__u8 *offset = NULL;
+	size_t non_options_len = 0;
+	unsigned int options_len = 0;
+	struct rpl_msg *msg;
+	msg = (struct rpl_msg *)skb_transport_header(skb);
+	offset = icmpv6_rpl_get_options(skb,&non_options_len);
+
+	if(!offset)
+		return NULL;
+
+	options_len = non_options_len;
+	while(options_len<skb->len)
+	{
+		type = *(offset);
+		if(type == ICMPV6_RPL_OPT_Pad1)
+		{
+			len = 1;
+		} else {
+			len = *(offset+1);
+		}
+		option = (u_rpl_option *) offset;
+		if(type == req_type)
+			goto out;
+		if(type == ICMPV6_RPL_OPT_Pad1)
+		{
+			offset += 1;
+			options_len += 1;
+		} else {
+			offset += len+2;
+			options_len += len+2;
+		}
+	}
+	option = NULL;
+out:
+	return option;
+}
+
+int icmpv6_rpl_is_option_allowed(__u8 message_type, __u8 option_type)
+{
+	switch (message_type) {
+		case ICMPV6_RPL_DIS:
+		case ICMPV6_RPL_SEC_DIS:
+			switch(option_type){
+			case ICMPV6_RPL_OPT_Pad1:
+			case ICMPV6_RPL_OPT_PadN:
+			case ICMPV6_RPL_OPT_Solicited_Information:
+				return 1;
+				break;
+			default:
+				return 0;
+				break;
+			}
+			break;
+		case ICMPV6_RPL_DIO:
+		case ICMPV6_RPL_SEC_DIO:
+			switch(option_type){
+			case ICMPV6_RPL_OPT_Pad1:
+			case ICMPV6_RPL_OPT_PadN:
+			case ICMPV6_RPL_OPT_DAG_Metric_Container:
+			case ICMPV6_RPL_OPT_Route_Information:
+			case ICMPV6_RPL_OPT_DODAG_Configuration:
+			case ICMPV6_RPL_OPT_Prefix_Information:
+				return 1;
+				break;
+			default:
+				return 0;
+				break;
+			}
+			break;
+		case ICMPV6_RPL_DAO:
+		case ICMPV6_RPL_SEC_DAO:
+			switch(option_type){
+			case ICMPV6_RPL_OPT_Pad1:
+			case ICMPV6_RPL_OPT_PadN:
+			case ICMPV6_RPL_OPT_RPL_Target:
+			case ICMPV6_RPL_OPT_Transit_Information:
+			case ICMPV6_RPL_OPT_RPL_Target_Descriptor:
+				return 1;
+				break;
+			default:
+				return 0;
+				break;
+			}
+			break;
+		case ICMPV6_RPL_DAO_ACK:
+		case ICMPV6_RPL_SEC_DAO_ACK:
+			return 0;
+			break;
+		case ICMPV6_RPL_CC:
+			switch(option_type){
+			case ICMPV6_RPL_OPT_Pad1:
+			case ICMPV6_RPL_OPT_PadN:
+				return 1;
+				break;
+			default:
+				return 0;
+				break;
+			}
+			break;
+		default:
+			return 1;
+			break;
+	}
+	return 1;
+}
diff --git a/net/ipv6/rpl/rpl_trickle.c b/net/ipv6/rpl/rpl_trickle.c
new file mode 100644
index 0000000..6d1f895
--- /dev/null
+++ b/net/ipv6/rpl/rpl_trickle.c
@@ -0,0 +1,264 @@
+/*
+ *	Trickle Timer: The Trickle Algorithm (RFC6206)
+ *	Linux RPL implementation
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_trickle.c
+ *
+ * @date Jul 30, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#define pr_fmt(fmt) "ICMPv6: " fmt
+
+#include <linux/kthread.h>	// for threads
+#include <linux/time.h>		// for using jiffies
+#include <linux/random.h>	// for randomize_range
+#include <linux/net.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+
+#include <net/rpl/rpl_trickle.h>
+
+#define RPL_DEBUG 1
+
+#define RPL_PRINTK(val, level, fmt, ...)				\
+do {								\
+	if (val <= RPL_DEBUG)					\
+		net_##level##_ratelimited(fmt, ##__VA_ARGS__);	\
+} while (0)
+
+/*
+ * Since using randomize_range (which's !exported) from <linux/random.h> I got following error:
+ * ERROR: "randomize_range" [net/ipv6/ipv6.ko] undefined!
+ * here's the same function...
+ */
+static unsigned long
+rpl_randomize_range(unsigned long start, unsigned long end, unsigned long len)
+{
+	unsigned long range = end - len - start;
+
+	if (end <= start + len)
+		return 0;
+	return get_random_int() % range + start;
+}
+
+struct trickle_timer *trickle_new(
+		unsigned long Imin,
+		unsigned long Imax,
+		int k,
+		void (*trickle_fn)(unsigned long arg),
+		unsigned long trickle_fn_arg)
+{
+	struct trickle_timer *trickle = NULL;
+	trickle = kmalloc(sizeof(struct trickle_timer),GFP_KERNEL);
+	if(!trickle)
+	{
+		RPL_PRINTK(0, err, "rpl_trickle: %s: error allocating memory to timer\n", __func__);
+		return NULL;
+	}
+	trickle->task = NULL;
+	trickle->Imin = Imin;
+	trickle->Imax = Imin * (1 << Imax);
+	trickle->k = k;
+
+	trickle->trickle_fn = trickle_fn;
+	trickle->trickle_fn_arg = trickle_fn_arg;
+
+	// step 1
+	trickle->I = rpl_randomize_range(trickle->Imin, trickle->Imax, 1);
+
+	// step 2
+	trickle->c = 0;
+	trickle->t = rpl_randomize_range(trickle->I / 2, trickle->I, 1);
+
+	mutex_init(&trickle->lock);
+
+	//RPL_PRINTK(2, info, "rpl_trickle: %s: next trickle timer is set to run in %lu (ms) Imin: %lu Imax: %lu\n",__func__,trickle->t,trickle->Imin,trickle->Imax);
+	return trickle;
+}
+
+static int _trickle_stop(struct trickle_timer *trickle);
+void trickle_free(struct trickle_timer *trickle)
+{
+	if(trickle)
+	{
+		mutex_lock(&trickle->lock);
+		if(trickle->task)
+			_trickle_stop(trickle);
+		mutex_unlock(&trickle->lock);
+		kfree(trickle);
+	}
+}
+
+static int trickle_threadfn(void *data) {
+	struct trickle_timer *trickle = (struct trickle_timer *) data;
+	int local_k = 0;
+	int local_c = 0;
+	unsigned long local_t = 0, j0 = 0, delay = 0, delay_remain = 0;
+	bool should_stop = false;
+
+	RPL_PRINTK(2, info, "rpl_trickle: %s: starting..HZ: %d\n",__func__,HZ);
+	set_current_state(TASK_INTERRUPTIBLE);
+	should_stop = kthread_should_stop();
+	while (!should_stop) {
+		j0 = jiffies;
+		mutex_lock(&trickle->lock);
+		delay = trickle->t * HZ / 1000;
+		local_t = j0 + delay;
+		mutex_unlock(&trickle->lock);
+
+		RPL_PRINTK(2, info, "rpl_trickle: %s: waiting for %lu (ms) or %lu (jiffies)\n",__func__,trickle->t,delay);
+
+		delay_remain = delay;
+		while(delay_remain>0){
+			set_current_state(TASK_INTERRUPTIBLE);
+			delay_remain = schedule_timeout(delay);
+			delay = delay_remain;
+
+			if((should_stop = kthread_should_stop()))
+				break;
+			else if(delay_remain>0)
+				RPL_PRINTK(2, info, "rpl_trickle: %s: Interrupted: waiting for %lu (ms) Remain: %lu (jiffies)\n",__func__,trickle->t,delay);
+		}
+
+		if(should_stop)
+			break;
+
+		RPL_PRINTK(2, info, "rpl_trickle: %s: trickle timer waited for %lu (ms)\n",__func__,trickle->t);
+
+		// Step #4
+		mutex_lock(&trickle->lock);
+		local_k = trickle->k;
+		local_c = trickle->c;
+		mutex_unlock(&trickle->lock);
+		if(local_k == 0 || local_c < local_k)
+		{
+			//RPL_PRINTK(2, info, "rpl_trickle: %s: calling trickle_fn\n",__func__);
+			trickle->trickle_fn(trickle->trickle_fn_arg);
+		}
+
+		mutex_lock(&trickle->lock);
+		// step #5
+		trickle->I = trickle->I * 3;
+		if(trickle->I > trickle->Imax)
+		{
+			RPL_PRINTK(2, info, "rpl_trickle: %s: trickle timer has reached maximum interval size\n",__func__);
+			trickle->I = trickle->Imax;
+		}
+		local_c = trickle->c = 0;
+		trickle->t = rpl_randomize_range(trickle->I / 2, trickle->I, 1);
+		RPL_PRINTK(2, info, "rpl_trickle: %s: next trickle timer is set to run in %lu (ms)\n",__func__,trickle->t);
+		mutex_unlock(&trickle->lock);
+		should_stop = kthread_should_stop();
+	}
+	return 0;
+}
+
+static int _trickle_start(struct trickle_timer *trickle)
+{
+	struct task_struct *__k = NULL;
+	int ret = -EINVAL;
+	if(trickle){
+		RPL_PRINTK(2, info, "rpl_trickle: %s: starting thread\n",__func__);
+		__k = kthread_run(trickle_threadfn, trickle, "trickle-timer");
+		if (IS_ERR(__k))
+		{
+			ret = PTR_ERR(__k);
+		} else {
+			trickle->task = __k;
+			ret = 0;
+		}
+	}
+	return ret;
+}
+
+int trickle_start(struct trickle_timer *trickle)
+{
+	int ret = -EINVAL;
+	if(trickle){
+		mutex_lock(&trickle->lock);
+		ret = _trickle_start(trickle);
+		mutex_unlock(&trickle->lock);
+		ret = 0;
+	}
+	return ret;
+}
+
+static int _trickle_stop(struct trickle_timer *trickle)
+{
+	int ret = -EINVAL;
+	if(trickle){
+		ret = kthread_stop(trickle->task);
+		trickle->task = NULL;
+	}
+	return ret;
+}
+
+int trickle_stop(struct trickle_timer *trickle)
+{
+	int ret = -EINVAL;
+	if(trickle){
+		mutex_lock(&trickle->lock);
+		ret = _trickle_stop(trickle);
+		mutex_unlock(&trickle->lock);
+		ret = 0;
+	}
+	return ret;
+}
+
+int trickle_hear_consistent(struct trickle_timer *trickle)
+{
+	int ret = -EINVAL;
+	if(trickle){
+		mutex_lock(&trickle->lock);
+		RPL_PRINTK(2, info, "rpl_trickle: %s: Hearing a consistent message\n", __func__);
+		// step 3
+		trickle->c += 1;
+		mutex_unlock(&trickle->lock);
+		ret = 0;
+	}
+	return ret;
+}
+
+int trickle_hear_inconsistent(struct trickle_timer *trickle)
+{
+	int ret = -EINVAL;
+	if(trickle){
+		mutex_lock(&trickle->lock);
+		// step #6
+		RPL_PRINTK(2, info, "rpl_trickle: %s: Hearing a inconsistent message, resetting timer\n", __func__);
+		if(trickle->I != trickle->Imin)
+		{
+			mutex_unlock(&trickle->lock);
+			if ((ret = _trickle_stop(trickle)) != 0) {
+				RPL_PRINTK(0, err, "rpl_trickle: %s error stopping thread: %d\n",__func__,ret);
+			} else {
+				mutex_lock(&trickle->lock);
+				trickle->I = trickle->Imin;
+				trickle->c = 0;
+				trickle->t = rpl_randomize_range(trickle->I / 2, trickle->I, 1);
+				mutex_unlock(&trickle->lock);
+	//			if((ret = _trickle_stop(trickle)) != 0)
+	//			{
+	//				RPL_PRINTK(0, err, "rpl_trickle: %s error stopping thread\n", __func__);
+	//			} else
+				if((ret = _trickle_start(trickle)) != 0){
+					RPL_PRINTK(0, err, "rpl_trickle: %s error starting thread: %d\n", __func__,ret);
+				}
+			}
+		} else {
+			mutex_unlock(&trickle->lock);
+		}
+	}
+	return ret;
+}
diff --git a/net/ipv6/rpl_of_of0.c b/net/ipv6/rpl_of_of0.c
new file mode 100644
index 0000000..682701e
--- /dev/null
+++ b/net/ipv6/rpl_of_of0.c
@@ -0,0 +1,181 @@
+/*
+ *	RPL: Objective Function Zero for the Routing Protocol
+ *	for Low-Power and Lossy Networks (RFC 6552)
+ *
+ *	Authors:
+ *	Joao Pedro Taveira	<joao.silva@inov.pt>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+/**
+ * @file rpl_of_of0.c
+ *
+ * @date Aug 2, 2013
+ * @author Joao Pedro Taveira
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+
+#if IS_ENABLED(CONFIG_IPV6_RPL)
+#include <net/rpl/rpl_of.h>
+#endif
+
+static void reset(struct rpl_dag *dag)
+{
+
+}
+
+static void parent_state_callback(struct rpl_node *node, void *data)
+{
+
+}
+
+static int compare_nodes(struct rpl_node *parent1, struct rpl_node *parent2)
+{
+	rpl_rank_t rank1, rank2;
+	if(!parent1)
+		return 1;
+	if(!parent2)
+		return -1;
+	if(parent1->dag == parent2->dag &&
+			parent1->dag->version != parent2->dag->version)
+		return (parent1->dag->version > parent2->dag->version)?-1:(parent1->dag->version < parent2->dag->version)?1:0;
+	rank1 = parent1->dag->instance->of->ops->calculate_rank(parent1,0);
+	rank2 = parent2->dag->instance->of->ops->calculate_rank(parent2,0);
+	if(DAGRank(rank1,parent1->dag) != DAGRank(rank2,parent2->dag))
+		return (rank1 < rank2)?-1:(rank1 > rank2)?1:0;
+
+	//printk(KERN_DEBUG "%s(): p1: %pI6 rank: %u %u %u p2: %pI6 rank: %u %u %u\n",__func__,&parent1->addr,parent1->rank,DAGRank(rank1,parent1->dag),rank1,&parent2->addr,parent2->rank,DAGRank(rank2,parent2->dag),rank2);
+	return 0;
+}
+
+static struct rpl_node *best_parent(struct rpl_node *parent1, struct rpl_node *parent2)
+{
+	rpl_rank_t rank1, rank2;
+	if(!parent1)
+		return parent2;
+	if(!parent2)
+		return parent1;
+	if(parent1->dag == parent2->dag &&
+			parent1->dag->version != parent2->dag->version)
+		return (parent1->dag->version > parent2->dag->version)?parent1:parent2;
+	rank1 = parent1->dag->instance->of->ops->calculate_rank(parent1,0);
+	rank2 = parent2->dag->instance->of->ops->calculate_rank(parent2,0);
+	if(DAGRank(rank1,parent1->dag) != DAGRank(rank2,parent2->dag))
+		return (rank1 - rank2 > 0)?parent1:parent2;
+	return parent1;
+}
+
+static struct rpl_dag *best_dag(struct rpl_dag *dag1, struct rpl_dag *dag2)
+{
+	if(dag1->grounded) {
+		if (!dag2->grounded) {
+			return dag1;
+		}
+	} else if(dag2->grounded) {
+		return dag2;
+	}
+
+	if(dag1->preference < dag2->preference) {
+		return dag2;
+	} else {
+		if(dag1->preference > dag2->preference) {
+			return dag1;
+		}
+	}
+
+	if(dag2->rank < dag1->rank) {
+		return dag2;
+	} else {
+		return dag1;
+	}
+}
+
+static rpl_rank_t calculate_rank(struct rpl_node *node, rpl_rank_t base_rank)
+{
+	rpl_rank_t increment;
+	if(base_rank == 0)
+	{
+		if(!node)
+		{
+			return RPL_INFINITE_RANK;
+		}
+		base_rank = node->rank;
+	}
+	increment = (node != NULL)?node->dag->MinHopRankIncrease:RPL_DEFAULT_MIN_HOP_RANK_INCREASE;
+	//printk(KERN_DEBUG "OF0: %s(): increment: %u base_rank: %u\n",__func__,increment,base_rank);
+	if((rpl_rank_t)(base_rank + increment) < base_rank)
+	{
+		return RPL_INFINITE_RANK;
+	}
+	//printk(KERN_DEBUG "OF0: %s(): increment + base_rank: %d\n",__func__,base_rank + increment);
+	return base_rank + increment;
+}
+
+static void update_metric_container(struct rpl_instance *instance)
+{
+
+}
+
+static struct rpl_of_ops of_of0_ops = {
+		.owner = THIS_MODULE,
+		.reset = reset,
+		.parent_state_callback = parent_state_callback,
+		.best_parent = best_parent,
+		.compare_nodes = compare_nodes,
+		.best_dag = best_dag,
+		.calculate_rank = calculate_rank,
+		.update_metric_container = update_metric_container,
+};
+
+static __init int rpl_of_of0_init(void)
+{
+	struct rpl_of *of0;
+	int err = 0;
+
+	printk(KERN_INFO "RPL: Objective Function Zero (RFC 6552)\n");
+
+	of0 = rpl_of_alloc(RPL_OF_OF0,&of_of0_ops);
+	if(!of0)
+	{
+		printk(KERN_ERR "RPL: %s(): error creating rpl of\n",__func__);
+		err = -ENOMEM;
+		goto out;
+	}
+	err = rpl_of_register(of0);
+	if(err)
+	{
+		printk(KERN_ERR "RPL: %s(): error registering rpl of\n",__func__);
+		rpl_of_free(of0);
+		goto out;
+	}
+	return 0;
+out:
+	return err;
+}
+
+static __exit void rpl_of_of0_exit(void)
+{
+	struct rpl_of *of0;
+	of0 = rpl_of_get(RPL_OF_OF0);
+	if(of0)
+	{
+		rpl_of_unregister(of0);
+		rpl_of_free(of0);
+	}
+}
+
+module_init(rpl_of_of0_init);
+module_exit(rpl_of_of0_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("João Pedro Taveira");
+MODULE_DESCRIPTION("RPL: Objective Function Zero (RFC 6552)");
+MODULE_ALIAS_RPL_OF(RPL_OF_OF0);
+
+
-- 
1.8.3.2

